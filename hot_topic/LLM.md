# üîç LLM Papers ¬∑ 2025-03-31

[![Total Papers](https://img.shields.io/badge/Papers-65-2688EB)]()
[![Last Updated](https://img.shields.io/badge/dynamic/json?url=https://api.github.com/repos/tavish9/awesome-daily-AI-arxiv/commits/main&query=%24.commit.author.date&label=updated&color=orange)]()

---

## üìå Filter by Category
**Keywords**: `LLM` `Large Language Model` `GPT`  
**Filter**: `None`

---

## üìö Paper List

- **[Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation](http://arxiv.org/abs/2503.24379v1)**  `arXiv:2503.24379`  `cs.CV` `cs.AI`  
  _Shengqiong Wu, Weicai Ye, Jiahao Wang, Quande Liu, Xintao Wang, Pengfei Wan, et al._
  <details open><summary>Abstract</summary>
  To address the bottleneck of accurate user intent interpretation within thecurrent video generation community, we present Any2Caption, a novel frameworkfor controllable video generation under any condition. The key idea is todecouple various condition interpretation steps from the video synthesis step.By leveraging modern multimodal large language models (MLLMs), Any2Captioninterprets diverse inputs--text, images, videos, and specialized cues such asregion, motion, and camera poses--into dense, structured captions that offerbackbone video generators with better guidance. We also introduce Any2CapIns, alarge-scale dataset with 337K instances and 407K conditions forany-condition-to-caption instruction tuning. Comprehensive evaluationsdemonstrate significant improvements of our system in controllability and videoquality across various aspects of existing video generation models. ProjectPage: https://sqwu.top/Any2Cap/
  </details>

- **[Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models](http://arxiv.org/abs/2503.24377v1)**  `arXiv:2503.24377`  `cs.CL` `cs.AI`  
  _Rui Wang, Hongru Wang, Boyang Xue, Jianhui Pang, Shudong Liu, Yi Chen, et al._
  <details open><summary>Abstract</summary>
  Recent advancements in Large Language Models (LLMs) have significantlyenhanced their ability to perform complex reasoning tasks, transitioning fromfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).While System 2 reasoning improves task accuracy, it often incurs substantialcomputational costs due to its slow thinking nature and inefficient orunnecessary reasoning behaviors. In contrast, System 1 reasoning iscomputationally efficient but leads to suboptimal performance. Consequently, itis critical to balance the trade-off between performance (benefits) andcomputational costs (budgets), giving rise to the concept of reasoning economy.In this survey, we provide a comprehensive analysis of reasoning economy inboth the post-training and test-time inference stages of LLMs, encompassing i)the cause of reasoning inefficiency, ii) behavior analysis of differentreasoning patterns, and iii) potential solutions to achieve reasoning economy.By offering actionable insights and highlighting open challenges, we aim toshed light on strategies for improving the reasoning economy of LLMs, therebyserving as a valuable resource for advancing research in this evolving area. Wealso provide a public repository to continually track developments in thisfast-evolving field.
  </details>

- **[Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1](http://arxiv.org/abs/2503.24376v1)**  `arXiv:2503.24376`  `cs.LG` `cs.CV` `cs.CL` `cs.AI`  
  _Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Lu Qiu, Ying Shan, et al._
  <details open><summary>Abstract</summary>
  Recent advancements in Chain of Thought (COT) generation have significantlyimproved the reasoning capabilities of Large Language Models (LLMs), withreinforcement learning (RL) emerging as an effective post-training approach.Multimodal Large Language Models (MLLMs) inherit this reasoning potential butremain underexplored in tasks requiring both perception and logical reasoning.To address this, we introduce SEED-Bench-R1, a benchmark designed tosystematically evaluate post-training methods for MLLMs in video understanding.It includes intricate real-world videos and complex everyday planning tasks inthe format of multiple-choice questions, requiring sophisticated perception andreasoning. SEED-Bench-R1 assesses generalization through a three-levelhierarchy: in-distribution, cross-environment, and cross-environment-taskscenarios, equipped with a large-scale training dataset with easily verifiableground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RLwith supervised fine-tuning (SFT), demonstrating RL's data efficiency andsuperior performance on both in-distribution and out-of-distribution tasks,even outperforming SFT on general video understanding benchmarks likeLongVideoBench. Our detailed analysis reveals that RL enhances visualperception but often produces less logically coherent reasoning chains. Weidentify key limitations such as inconsistent reasoning and overlooked visualcues, and suggest future improvements in base model reasoning, reward modeling,and RL robustness against noisy signals.
  </details>

- **[Effectively Controlling Reasoning Models through Thinking Intervention](http://arxiv.org/abs/2503.24370v1)**  `arXiv:2503.24370`  `cs.LG` `cs.CL` `cs.AI`  
  _Tong Wu, Chong Xiang, Jiachen T. Wang, Prateek Mittal_
  <details open><summary>Abstract</summary>
  Reasoning-enhanced large language models (LLMs) explicitly generateintermediate reasoning steps prior to generating final answers, helping themodel excel in complex problem-solving. In this paper, we demonstrate that thisemerging generation framework offers a unique opportunity for more fine-grainedcontrol over model behavior. We propose Thinking Intervention, a novel paradigmdesigned to explicitly guide the internal reasoning processes of LLMs bystrategically inserting or revising specific thinking tokens. We conductcomprehensive evaluations across multiple tasks, including instructionfollowing on IFEval, instruction hierarchy on SEP, and safety alignment onXSTest and SORRY-Bench. Our results demonstrate that Thinking Interventionsignificantly outperforms baseline prompting approaches, achieving up to 6.7%accuracy gains in instruction-following scenarios, 15.4% improvements inreasoning about instruction hierarchies, and a 40.0% increase in refusal ratesfor unsafe prompts using open-source DeepSeek R1 models. Overall, our workopens a promising new research avenue for controlling reasoning LLMs.
  </details>

- **[ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion](http://arxiv.org/abs/2503.24354v1)**  `arXiv:2503.24354`  `cs.LG` `cs.CV` `cs.CL` `cs.AI`  
  _Rana Muhammad Shahroz Khan, Dongwen Tang, Pingzhi Li, Kai Wang, Tianlong Chen_
  <details open><summary>Abstract</summary>
  Parameter generation has emerged as a novel paradigm for neural networkdevelopment, offering an alternative to traditional neural network training bysynthesizing high-quality model weights directly. In the context of Low-RankAdaptation (LoRA) for evolving ($\textit{i.e.}$, constantly updated) largelanguage models (LLMs), this approach promises efficient adaptation withoutcostly retraining. However, existing methods face critical limitations insimultaneously achieving scalability and controllability. In this paper, weintroduce $\texttt{ORAL}$, a novel $\textbf{conditional recurrent diffusion}$framework that addresses these challenges. $\texttt{ORAL}$ incorporates a novelconditioning mechanism that integrates model architecture and textual taskspecifications, enabling the generation of task-specific LoRA parameters thatcan seamlessly transfer across evolving foundation models. Our approachsuccessfully scales to billions-of-parameter LLMs and maintainscontrollability. Through extensive experiments across seven language tasks,four vision tasks, and three multimodal tasks using five pre-trained LLMs, wedemonstrate that $\texttt{ORAL}$ generates high-quality LoRA parameters thatachieve comparable or superior performance to vanilla trained counterparts.
  </details>

- **[Is analogy enough to draw novel adjective-noun inferences?](http://arxiv.org/abs/2503.24293v1)**  `arXiv:2503.24293`  `cs.CL`  
  _Hayley Ross, Kathryn Davidson, Najoung Kim_
  <details open><summary>Abstract</summary>
  Recent work (Ross et al., 2025, 2024) has argued that the ability of humansand LLMs respectively to generalize to novel adjective-noun combinations showsthat they each have access to a compositional mechanism to determine thephrase's meaning and derive inferences. We study whether these inferences caninstead be derived by analogy to known inferences, without need forcomposition. We investigate this by (1) building a model of analogicalreasoning using similarity over lexical items, and (2) asking humanparticipants to reason by analogy. While we find that this strategy works wellfor a large proportion of the dataset of Ross et al. (2025), there are novelcombinations for which both humans and LLMs derive convergent inferences butwhich are not well handled by analogy. We thus conclude that the mechanismhumans and LLMs use to generalize in these cases cannot be fully reduced toanalogy, and likely involves composition.
  </details>

- **[Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality](http://arxiv.org/abs/2503.24277v1)**  `arXiv:2503.24277`  `cs.LG` `cs.AI`  
  _Sewoong Lee, Adam Davies, Marc E. Canby, Julia Hockenmaier_
  <details open><summary>Abstract</summary>
  Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanisticinterpretability, but leading SAE approaches with top-$k$ style activationfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEsare based on the linear representation hypothesis (LRH), which assumes that therepresentations of large language models (LLMs) are linearly encoded, and thesuperposition hypothesis (SH), which states that there can be more features inthe model than its dimensionality. We show that, based on the formaldefinitions of the LRH and SH, the magnitude of sparse feature vectors (thelatent representations learned by SAEs of the dense embeddings of LLMs) can beapproximated using their corresponding dense vector with a closed-form errorbound. To visualize this, we propose the ZF plot, which reveals a previouslyunknown relationship between LLM hidden embeddings and SAE feature vectors,allowing us to make the first empirical measurement of the extent to whichfeature vectors of pre-trained SAEs are over- or under-activated for a giveninput. Correspondingly, we introduce Approximate Feature Activation (AFA),which approximates the magnitude of the ground-truth sparse feature vector, andpropose a new evaluation metric derived from AFA to assess the alignmentbetween inputs and activations. We also leverage AFA to introduce a novel SAEarchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line withtheoretical justifications; and (b) obviate the need to tune SAE sparsityhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achievereconstruction loss comparable to that of state-of-the-art top-k SAEs, withoutrequiring the hyperparameter $k$ to be tuned. Our code is available at:https://github.com/SewoongLee/top-afa-sae.
  </details>

- **[Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation](http://arxiv.org/abs/2503.24245v1)**  `arXiv:2503.24245`  `cs.CL`  
  _Dun Yuan, Hao Zhou, Di Wu, Xue Liu, Hao Chen, Yan Xin, et al._
  <details open><summary>Abstract</summary>
  Large language models (LLMs) have made significant progress ingeneral-purpose natural language processing tasks. However, LLMs are stillfacing challenges when applied to domain-specific areas liketelecommunications, which demands specialized expertise and adaptability toevolving standards. This paper presents a novel framework that combinesknowledge graph (KG) and retrieval-augmented generation (RAG) techniques toenhance LLM performance in the telecom domain. The framework leverages a KG tocapture structured, domain-specific information about network protocols,standards, and other telecom-related entities, comprehensively representingtheir relationships. By integrating KG with RAG, LLMs can dynamically accessand utilize the most relevant and up-to-date knowledge during responsegeneration. This hybrid approach bridges the gap between structured knowledgerepresentation and the generative capabilities of LLMs, significantly enhancingaccuracy, adaptability, and domain-specific comprehension. Our resultsdemonstrate the effectiveness of the KG-RAG framework in addressing complextechnical queries with precision. The proposed KG-RAG model attained anaccuracy of 88% for question answering tasks on a frequently usedtelecom-specific dataset, compared to 82% for the RAG-only and 48% for theLLM-only approaches.
  </details>

- **[What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models](http://arxiv.org/abs/2503.24235v1)**  `arXiv:2503.24235`  `cs.CL` `cs.AI`  
  _Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Zhihan Guo, et al._
  <details open><summary>Abstract</summary>
  As enthusiasm for scaling computation (data and parameters) in thepretraining era gradually diminished, test-time scaling (TTS), also referred toas ``test-time computing'' has emerged as a prominent research focus. Recentstudies demonstrate that TTS can further elicit the problem-solvingcapabilities of large language models (LLMs), enabling significantbreakthroughs not only in specialized reasoning tasks, such as mathematics andcoding, but also in general tasks like open-ended Q&A. However, despite theexplosion of recent efforts in this area, there remains an urgent need for acomprehensive survey offering a systemic understanding. To fill this gap, wepropose a unified, multidimensional framework structured along four coredimensions of TTS research: what to scale, how to scale, where to scale, andhow well to scale. Building upon this taxonomy, we conduct an extensive reviewof methods, application scenarios, and assessment aspects, and present anorganized decomposition that highlights the unique functional roles ofindividual techniques within the broader TTS landscape. From this analysis, wedistill the major developmental trajectories of TTS to date and offer hands-onguidelines for practical deployment. Furthermore, we identify several openchallenges and offer insights into promising future directions, includingfurther scaling, clarifying the functional essence of techniques, generalizingto more tasks, and more attributions.
  </details>

- **[PAARS: Persona Aligned Agentic Retail Shoppers](http://arxiv.org/abs/2503.24228v1)**  `arXiv:2503.24228`  `cs.MA` `cs.CL` `cs.AI`  
  _Saab Mansour, Leonardo Perelli, Lorenzo Mainetti, George Davidson, Stefano D'Amato_
  <details open><summary>Abstract</summary>
  In e-commerce, behavioral data is collected for decision making which can becostly and slow. Simulation with LLM powered agents is emerging as a promisingalternative for representing human population behavior. However, LLMs are knownto exhibit certain biases, such as brand bias, review rating bias and limitedrepresentation of certain groups in the population, hence they need to becarefully benchmarked and aligned to user behavior. Ultimately, our goal is tosynthesise an agent population and verify that it collectively approximates areal sample of humans. To this end, we propose a framework that: (i) createssynthetic shopping agents by automatically mining personas from anonymisedhistorical shopping data, (ii) equips agents with retail-specific tools tosynthesise shopping sessions and (iii) introduces a novel alignment suitemeasuring distributional differences between humans and shopping agents at thegroup (i.e. population) level rather than the traditional "individual" level.Experimental results demonstrate that using personas improves performance onthe alignment suite, though a gap remains to human behaviour. We showcase aninitial application of our framework for automated agentic A/B testing andcompare the findings to human results. Finally, we discuss applications,limitations and challenges setting the stage for impactful future work.
  </details>

- **[Synthetic News Generation for Fake News Classification](http://arxiv.org/abs/2503.24206v1)**  `arXiv:2503.24206`  `cs.CL`  
  _Abdul Sittar, Luka Golob, Mateja Smiljanic_
  <details open><summary>Abstract</summary>
  This study explores the generation and evaluation of synthetic fake newsthrough fact based manipulations using large language models (LLMs). Weintroduce a novel methodology that extracts key facts from real articles,modifies them, and regenerates content to simulate fake news while maintainingcoherence. To assess the quality of the generated content, we propose a set ofevaluation metrics coherence, dissimilarity, and correctness. The research alsoinvestigates the application of synthetic data in fake news classification,comparing traditional machine learning models with transformer based modelssuch as BERT. Our experiments demonstrate that transformer models, especiallyBERT, effectively leverage synthetic data for fake news detection, showingimprovements with smaller proportions of synthetic data. Additionally, we findthat fact verification features, which focus on identifying factualinconsistencies, provide the most promising results in distinguishing syntheticfake news. The study highlights the potential of synthetic data to enhance fakenews detection systems, offering valuable insights for future research andsuggesting that targeted improvements in synthetic data generation can furtherstrengthen detection models.
  </details>

- **[TwT: Thinking without Tokens by Habitual Reasoning Distillation with Multi-Teachers' Guidance](http://arxiv.org/abs/2503.24198v1)**  `arXiv:2503.24198`  `cs.CL`  
  _Jingxian Xu, Mengyu Zhou, Weichang Liu, Hanbing Liu, Shi Han, Dongmei Zhang_
  <details open><summary>Abstract</summary>
  Large Language Models (LLMs) have made significant strides in problem-solvingby incorporating reasoning processes. However, this enhanced reasoningcapability results in an increased number of output tokens during inference,leading to higher computational costs. To address this challenge, we proposeTwT (Thinking without Tokens), a method that reduces inference-time coststhrough habitual reasoning distillation with multi-teachers' guidance, whilemaintaining high performance. Our approach introduces a Habitual ReasoningDistillation method, which internalizes explicit reasoning into the model'shabitual behavior through a Teacher-Guided compression strategy inspired byhuman cognition. Additionally, we propose Dual-Criteria Rejection Sampling(DCRS), a technique that generates a high-quality and diverse distillationdataset using multiple teacher models, making our method suitable forunsupervised scenarios. Experimental results demonstrate that TwT effectivelyreduces inference costs while preserving superior performance, achieving up toa 13.6% improvement in accuracy with fewer output tokens compared to otherdistillation methods, offering a highly practical solution for efficient LLMdeployment.
  </details>

- **[Implicit In-Context Learning: Evidence from Artificial Language Experiments](http://arxiv.org/abs/2503.24190v1)**  `arXiv:2503.24190`  `cs.CL`  
  _Xiaomeng Ma, Qihui Xu_
  <details open><summary>Abstract</summary>
  Humans acquire language through implicit learning, absorbing complex patternswithout explicit awareness. While LLMs demonstrate impressive linguisticcapabilities, it remains unclear whether they exhibit human-like patternrecognition during in-context learning at inferencing level. We adapted threeclassic artificial language learning experiments spanning morphology,morphosyntax, and syntax to systematically evaluate implicit learning atinferencing level in two state-of-the-art OpenAI models: gpt-4o and o3-mini.Our results reveal linguistic domain-specific alignment between models andhuman behaviors, o3-mini aligns better in morphology while both models align insyntax.
  </details>

- **[LLM4FS: Leveraging Large Language Models for Feature Selection and How to Improve It](http://arxiv.org/abs/2503.24157v1)**  `arXiv:2503.24157`  `cs.LG`  
  _Jianhao Li, Xianchao Xiu_
  <details open><summary>Abstract</summary>
  Recent advances in large language models (LLMs) have provided newopportunities for decision-making, particularly in the task of automatedfeature selection. In this paper, we first comprehensively evaluate LLM-basedfeature selection methods, covering the state-of-the-art DeepSeek-R1,GPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy calledLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,input data samples into LLMs, and directly call traditional data-driventechniques such as random forest and forward sequential selection. Notably, ouranalysis reveals that the hybrid strategy leverages the contextualunderstanding of LLMs and the high statistical reliability of traditionaldata-driven methods to achieve excellent feature selection performance, evensurpassing LLMs and traditional data-driven methods. Finally, we point out thelimitations of its application in decision-making.
  </details>

- **[Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition](http://arxiv.org/abs/2503.24110v1)**  `arXiv:2503.24110`  `cs.CL` `cs.AI`  
  _Fran√ßois Olivier, Zied Bouraoui_
  <details open><summary>Abstract</summary>
  Despite advances in embodied AI, agent reasoning systems still struggle tocapture the fundamental conceptual structures that humans naturally use tounderstand and interact with their environment. To address this, we propose anovel framework that bridges embodied cognition theory and agent systems byleveraging a formal characterization of image schemas, which are defined asrecurring patterns of sensorimotor experience that structure human cognition.By customizing LLMs to translate natural language descriptions into formalrepresentations based on these sensorimotor patterns, we will be able to createa neurosymbolic system that grounds the agent's understanding in fundamentalconceptual structures. We argue that such an approach enhances both efficiencyand interpretability while enabling more intuitive human-agent interactionsthrough shared embodied understanding.
  </details>

- **[Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?](http://arxiv.org/abs/2503.24102v1)**  `arXiv:2503.24102`  `cs.CL`  
  _Yewei Song, Lujun Li, Cedric Lothritz, Saad Ezzini, Lama Sleem, Niccolo Gentile, et al._
  <details open><summary>Abstract</summary>
  Low-Resource Languages (LRLs) present significant challenges in naturallanguage processing due to their limited linguistic resources andunderrepresentation in standard datasets. While recent advancements in LargeLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantiallyimproved translation capabilities for high-resource languages, performancedisparities persist for LRLs, particularly impacting privacy-sensitive andresource-constrained scenarios. This paper systematically evaluates thelimitations of current LLMs across 200 languages using benchmarks such asFLORES-200. We also explore alternative data sources, including news articlesand bilingual dictionaries, and demonstrate how knowledge distillation fromlarge pre-trained models can significantly improve smaller LRL translations.Additionally, we investigate various fine-tuning strategies, revealing thatincremental enhancements markedly reduce performance gaps on smaller LLMs.
  </details>

- **[DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description](http://arxiv.org/abs/2503.24096v1)**  `arXiv:2503.24096`  `cs.CV`  
  _Adrienne Deganutti, Simon Hadfield, Andrew Gilbert_
  <details open><summary>Abstract</summary>
  Audio Description is a narrated commentary designed to aid vision-impairedaudiences in perceiving key visual elements in a video. While short-form videounderstanding has advanced rapidly, a solution for maintaining coherentlong-term visual storytelling remains unresolved. Existing methods rely solelyon frame-level embeddings, effectively describing object-based content butlacking contextual information across scenes. We introduce DANTE-AD, anenhanced video description model leveraging a dual-vision Transformer-basedarchitecture to address this gap. DANTE-AD sequentially fuses both frame andscene level embeddings to improve long-term contextual understanding. Wepropose a novel, state-of-the-art method for sequential cross-attention toachieve contextual grounding for fine-grained audio description generation.Evaluated on a broad range of key scenes from well-known movie clips, DANTE-ADoutperforms existing methods across traditional NLP metrics and LLM-basedevaluations.
  </details>

- **[TransMamba: Flexibly Switching between Transformer and Mamba](http://arxiv.org/abs/2503.24067v1)**  `arXiv:2503.24067`  `cs.LG`  
  _Yixing Li, Ruobing Xie, Zhen Yang, Xingwu Sun, Shuaipeng Li, Weidong Han, et al._
  <details open><summary>Abstract</summary>
  Transformers are the cornerstone of modern large language models, but theirquadratic computational complexity limits efficiency in long-sequenceprocessing. Recent advancements in Mamba, a state space model (SSM) with linearcomplexity, offer promising efficiency gains but suffer from unstablecontextual learning and multitask generalization. This paper proposesTransMamba, a novel framework that unifies Transformer and Mamba through sharedparameter matrices (e.g., QKV and CBx), and thus could dynamically switchbetween attention and SSM mechanisms at different token lengths and layers. Wedesign the Memory converter to bridge Transformer and Mamba by convertingattention outputs into SSM-compatible states, ensuring seamless informationflow at TransPoints where the transformation happens. The TransPoint schedulingis also thoroughly explored for further improvements. We conducted extensiveexperiments demonstrating that TransMamba achieves superior training efficiencyand performance compared to baselines, and validated the deeper consistencybetween Transformer and Mamba paradigms, offering a scalable solution fornext-generation sequence modeling.
  </details>

- **[Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data](http://arxiv.org/abs/2503.24062v1)**  `arXiv:2503.24062`  `cs.LG` `cs.CL` `cs.AI`  
  _Fatemeh Mohammadi, Tommaso Romano, Samira Maghool, Paolo Ceravolo_
  <details open><summary>Abstract</summary>
  Collecting high-quality training data is essential for fine-tuning LargeLanguage Models (LLMs). However, acquiring such data is often costly andtime-consuming, especially for non-English languages such as Italian. Recently,researchers have begun to explore the use of LLMs to generate syntheticdatasets as a viable alternative. This study proposes a pipeline for generatingsynthetic data and a comprehensive approach for investigating the factors thatinfluence the validity of synthetic data generated by LLMs by examining howmodel performance is affected by metrics such as prompt strategy, text lengthand target position in a specific task, i.e. inclusive language detection inItalian job advertisements. Our results show that, in most cases and acrossdifferent metrics, the fine-tuned models trained on synthetic data consistentlyoutperformed other models on both real and synthetic test datasets. The studydiscusses the practical implications and limitations of using synthetic datafor language detection tasks with LLMs.
  </details>

- **[Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents](http://arxiv.org/abs/2503.24047v1)**  `arXiv:2503.24047`  `cs.MA` `cs.AI`  
  _Shuo Ren, Pu Jian, Zhenjiang Ren, Chunlin Leng, Can Xie, Jiajun Zhang_
  <details open><summary>Abstract</summary>
  As scientific research becomes increasingly complex, innovative tools areneeded to manage vast data, facilitate interdisciplinary collaboration, andaccelerate discovery. Large language models (LLMs) are now evolving intoLLM-based scientific agents that automate critical tasks, ranging fromhypothesis generation and experiment design to data analysis and simulation.Unlike general-purpose LLMs, these specialized agents integrate domain-specificknowledge, advanced tool sets, and robust validation mechanisms, enabling themto handle complex data types, ensure reproducibility, and drive scientificbreakthroughs. This survey provides a focused review of the architectures,design, benchmarks, applications, and ethical considerations surroundingLLM-based scientific agents. We highlight why they differ from general agentsand the ways in which they advance research across various scientific fields.By examining their development and challenges, this survey offers acomprehensive roadmap for researchers and practitioners to harness these agentsfor more efficient, reliable, and ethically sound scientific discovery.
  </details>

- **[Pay More Attention to the Robustness of Prompt for Instruction Data Mining](http://arxiv.org/abs/2503.24028v1)**  `arXiv:2503.24028`  `cs.AI`  
  _Qiang Wang, Dawei Feng, Xu Zhang, Ao Shen, Yang Xu, Bo Ding, et al._
  <details open><summary>Abstract</summary>
  Instruction tuning has emerged as a paramount method for tailoring thebehaviors of LLMs. Recent work has unveiled the potential for LLMs to achievehigh performance through fine-tuning with a limited quantity of high-qualityinstruction data. Building upon this approach, we further explore the impact ofprompt's robustness on the selection of high-quality instruction data. Thispaper proposes a pioneering framework of high-quality online instruction datamining for instruction tuning, focusing on the impact of prompt's robustness onthe data mining process. Our notable innovation, is to generate the adversarialinstruction data by conducting the attack for the prompt of online instructiondata. Then, we introduce an Adversarial Instruction-Following Difficulty metricto measure how much help the adversarial instruction data can provide to thegeneration of the corresponding response. Apart from it, we propose a novelAdversarial Instruction Output Embedding Consistency approach to selecthigh-quality online instruction data. We conduct extensive experiments on twobenchmark datasets to assess the performance. The experimental results serve tounderscore the effectiveness of our proposed two methods. Moreover, the resultsunderscore the critical practical significance of considering prompt'srobustness.
  </details>

- **[H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding](http://arxiv.org/abs/2503.24008v1)**  `arXiv:2503.24008`  `cs.CV` `cs.AI`  
  _Qi Wu, Quanlong Zheng, Yanhao Zhang, Junlin Xie, Jinguo Luo, Kuo Wang, et al._
  <details open><summary>Abstract</summary>
  With the rapid development of multimodal models, the demand for assessingvideo understanding capabilities has been steadily increasing. However,existing benchmarks for evaluating video understanding exhibit significantlimitations in coverage, task diversity, and scene adaptability. Theseshortcomings hinder the accurate assessment of models' comprehensive videounderstanding capabilities. To tackle this challenge, we propose a hierarchicaland holistic video understanding (H2VU) benchmark designed to evaluate bothgeneral video and online streaming video comprehension. This benchmarkcontributes three key features:  Extended video duration: Spanning videos from brief 3-second clips tocomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found incurrent benchmarks. Comprehensive assessment tasks: Beyond traditionalperceptual and reasoning tasks, we have introduced modules forcountercommonsense comprehension and trajectory state tracking. These additionstest the models' deep understanding capabilities beyond mere prior knowledge.Enriched video data: To keep pace with the rapid evolution of current AIagents, we have expanded first-person streaming video datasets. This expansionallows for the exploration of multimodal models' performance in understandingstreaming videos from a first-person perspective. Extensive results from H2VUreveal that existing multimodal large language models (MLLMs) possesssubstantial potential for improvement in our newly proposed evaluation tasks.We expect that H2VU will facilitate advancements in video understandingresearch by offering a comprehensive and in-depth analysis of MLLMs.
  </details>

- **[Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving](http://arxiv.org/abs/2503.24000v1)**  `arXiv:2503.24000`  `cs.LG` `cs.AI`  
  _Wei Gao, Xinyu Zhou, Peng Sun, Tianwei Zhang, Yonggang Wen_
  <details open><summary>Abstract</summary>
  Key-Value cache (\texttt{KV} \texttt{cache}) compression has emerged as apromising technique to optimize Large Language Model (LLM) serving. Itprimarily decreases the memory consumption of \texttt{KV} \texttt{cache} toreduce the computation cost. Despite the development of many compressionalgorithms, their applications in production environments are still notprevalent. In this paper, we revisit mainstream \texttt{KV} \texttt{cache}compression solutions from a practical perspective. Our contributions arethree-fold. First, we comprehensively review existing algorithmic designs andbenchmark studies for \texttt{KV} \texttt{cache} compression and identifymissing pieces in their performance measurement, which could hinder theiradoption in practice. Second, we empirically evaluate representative\texttt{KV} \texttt{cache} compression methods to uncover two key issues thataffect the computational efficiency: (1) while compressing \texttt{KV}\texttt{cache} can reduce memory consumption, current implementations (e.g.,FlashAttention, PagedAttention) do not optimize for production-level LLMserving, resulting in suboptimal throughput performance; (2) compressing\texttt{KV} \texttt{cache} may lead to longer outputs, resulting in increasedend-to-end latency. We further investigate the accuracy performance ofindividual samples rather than the overall performance, revealing the intrinsiclimitations in \texttt{KV} \texttt{cache} compression when handling specificLLM tasks. Third, we provide tools to shed light on future \texttt{KV}\texttt{cache} compression studies and facilitate their practical deployment inproduction. They are open-sourced in\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.
  </details>

- **[Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in Discriminative and Generative AI Operations](http://arxiv.org/abs/2503.23934v1)**  `arXiv:2503.23934`  `cs.LG` `cs.AI`  
  _Adri√°n S√°nchez-Momp√≥, Ioannis Mavromatis, Peizheng Li, Konstantinos Katsaros, Aftab Khan_
  <details open><summary>Abstract</summary>
  This study presents an empirical investigation into the energy consumption ofDiscriminative and Generative AI models within real-world MLOps pipelines. ForDiscriminative models, we examine various architectures and hyperparametersduring training and inference and identify energy-efficient practices. ForGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily onenergy consumption across different model sizes and varying service requests.Our study employs software-based power measurements, ensuring ease ofreplication across diverse configurations, models, and datasets. We analysemultiple models and hardware setups to uncover correlations among variousmetrics, identifying key contributors to energy consumption. The resultsindicate that for Discriminative models, optimising architectures,hyperparameters, and hardware can significantly reduce energy consumptionwithout sacrificing performance. For LLMs, energy efficiency depends onbalancing model size, reasoning complexity, and request-handling capacity, aslarger models do not necessarily consume more energy when utilisation remainslow. This analysis provides practical guidelines for designing green andsustainable ML operations, emphasising energy consumption and carbon footprintreductions while maintaining performance. This paper can serve as a benchmarkfor accurately estimating total energy use across different types of AI models.
  </details>

- **[Model Hemorrhage and the Robustness Limits of Large Language Models](http://arxiv.org/abs/2503.23924v1)**  `arXiv:2503.23924`  `cs.LG` `cs.CL`  
  _Ziyang Ma, Zuchao Li, Lefei Zhang, Gui-Song Xia, Bo Du, Liangpei Zhang, et al._
  <details open><summary>Abstract</summary>
  Large language models (LLMs) demonstrate strong performance across naturallanguage processing tasks, yet undergo significant performance degradation whenmodified for deployment through quantization, pruning, or decoding strategyadjustments. We define this phenomenon as model hemorrhage - performancedecline caused by parameter alterations and architectural changes. Throughsystematic analysis of various LLM frameworks, we identify key vulnerabilitypatterns: layer expansion frequently disrupts attention mechanisms, compressiontechniques induce information loss cascades, and decoding adjustments amplifyprediction divergences. Our investigation reveals transformer architecturesexhibit inherent robustness thresholds that determine hemorrhage severityacross modification types. We propose three mitigation strategies:gradient-aware pruning preserves critical weight pathways, dynamic quantizationscaling maintains activation integrity, and decoding calibration alignsgeneration trajectories with original model distributions. This workestablishes foundational metrics for evaluating model stability duringadaptation, providing practical guidelines for maintaining performance whileenabling efficient LLM deployment. Our findings advance understanding of neuralnetwork resilience under architectural transformations, particularly forlarge-scale language models.
  </details>

- **[Entropy-Based Adaptive Weighting for Self-Training](http://arxiv.org/abs/2503.23913v1)**  `arXiv:2503.23913`  `cs.CL`  
  _Xiaoxuan Wang, Yihe Deng, Mingyu Derek Ma, Wei Wang_
  <details open><summary>Abstract</summary>
  The mathematical problem-solving capabilities of large language models havebecome a focal point of research, with growing interests in leveragingself-generated reasoning paths as a promising way to refine and enhance thesemodels. These paths capture step-by-step logical processes while requiring onlythe correct answer for supervision. The self-training method has been shown tobe effective in reasoning tasks while eliminating the need for external modelsand manual annotations. However, optimizing the use of self-generated data formodel training remains an open challenge. In this work, we proposeEntropy-Based Adaptive Weighting for Self-Training (EAST), an adaptiveweighting strategy designed to prioritize uncertain data during self-training.Specifically, EAST employs a mapping function with a tunable parameter thatcontrols the sharpness of the weighting, assigning higher weights to data wherethe model exhibits greater uncertainty. This approach guides the model to focuson more informative and challenging examples, thereby enhancing its reasoningability. We evaluate our approach on GSM8K and MATH benchmarks. Empiricalresults show that, while the vanilla method yields virtually no improvement(0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K,EAST attains a further 1-2% performance boost compared to the vanilla method.
  </details>

- **[Better wit than wealth: Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement](http://arxiv.org/abs/2503.23895v1)**  `arXiv:2503.23895`  `cs.CL` `cs.AI`  
  _Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu_
  <details open><summary>Abstract</summary>
  Retrieval-augmented generation (RAG) enhances large language models (LLMs) byretrieving relevant documents from external sources and incorporating them intothe context. While it improves reliability by providing factual texts, itsignificantly increases inference costs as context length grows and introduceschallenging issue of RAG hallucination, primarily caused by the lack ofcorresponding parametric knowledge in LLMs. An efficient solution is to enhancethe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this byembedding document into LLMs parameters to perform test-time knowledgeenhancement, effectively reducing inference costs through offline training.However, its high training and storage costs, along with limited generalizationability, significantly restrict its practical adoption. To address thesechallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework thatleverages a lightweight parameter translator model to efficiently convertdocuments into parametric knowledge. DyPRAG not only reduces inference,training, and storage costs but also dynamically generates parametricknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledgeconflicts in a plug-and-play manner at test-time. Extensive experiments onmultiple datasets demonstrate the effectiveness and generalization capabilitiesof DyPRAG, offering a powerful and practical RAG paradigm which enablessuperior knowledge fusion and mitigates RAG hallucination in real-worldapplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.
  </details>

- **[GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via Language Models](http://arxiv.org/abs/2503.23875v1)**  `arXiv:2503.23875`  `cs.MA` `cs.RO` `cs.AI`  
  _Wenkang Ji, Huaben Chen, Mingyang Chen, Guobin Zhu, Lufeng Xu, Roderich Gro√ü, et al._
  <details open><summary>Abstract</summary>
  The development of control policies for multi-robot systems traditionallyfollows a complex and labor-intensive process, often lacking the flexibility toadapt to dynamic tasks. This has motivated research on methods to automaticallycreate control policies. However, these methods require iterative processes ofmanually crafting and refining objective functions, thereby prolonging thedevelopment cycle. This work introduces \textit{GenSwarm}, an end-to-end systemthat leverages large language models to automatically generate and deploycontrol policies for multi-robot tasks based on simple user instructions innatural language. As a multi-language-agent system, GenSwarm achieves zero-shotlearning, enabling rapid adaptation to altered or unseen tasks. The white-boxnature of the code policies ensures strong reproducibility andinterpretability. With its scalable software and hardware architectures,GenSwarm supports efficient policy deployment on both simulated and real-worldmulti-robot systems, realizing an instruction-to-execution end-to-endfunctionality that could prove valuable for robotics specialists andnon-specialists alike.The code of the proposed GenSwarm system is availableonline: https://github.com/WindyLab/GenSwarm.
  </details>

- **[Communication-Efficient and Personalized Federated Foundation Model Fine-Tuning via Tri-Matrix Adaptation](http://arxiv.org/abs/2503.23869v1)**  `arXiv:2503.23869`  `cs.LG`  
  _Yongle Li, Bo Liu, Sheng Huang, ZHeng ZHang, Xiaotong Yuan, Richang Hong_
  <details open><summary>Abstract</summary>
  In federated learning, fine-tuning pre-trained foundation models posessignificant challenges, particularly regarding high communication cost andsuboptimal model performance due to data heterogeneity between the clients. Toaddress these issues, this paper introduces communication-efficient federatedLoRA adaption (CE-LoRA), a method that employs a tri-factorization low-rankadaptation approach with personalized model parameter aggregation. We firstpresents a novel LoRA parameter factorization by introducing a small-size densematrix, which can significantly reduce the communication cost and achievecomparable empirical performance than transferring the low-rank parametermatrix used by existing methods. Without violating data privacy, the serverconsiders the client similarity in both training dataset and model parameterspace, and learns personalized weights for model aggregation. Our experimentson various LLM and VLM fine-tuning tasks demonstrate that CE-LoRA not onlysignificantly reduces communication overhead but also improves performanceunder not independently and identically distributed data conditions. Inaddition, CE-LoRA improves data privacy protection, effectively mitigatinggradient-based data reconstruction attacks.
  </details>

- **[SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to Accelerate Your Speech-LLM Development](http://arxiv.org/abs/2503.23848v1)**  `arXiv:2503.23848`  `cs.CL`  
  _Minghan Wang, Ye Bai, Yuxia Wang, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari_
  <details open><summary>Abstract</summary>
  High-quality speech dialogue datasets are crucial for Speech-LLM development,yet existing acquisition methods face significant limitations. Human recordingsincur high costs and privacy concerns, while synthetic approaches often lackconversational authenticity. To address these challenges, we introduce\textsc{SpeechDialogueFactory}, a production-ready framework for generatingnatural speech dialogues efficiently. Our solution employs a comprehensivepipeline including metadata generation, dialogue scripting,paralinguistic-enriched utterance simulation, and natural speech synthesis withvoice cloning. Additionally, the system provides an interactive UI for detailedsample inspection and a high-throughput batch synthesis mode. Evaluations showthat dialogues generated by our system achieve a quality comparable to humanrecordings while significantly reducing production costs. We release our workas an open-source toolkit, alongside example datasets available in English andChinese, empowering researchers and developers in Speech-LLM research anddevelopment.
  </details>

- **[Expanding RL with Verifiable Rewards Across Diverse Domains](http://arxiv.org/abs/2503.23829v1)**  `arXiv:2503.23829`  `cs.CL`  
  _Yi Su, Dian Yu, Linfeng Song, Juntao Li, Haitao Mi, Zhaopeng Tu, et al._
  <details open><summary>Abstract</summary>
  Reinforcement learning (RL) with verifiable rewards (RLVR) has shownpromising results in mathematical reasoning and coding tasks wherewell-structured reference answers are available. However, its applicability tobroader domains remains underexplored. In this work, we study the extension ofRLVR to more diverse domains such as medicine, chemistry, psychology, andeconomics. We observe high agreement in binary judgments across different largelanguage models (LLMs) when objective reference answers exist, which challengesthe necessity of large-scale annotation for training domain-specific rewardmodels. To address the limitations of binary rewards when handling unstructuredreference answers, we further incorporate model-based soft scoring into RLVR toimprove its flexibility. Our experiments show that a distilled generativereward model can serve as an effective cross-domain verifier, providingreliable reward signals for RL without requiring domain-specific annotations.By fine-tuning a base 7B model using various RL algorithms against our rewardmodel, we obtain policies that outperform state-of-the-art open-source alignedLLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a largemargin, across domains in free-form answer settings. This also strengthensRLVR's robustness and scalability, highlighting its potential for real-worldapplications with noisy or weak labels.
  </details>

- **[Adaptive Layer-skipping in Pre-trained LLMs](http://arxiv.org/abs/2503.23798v1)**  `arXiv:2503.23798`  `cs.CL` `cs.AI`  
  _Xuan Luo, Weizhi Wang, Xifeng Yan_
  <details open><summary>Abstract</summary>
  Various layer-skipping methods have been proposed to accelerate tokengeneration in large language models (LLMs). However, they have overlooked afundamental question: How do computational demands vary across the generationof different tokens? In this work, we introduce FlexiDepth, a method thatdynamically adjusts the number of Transformer layers used in text generation.By incorporating a plug-in router and adapter, FlexiDepth enables adaptivelayer-skipping in LLMs without modifying their original parameters. IntroducingFlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32,and meanwhile maintains the full 100\% benchmark performance. Experimentalresults with FlexiDepth demonstrate that computational demands in LLMssignificantly vary based on token type. Specifically, generating repetitivetokens or fixed phrases requires fewer layers, whereas producing tokensinvolving computation or high uncertainty requires more layers. Interestingly,this adaptive allocation pattern aligns with human intuition. To advanceresearch in this area, we open sourced FlexiDepth and a dataset documentingFlexiDepth's layer allocation patterns for future exploration.
  </details>

- **[DebFlow: Automating Agent Creation via Agent Debate](http://arxiv.org/abs/2503.23781v1)**  `arXiv:2503.23781`  `cs.AI`  
  _Jinwei Su, Yinghui Xia, Ronghua Shi, Jianhui Wang, Jianuo Huang, Yijin Wang, et al._
  <details open><summary>Abstract</summary>
  Large language models (LLMs) have demonstrated strong potential andimpressive performance in automating the generation and optimization ofworkflows. However, existing approaches are marked by limited reasoningcapabilities, high computational demands, and significant resourcerequirements. To address these issues, we propose DebFlow, a framework thatemploys a debate mechanism to optimize workflows and integrates reflexion toimprove based on previous experiences. We evaluated our method across sixbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approachachieved a 3\% average performance improvement over the latest baselines,demonstrating its effectiveness in diverse problem domains. In particular,during training, our framework reduces resource consumption by 37\% compared tothe state-of-the-art baselines. Additionally, we performed ablation studies.Removing the Debate component resulted in a 4\% performance drop across twobenchmark datasets, significantly greater than the 2\% drop observed when theReflection component was removed. These findings strongly demonstrate thecritical role of Debate in enhancing framework performance, while alsohighlighting the auxiliary contribution of reflexion to overall optimization.
  </details>

- **[WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with Common Sense Categorization](http://arxiv.org/abs/2503.23779v1)**  `arXiv:2503.23779`  `cs.CL` `cs.AI`  
  _Ine Gevers, Victor De Marez, Luna De Bruyne, Walter Daelemans_
  <details open><summary>Abstract</summary>
  In this study, we take a closer look at how Winograd schema challenges can beused to evaluate common sense reasoning in LLMs. Specifically, we evaluategenerative models of different sizes on the popular WinoGrande benchmark. Werelease WinoWhat, a new corpus, in which each instance of the WinoGrandevalidation set is paraphrased. Additionally, we evaluate the performance on thechallenge across five common sense knowledge categories, giving morefine-grained insights on what types of knowledge are more challenging for LLMs.Surprisingly, all models perform significantly worse on WinoWhat, implying thatLLM reasoning capabilities are overestimated on WinoGrande. To verify whetherthis is an effect of benchmark memorization, we match benchmark instances toLLM trainingdata and create two test-suites. We observe that memorization has aminimal effect on model performance on WinoGrande.
  </details>

- **[CONGRAD:Conflicting Gradient Filtering for Multilingual Preference Alignment](http://arxiv.org/abs/2503.23777v1)**  `arXiv:2503.23777`  `cs.CL`  
  _Jiangnan Li, Thuy-Trang Vu, Christian Herold, Amirhossein Tebbifakhr, Shahram Khadivi, Gholamreza Haffari_
  <details open><summary>Abstract</summary>
  Naive joint training of large language models (LLMs) for multilingualpreference alignment can suffer from negative interference. This is a knownissue in multilingual training, where conflicting objectives degrade overallperformance. However, the impact of this phenomenon in the context ofmultilingual preference alignment remains largely underexplored. To addressthis issue, we propose CONGRAD, a scalable and effective filtering method thatselects high-quality preference samples with minimal gradient conflicts acrosslanguages. Our method leverages gradient surgery to retain samples aligned withan aggregated multilingual update direction. Additionally, we incorporate asublinear gradient compression strategy that reduces memory overhead duringgradient accumulation. We integrate CONGRAD into self-rewarding framework andevaluate on LLaMA3-8B and Gemma2-2B across 10 languages. Results show thatCONGRAD consistently outperforms strong baselines in both seen and unseenlanguages, with minimal alignment tax.
  </details>

- **[XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery?](http://arxiv.org/abs/2503.23771v1)**  `arXiv:2503.23771`  `cs.CV`  
  _Fengxiang Wang, Hongzhen Wang, Mingshuo Chen, Di Wang, Yulin Wang, Zonghao Guo, et al._
  <details open><summary>Abstract</summary>
  The astonishing breakthrough of multimodal large language models (MLLMs) hasnecessitated new benchmarks to quantitatively assess their capabilities, revealtheir limitations, and indicate future research directions. However, this ischallenging in the context of remote sensing (RS), since the imagery featuresultra-high resolution that incorporates extremely complex semanticrelationships. Existing benchmarks usually adopt notably smaller image sizesthan real-world RS scenarios, suffer from limited annotation quality, andconsider insufficient dimensions of evaluation. To address these issues, wepresent XLRS-Bench: a comprehensive benchmark for evaluating the perception andreasoning capabilities of MLLMs in ultra-high-resolution RS scenarios.XLRS-Bench boasts the largest average image size (8500$\times$8500) observedthus far, with all evaluation samples meticulously annotated manually, assistedby a novel semi-automatic captioner on ultra-high-resolution RS images. On topof the XLRS-Bench, 16 sub-tasks are defined to evaluate MLLMs' 10 kinds ofperceptual capabilities and 6 kinds of reasoning capabilities, with a primaryemphasis on advanced cognitive processes that facilitate real-worlddecision-making and the capture of spatiotemporal changes. The results of bothgeneral and RS-focused MLLMs on XLRS-Bench indicate that further efforts areneeded for real-world RS applications. We have open-sourced XLRS-Bench tosupport further research in developing more powerful MLLMs for remote sensing.
  </details>

- **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v1)**  `arXiv:2503.23765`  `cs.CV`  
  _Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, et al._
  <details open><summary>Abstract</summary>
  The use of Multimodal Large Language Models (MLLMs) as an end-to-end solutionfor Embodied AI and Autonomous Driving has become a prevailing trend. WhileMLLMs have been extensively studied for visual semantic understanding tasks,their ability to perform precise and quantitative spatial-temporalunderstanding in real-world applications remains largely unexamined, leading touncertain prospects. To evaluate models' Spatial-Temporal Intelligence, weintroduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporalunderstanding through challenging tasks such as estimating and predicting theappearance, pose, displacement, and motion of objects. Our benchmarkencompasses a wide range of robot and vehicle operations across desktop,indoor, and outdoor scenarios. The extensive experiments reveals that thestate-of-the-art MLLMs still struggle in real-world spatial-temporalunderstanding, especially in tasks requiring precise distance estimation andmotion analysis.
  </details>

- **[LANID: LLM-assisted New Intent Discovery](http://arxiv.org/abs/2503.23740v1)**  `arXiv:2503.23740`  `cs.CL` `cs.AI`  
  _Lu Fan, Jiashu Pu, Rongsheng Zhang, Xiao-Ming Wu_
  <details open><summary>Abstract</summary>
  Task-oriented Dialogue Systems (TODS) often face the challenge ofencountering new intents. New Intent Discovery (NID) is a crucial task thataims to identify these novel intents while maintaining the capability torecognize existing ones. Previous efforts to adapt TODS to new intents havestruggled with inadequate semantic representation or have depended on externalknowledge, which is often not scalable or flexible. Recently, Large LanguageModels (LLMs) have demonstrated strong zero-shot capabilities; however, theirscale can be impractical for real-world applications that involve extensivequeries. To address the limitations of existing NID methods by leveraging LLMs,we propose LANID, a framework that enhances the semantic representation oflightweight NID encoders with the guidance of LLMs. Specifically, LANID employsthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applicationswith Noise (DBSCAN) algorithms to sample selective utterance pairs from thetraining set. It then queries an LLM to ascertain the relationships betweenthese pairs. The data produced from this process is utilized to design acontrastive fine-tuning task, which is then used to train a small encoder witha contrastive triplet loss. Our experimental results demonstrate the efficacyof the proposed method across three distinct NID datasets, surpassing strongbaselines in both unsupervised and semi-supervised settings. Our code isavailable at https://github.com/floatSDSDS/LANID.
  </details>

- **[AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization](http://arxiv.org/abs/2503.23733v1)**  `arXiv:2503.23733`  `cs.CV` `cs.CL`  
  _Yiyang Du, Xiaochen Wang, Chi Chen, Jiabo Ye, Yiru Wang, Peng Li, et al._
  <details open><summary>Abstract</summary>
  Recently, model merging methods have demonstrated powerful strengths incombining abilities on various tasks from multiple Large Language Models(LLMs). While previous model merging methods mainly focus on merginghomogeneous models with identical architecture, they meet challenges whendealing with Multimodal Large Language Models (MLLMs) with inherentheterogeneous property, including differences in model architecture and theasymmetry in the parameter space. In this work, we propose AdaMMS, a novelmodel merging method tailored for heterogeneous MLLMs. Our method tackles thechallenges in three steps: mapping, merging and searching. Specifically, wefirst design mapping function between models to apply model merging on MLLMswith different architecture. Then we apply linear interpolation on modelweights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally inthe hyper-parameter searching step, we propose an unsupervised hyper-parameterselection method for model merging. As the first model merging method capableof merging heterogeneous MLLMs without labeled data, extensive experiments onvarious model combinations demonstrated that AdaMMS outperforms previous modelmerging methods on various vision-language benchmarks.
  </details>

- **[HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video Generation](http://arxiv.org/abs/2503.23715v1)**  `arXiv:2503.23715`  `cs.CV`  
  _Kun Liu, Qi Liu, Xinchen Liu, Jie Li, Yongdong Zhang, Jiebo Luo, et al._
  <details open><summary>Abstract</summary>
  Text-to-video (T2V) generation has made tremendous progress in generatingcomplicated scenes based on texts. However, human-object interaction (HOI)often cannot be precisely generated by current T2V models due to the lack oflarge-scale videos with accurate captions for HOI. To address this issue, weintroduce HOIGen-1M, the first largescale dataset for HOI Generation,consisting of over one million high-quality videos collected from diversesources. In particular, to guarantee the high quality of videos, we firstdesign an efficient framework to automatically curate HOI videos using thepowerful multimodal large language models (MLLMs), and then the videos arefurther cleaned by human annotators. Moreover, to obtain accurate textualcaptions for HOI videos, we design a novel video description method based on aMixture-of-Multimodal-Experts (MoME) strategy that not only generatesexpressive captions but also eliminates the hallucination by individual MLLM.Furthermore, due to the lack of an evaluation framework for generated HOIvideos, we propose two new metrics to assess the quality of generated videos ina coarse-to-fine manner. Extensive experiments reveal that current T2V modelsstruggle to generate high-quality HOI videos and confirm that our HOIGen-1Mdataset is instrumental for improving HOI video generation. Project webpage isavailable at https://liuqi-creat.github.io/HOIGen.github.io.
  </details>

- **[Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models](http://arxiv.org/abs/2503.23714v1)**  `arXiv:2503.23714`  `cs.CL`  
  _Youmi Ma, Sakae Mizuki, Kazuki Fujii, Taishi Nakamura, Masanari Ohi, Hinari Shimada, et al._
  <details open><summary>Abstract</summary>
  Instruction tuning is crucial for enabling Large Language Models (LLMs) tosolve real-world tasks. Prior work has shown the effectiveness ofinstruction-tuning data synthesized solely from LLMs, raising a fundamentalquestion: Do we still need human-originated signals for instruction tuning?This work answers the question affirmatively: we build state-of-the-artinstruction-tuning datasets sourced from human-written instructions, by simplypairing them with LLM-generated responses. LLMs fine-tuned on our datasetsconsistently outperform those fine-tuned on existing ones. Our dataconstruction approach can be easily adapted to other languages; we builddatasets for Japanese and confirm that LLMs tuned with our data reachstate-of-the-art performance. Analyses suggest that instruction-tuning in a newlanguage allows LLMs to follow instructions, while the tuned models exhibit anotable lack of culture-specific knowledge in that language. The datasets andfine-tuned models will be publicly available. Our datasets, synthesized withopen-weight LLMs, are openly distributed under permissive licenses, allowingfor diverse use cases.
  </details>

- **[MKA: Leveraging Cross-Lingual Consensus for Model Abstention](http://arxiv.org/abs/2503.23687v1)**  `arXiv:2503.23687`  `cs.LG` `cs.CL`  
  _Sharad Duwal_
  <details open><summary>Abstract</summary>
  Reliability of LLMs is questionable even as they get better at more tasks. Awider adoption of LLMs is contingent on whether they are usably factual. And ifthey are not, on whether they can properly calibrate their confidence in theirresponses. This work focuses on utilizing the multilingual knowledge of an LLMto inform its decision to abstain or answer when prompted. We develop amultilingual pipeline to calibrate the model's confidence and let it abstainwhen uncertain. We run several multilingual models through the pipeline toprofile them across different languages. We find that the performance of thepipeline varies by model and language, but that in general they benefit fromit. This is evidenced by the accuracy improvement of $71.2\%$ for Bengali overa baseline performance without the pipeline. Even a high-resource language likeEnglish sees a $15.5\%$ improvement. These results hint at possible furtherimprovements.
  </details>

- **[WHERE and WHICH: Iterative Debate for Biomedical Synthetic Data Augmentation](http://arxiv.org/abs/2503.23673v1)**  `arXiv:2503.23673`  `cs.CL`  
  _Zhengyi Zhao, Shubo Zhang, Bin Liang, Binyang Li, Kam-Fai Wong_
  <details open><summary>Abstract</summary>
  In Biomedical Natural Language Processing (BioNLP) tasks, such as RelationExtraction, Named Entity Recognition, and Text Classification, the scarcity ofhigh-quality data remains a significant challenge. This limitation poisonslarge language models to correctly understand relationships between biologicalentities, such as molecules and diseases, or drug interactions, and furtherresults in potential misinterpretation of biomedical documents. To address thisissue, current approaches generally adopt the Synthetic Data Augmentationmethod which involves similarity computation followed by word replacement, butcounterfactual data are usually generated. As a result, these methods disruptmeaningful word sets or produce sentences with meanings that deviatesubstantially from the original context, rendering them ineffective inimproving model performance. To this end, this paper proposes abiomedical-dedicated rationale-based synthetic data augmentation method. Beyondthe naive lexicon similarity, specific bio-relation similarity is measured tohold the augmented instance having a strong correlation with bio-relationinstead of simply increasing the diversity of augmented data. Moreover, amulti-agents-involved reflection mechanism helps the model iterativelydistinguish different usage of similar entities to escape falling into themis-replace trap. We evaluate our method on the BLURB and BigBIO benchmark,which includes 9 common datasets spanning four major BioNLP tasks. Ourexperimental results demonstrate consistent performance improvements across alltasks, highlighting the effectiveness of our approach in addressing thechallenges associated with data scarcity and enhancing the overall performanceof biomedical NLP models.
  </details>

- **[MolGround: A Benchmark for Molecular Grounding](http://arxiv.org/abs/2503.23668v1)**  `arXiv:2503.23668`  `cs.AI`  
  _Jiaxin Wu, Ting Zhang, Rubing Chen, Wengyu Zhang, Chen Jason Zhang, Xiaoyong Wei, et al._
  <details open><summary>Abstract</summary>
  Current molecular understanding approaches predominantly focus on thedescriptive aspect of human perception, providing broad, topic-level insights.However, the referential aspect -- linking molecular concepts to specificstructural components -- remains largely unexplored. To address this gap, wepropose a molecular grounding benchmark designed to evaluate a model'sreferential abilities. We align molecular grounding with establishedconventions in NLP, cheminformatics, and molecular science, showcasing thepotential of NLP techniques to advance molecular understanding within the AIfor Science movement. Furthermore, we constructed the largest molecularunderstanding benchmark to date, comprising 79k QA pairs, and developed amulti-agent grounding prototype as proof of concept. This system outperformsexisting models, including GPT-4o, and its grounding outputs have beenintegrated to enhance traditional tasks such as molecular captioning and ATC(Anatomical, Therapeutic, Chemical) classification.
  </details>

- **[Context-Independent OCR with Multimodal LLMs: Effects of Image Resolution and Visual Complexity](http://arxiv.org/abs/2503.23667v1)**  `arXiv:2503.23667`  `cs.CV`  
  _Kotaro Inoue_
  <details open><summary>Abstract</summary>
  Due to their high versatility in tasks such as image captioning, documentanalysis, and automated content generation, multimodal Large Language Models(LLMs) have attracted significant attention across various industrial fields.In particular, they have been shown to surpass specialized models in OpticalCharacter Recognition (OCR). Nevertheless, their performance under differentimage conditions remains insufficiently investigated, and individual characterrecognition is not guaranteed due to their reliance on contextual cues. In thiswork, we examine a context-independent OCR task using single-character imageswith diverse visual complexities to determine the conditions for accuraterecognition. Our findings reveal that multimodal LLMs can match conventionalOCR methods at about 300 ppi, yet their performance deteriorates significantlybelow 150 ppi. Additionally, we observe a very weak correlation between visualcomplexity and misrecognitions, whereas a conventional OCR-specific modelexhibits no correlation. These results suggest that image resolution and visualcomplexity may play an important role in the reliable application of multimodalLLMs to OCR tasks that require precise character-level accuracy.
  </details>

- **[DeepDubber-V1: Towards High Quality and Dialogue, Narration, Monologue Adaptive Movie Dubbing Via Multi-Modal Chain-of-Thoughts Reasoning Guidance](http://arxiv.org/abs/2503.23660v1)**  `arXiv:2503.23660`  `cs.CV`  
  _Junjie Zheng, Zihao Chen, Chaofan Ding, Xinhan Di_
  <details open><summary>Abstract</summary>
  Current movie dubbing technology can generate the desired voice from a givenspeech prompt, ensuring good synchronization between speech and visuals whileaccurately conveying the intended emotions. However, in movie dubbing, keyaspects such as adapting to different dubbing styles, handling dialogue,narration, and monologue effectively, and understanding subtle details like theage and gender of speakers, have not been well studied. To address thischallenge, we propose a framework of multi-modal large language model. First,it utilizes multimodal Chain-of-Thought (CoT) reasoning methods on visualinputs to understand dubbing styles and fine-grained attributes. Second, itgenerates high-quality dubbing through large speech generation models, guidedby multimodal conditions. Additionally, we have developed a movie dubbingdataset with CoT annotations. The evaluation results demonstrate a performanceimprovement over state-of-the-art methods across multiple datasets. Inparticular, for the evaluation metrics, the SPK-SIM and EMO-SIM increases from82.48% to 89.74%, 66.24% to 78.88% for dubbing setting 2.0 on V2C Animationdataset, LSE-D and MCD-SL decreases from 14.79 to 14.63, 5.24 to 4.74 fordubbing setting 2.0 on Grid dataset, SPK-SIM increases from 64.03 to 83.42 andWER decreases from 52.69% to 23.20% for initial reasoning setting on proposedCoT-Movie-Dubbing dataset in the comparison with the state-of-the art models.
  </details>

- **[Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning](http://arxiv.org/abs/2503.22456v2)**  `arXiv:2503.22456`  `cs.LG` `cs.AI`  
  _Abdullah Vanlioglu_
  <details open><summary>Abstract</summary>
  We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach thatenhances the exploration-exploitation tradeoff by dynamically assigning weightsto generated outputs based on their advantage and entropy for ReinforcementLearning-based Large Language Model fine-tuning. EGSW integrates entropyregularization with advantage-based weighting to balance policy updates,enabling efficient exploration in high-dimensional state spaces. By employingtemperature-scaled softmax weighting over sequences, EGSW prioritizinghigh-reward, high-uncertainty steps while maintaining training stability.Although originally developed to improve Group Relative Policy Optimization(GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable toother reinforcement learning (RL) algorithms and can be implemented in bothstep-wise and trajectory-wise settings. Empirical evaluations demonstrate thatEGSW enhances GRPO reasoning ability, yielding improvements in sampleefficiency. Future work will explore the application of EGSW to advanced RLmethodologies.
  </details>

- **[Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback](http://arxiv.org/abs/2503.22230v2)**  `arXiv:2503.22230`  `cs.LG`  
  _Wei Shen, Guanlin Liu, Zheng Wu, Ruofei Zhu, Qingping Yang, Chao Xin, et al._
  <details open><summary>Abstract</summary>
  Reinforcement Learning from Human Feedback (RLHF) is crucial for aligninglarge language models with human preferences. While recent research has focusedon algorithmic improvements, the importance of prompt-data construction hasbeen overlooked. This paper addresses this gap by exploring data-drivenbottlenecks in RLHF performance scaling, particularly reward hacking anddecreasing response diversity. We introduce a hybrid reward system combiningreasoning task verifiers (RTV) and a generative reward model (GenRM) tomitigate reward hacking. We also propose a novel prompt-selection method,Pre-PPO, to maintain response diversity and enhance learning effectiveness.Additionally, we find that prioritizing mathematical and coding tasks early inRLHF training significantly improves performance. Experiments across two modelsizes validate our methods' effectiveness and scalability. Results show thatRTV is most resistant to reward hacking, followed by GenRM with ground truth,and then GenRM with SFT Best-of-N responses. Our strategies enable rapidcapture of subtle task-specific distinctions, leading to substantialimprovements in overall RLHF performance. This work highlights the importanceof careful data construction and provides practical methods to overcomeperformance barriers in RLHF.
  </details>

- **[EQ-Negotiator: An Emotion-Reasoning LLM Agent in Credit Dialogues](http://arxiv.org/abs/2503.21080v3)**  `arXiv:2503.21080`  `cs.CL`  
  _Yuhan Liu, Yunbo Long_
  <details open><summary>Abstract</summary>
  While large language model (LLM)-based chatbots have been applied foreffective engagement in credit dialogues, their capacity for dynamic emotionalexpression remains limited. Current agents primarily rely on passive empathyrather than affective reasoning. For instance, when faced with persistentclient negativity, the agent should employ strategic emotional adaptation byexpressing measured anger to discourage counterproductive behavior and guidethe conversation toward resolution. This context-aware emotional modulation isessential for imitating the nuanced decision-making of human negotiators. Thispaper introduces an EQ-negotiator that combines emotion sensing frompre-trained language models (PLMs) with emotional reasoning based on GameTheory and Hidden Markov Models. It takes into account both the current andhistorical emotions of the client to better manage and address negativeemotions during interactions. By fine-tuning pre-trained language models (PLMs)on public emotion datasets and validating them on the credit dialogue datasets,our approach enables LLM-based agents to effectively capture shifts in clientemotions and dynamically adjust their response tone based on our emotiondecision policies in real-world financial negotiations. This EQ-negotiator canalso help credit agencies foster positive client relationships, enhancingsatisfaction in credit services.
  </details>

- **[Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping](http://arxiv.org/abs/2503.21817v2)**  `arXiv:2503.21817`  `cs.CV`  
  _Weili Zeng, Ziyuan Huang, Kaixiang Ji, Yichao Yan_
  <details open><summary>Abstract</summary>
  Transformer-based models have driven significant advancements in MultimodalLarge Language Models (MLLMs), yet their computational costs surge drasticallywhen scaling resolution, training data, and model parameters. A key bottleneckstems from the proliferation of visual tokens required for fine-grained imageunderstanding. We propose Skip-Vision, a unified framework addressing bothtraining and inference inefficiencies in vision-language models. On top ofconventional token compression approaches, our method introduces twocomplementary acceleration strategies. For training acceleration, we observethat Feed-Forward Network (FFN) computations on visual tokens induce marginalfeature updates. This motivates our Skip-FFN strategy, which bypasses FFNlayers for redundant visual tokens. For inference acceleration, we design aselective KV-cache removal mechanism that prunes the skipped key-value pairsduring decoding while preserving model performance. Experimental resultsdemonstrate that Skip-Vision reduces training time by up to 35\%, inferenceFLOPs by 75\%, and latency by 45\%, while achieving comparable or superiorperformance to existing methods. Our work provides a practical solution forscaling high-performance MLLMs with enhanced efficiency.
  </details>

- **[Surgical Action Planning with Large Language Models](http://arxiv.org/abs/2503.18296v2)**  `arXiv:2503.18296`  `cs.CL`  
  _Mengya Xu, Zhongzhen Huang, Jie Zhang, Xiaofan Zhang, Qi Dou_
  <details open><summary>Abstract</summary>
  In robot-assisted minimally invasive surgery, we introduce the SurgicalAction Planning (SAP) task, which generates future action plans from visualinputs to address the absence of intraoperative predictive planning in currentintelligent applications. SAP shows great potential for enhancingintraoperative guidance and automating procedures. However, it faces challengessuch as understanding instrument-action relationships and tracking surgicalprogress. Large Language Models (LLMs) show promise in understanding surgicalvideo content but remain underexplored for predictive decision-making in SAP,as they focus mainly on retrospective analysis. Challenges like data privacy,computational demands, and modality-specific constraints further highlightsignificant research gaps. To tackle these challenges, we introduce LLM-SAP, aLarge Language Models-based Surgical Action Planning framework that predictsfuture actions and generates text responses by interpreting natural languageprompts of surgical goals. The text responses potentially support surgicaleducation, intraoperative decision-making, procedure documentation, and skillanalysis. LLM-SAP integrates two novel modules: the Near-History Focus MemoryModule (NHF-MM) for modeling historical states and the prompts factory foraction planning. We evaluate LLM-SAP on our constructed CholecT50-SAP datasetusing models like Qwen2.5 and Qwen2-VL, demonstrating its effectiveness innext-action prediction. Pre-trained LLMs are tested in a zero-shot setting, andsupervised fine-tuning (SFT) with LoRA is implemented. Our experiments showthat Qwen2.5-72B-SFT surpasses Qwen2.5-72B with a 19.3% higher accuracy.
  </details>

- **[TablePilot: Recommending Human-Preferred Tabular Data Analysis with Large Language Models](http://arxiv.org/abs/2503.13262v4)**  `arXiv:2503.13262`  `cs.CL`  
  _Deyin Yi, Yihao Liu, Lang Cao, Mengyu Zhou, Haoyu Dong, Shi Han, et al._
  <details open><summary>Abstract</summary>
  Tabular data analysis is crucial in many scenarios, yet efficientlyidentifying the most relevant data analysis queries and results for a new tableremains a significant challenge. The complexity of tabular data, diverseanalytical operations, and the demand for high-quality analysis make theprocess tedious. To address these challenges, we aim to recommendquery-code-result triplets tailored for new tables in tabular data analysisworkflows. In this paper, we present TablePilot, a pioneering tabular dataanalysis framework leveraging large language models to autonomously generatecomprehensive and superior analytical results without relying on user profilesor prior interactions. The framework incorporates key designs in analysispreparation and analysis optimization to enhance accuracy. Additionally, wepropose Rec-Align, a novel method to further improve recommendation quality andbetter align with human preferences. Experiments on DART, a datasetspecifically designed for comprehensive tabular data analysis recommendation,demonstrate the effectiveness of our framework. Based on GPT-4o, the tunedTablePilot achieves 77.0% top-5 recommendation recall. Human evaluationsfurther highlight its effectiveness in optimizing tabular data analysisworkflows.
  </details>

- **[Will Pre-Training Ever End? A First Step Toward Next-Generation Foundation MLLMs via Self-Improving Systematic Cognition](http://arxiv.org/abs/2503.12303v5)**  `arXiv:2503.12303`  `cs.CV`  
  _Xiaoying Zhang, Da Peng, Yipeng Zhang, Zonghao Guo, Chengyue Wu, Chi Chen, et al._
  <details open><summary>Abstract</summary>
  Recent progress in (multimodal) large language models ((M)LLMs) has shiftedfocus from pre-training to inference-time compute scaling and post-trainingoptimization, driven by concerns over limited high-quality real-world data.However, these strategies alone are insufficient for advancing modelcapabilities. We hypothesize that effective model improvement requires a strongsynergy among pre-training, inference-time compute scaling, and post-trainingoptimization. In this paper, we validate this hypothesis in the context ofmultimodal pre-training for foundation MLLM construction. We introduceSelf-Improving cognition (SIcog), a self-learning framework for constructingnext-generation foundation MLLMs by imparting multimodal knowledge andenhancing their systematic cognitive capabilities through multimodalpre-training with self-generated data. Specifically, we introduceChain-of-Description, a step-by-step visual understanding method to improvecomprehensive perception, and integrate structured chain-of-thought (CoT)reasoning to support in-depth multimodal reasoning. SIcog first equips a basemodel with systematic perception and reasoning using minimal externalsupervision. The enhanced model then generates candidate image captions andCoT-style reasoning responses for unlabeled images and image-question pairsacross diverse tasks, which are curated through a self-consistency mechanism.These curated samples are subsequently used for large-scale multimodalpre-training, completing a self-learning cycle that strengthens the model'scognitive foundation. Extensive experiments demonstrate that SIcog producesnext-generation foundation MLLMs with substantially improved multimodalcognition, outperforming prevailing pre-training approaches. These findingsempirically establish SIcog as a promising framework for realizing a completeself-improving paradigm.
  </details>

- **[DCAD-2000: A Multilingual Dataset across 2000+ Languages with Data Cleaning as Anomaly Detection](http://arxiv.org/abs/2502.11546v2)**  `arXiv:2502.11546`  `cs.CL`  
  _Yingli Shen, Wen Lai, Shuo Wang, Xueren Zhang, Kangyang Luo, Alexander Fraser, et al._
  <details open><summary>Abstract</summary>
  The rapid development of multilingual large language models (LLMs) highlightsthe need for high-quality, diverse, and clean multilingual datasets. In thispaper, we introduce DCAD-2000 (Data Cleaning as Anomaly Detection), alarge-scale multilingual corpus built using newly extracted Common Crawl dataand existing multilingual datasets. DCAD-2000 includes over 2,282 languages,46.72TB of data, and 8.63 billion documents, spanning 155 high- andmedium-resource languages and 159 writing scripts. To overcome the limitationsof current data cleaning methods, which rely on manual heuristic thresholds, wepropose reframing data cleaning as an anomaly detection task. This dynamicfiltering approach significantly enhances data quality by identifying andremoving noisy or anomalous content. We evaluate the quality of DCAD-2000 onthe FineTask benchmark, demonstrating substantial improvements in multilingualdataset quality and task performance.
  </details>

- **[PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models](http://arxiv.org/abs/2502.01584v3)**  `arXiv:2502.01584`  `cs.LG` `cs.AI`  
  _Zixuan Wu, Francesca Lucchetti, Aleksander Boruch-Gruszecki, Jingmiao Zhao, Carolyn Jane Anderson, Joydeep Biswas, et al._
  <details open><summary>Abstract</summary>
  Existing benchmarks for frontier models often test specialized, "PhD-level"knowledge that is difficult for non-experts to grasp. In contrast, we present abenchmark with 594 problems based on the NPR Sunday Puzzle Challenge thatrequires only general knowledge. Our benchmark is challenging for both humansand models; however correct solutions are easy to verify, and models' mistakesare easy to spot. As LLMs are more widely deployed in society, we believe it isuseful to develop benchmarks for frontier models that humans can understandwithout the need for deep domain expertise.  Our work reveals capability gaps that are not evident in existing benchmarks:OpenAI o1 significantly outperforms other reasoning models on our benchmark,despite being on par with other models when tested on benchmarks that testspecialized knowledge. Furthermore, our analysis of reasoning outputs uncoversnew kinds of failures. DeepSeek R1, for instance, often concedes with "I giveup" before providing an answer that it knows is wrong. R1 can also beremarkably "uncertain" in its output and in rare cases, it does not "finishthinking," which suggests the need for techniques to "wrap up" before thecontext window limit is reached. We also quantify the effectiveness ofreasoning longer to identify the point beyond which more reasoning is unlikelyto improve accuracy on our benchmark.
  </details>

- **[Know "No'' Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP](http://arxiv.org/abs/2501.10913v2)**  `arXiv:2501.10913`  `cs.CV` `cs.CL`  
  _Junsung Park, Jungbeom Lee, Jongyoon Song, Sangwon Yu, Dahuin Jung, Sungroh Yoon_
  <details open><summary>Abstract</summary>
  While CLIP has significantly advanced multimodal understanding by bridgingvision and language, the inability to grasp negation - such as failing todifferentiate concepts like "parking" from "no parking" - poses substantialchallenges. By analyzing the data used in the public CLIP model's pre-training,we posit this limitation stems from a lack of negation-inclusive data. Toaddress this, we introduce data generation pipelines that employ a largelanguage model (LLM) and a multimodal LLM to produce negation-inclusivecaptions. Fine-tuning CLIP with data generated from our pipelines, we developNegationCLIP, which enhances negation awareness while preserving thegenerality. Moreover, to enable a comprehensive evaluation of negationunderstanding, we propose NegRefCOCOg-a benchmark tailored to test VLMs'ability to interpret negation across diverse expressions and positions within asentence. Experiments on various CLIP architectures validate the effectivenessof our data generation pipelines in enhancing CLIP's ability to perceivenegation accurately. Additionally, NegationCLIP's enhanced negation awarenesshas practical applications across various multimodal tasks, demonstrated byperformance gains in text-to-image generation and referring image segmentation.
  </details>

- **[EmoVerse: Exploring Multimodal Large Language Models for Sentiment and Emotion Understanding](http://arxiv.org/abs/2412.08049v3)**  `arXiv:2412.08049`  `cs.CL`  
  _Ao Li, Longwei Xu, Chen Ling, Jinghui Zhang, Pengwei Wang_
  <details open><summary>Abstract</summary>
  Sentiment and emotion understanding are essential to applications such ashuman-computer interaction and depression detection. While Multimodal LargeLanguage Models (MLLMs) demonstrate robust general capabilities, they faceconsiderable challenges in the field of affective computing, particularly indetecting subtle facial expressions and handling complex emotion-related tasks,such as emotion reason inference and understanding emotions in long-contextscenarios. Furthermore, there is a lack of a unified MLLM that can effectivelyhandle both sentiment and emotion-related tasks. To address these challenges,we explore multi-task training strategies for MLLMs in affective computing andintroduce Emotion Universe (EmoVerse), an MLLM designed to handle a broadspectrum of sentiment and emotion-related tasks. In addition, EmoVerse iscapable of deeply analyzing the underlying causes of emotional states. We alsointroduce the Affective Multitask (AMT) Dataset, which supports multimodalsentiment analysis, multimodal emotion recognition, facial expressionrecognition, emotion reason inference, and emotion cause-pair extraction tasks.Extensive experiments demonstrate that EmoVerse outperforms existing methods,achieving state-of-the-art results in sentiment and emotion-related tasks. Thecode is available at https://github.com/liaolea/EmoVerse.
  </details>

- **[Truth or Mirage? Towards End-to-End Factuality Evaluation with LLM-Oasis](http://arxiv.org/abs/2411.19655v3)**  `arXiv:2411.19655`  `cs.CL`  
  _Alessandro Scir√®, Andrei Stefan Bejgu, Simone Tedeschi, Karim Ghonim, Federico Martelli, Roberto Navigli_
  <details open><summary>Abstract</summary>
  After the introduction of Large Language Models (LLMs), there have beensubstantial improvements in the performance of Natural Language Generation(NLG) tasks, including Text Summarization and Machine Translation. However,LLMs still produce outputs containing hallucinations, that is, content notgrounded in factual information. Therefore, developing methods to assess thefactuality of LLMs has become urgent.  Indeed, resources for factuality evaluation have recently emerged. Althoughchallenging, these resources face one or more of the following limitations: (i)they are tailored to a specific task or domain; (ii) they are limited in size,thereby preventing the training of new factuality evaluators; (iii) they aredesigned for simpler verification tasks, such as claim verification.  To address these issues, we introduce LLM-Oasis, to the best of our knowledgethe largest resource for training end-to-end factuality evaluators. LLM-Oasisis constructed by extracting claims from Wikipedia, falsifying a subset ofthese claims, and generating pairs of factual and unfactual texts. We then relyon human annotators to both validate the quality of our dataset and to create agold standard test set for benchmarking factuality evaluation systems.  Our experiments demonstrate that LLM-Oasis presents a significant challengefor state-of-the-art LLMs, with GPT-4o achieving up to 60% accuracy in ourproposed end-to-end factuality evaluation task, highlighting its potential todrive future research in the field.
  </details>

- **[HyperGLM: HyperGraph for Video Scene Graph Generation and Anticipation](http://arxiv.org/abs/2411.18042v2)**  `arXiv:2411.18042`  `cs.CV`  
  _Trong-Thuan Nguyen, Pha Nguyen, Jackson Cothren, Alper Yilmaz, Khoa Luu_
  <details open><summary>Abstract</summary>
  Multimodal LLMs have advanced vision-language tasks but still struggle withunderstanding video scenes. To bridge this gap, Video Scene Graph Generation(VidSGG) has emerged to capture multi-object relationships across video frames.However, prior methods rely on pairwise connections, limiting their ability tohandle complex multi-object interactions and reasoning. To this end, we proposeMultimodal LLMs on a Scene HyperGraph (HyperGLM), promoting reasoning aboutmulti-way interactions and higher-order relationships. Our approach uniquelyintegrates entity scene graphs, which capture spatial relationships betweenobjects, with a procedural graph that models their causal transitions, forminga unified HyperGraph. Significantly, HyperGLM enables reasoning by injectingthis unified HyperGraph into LLMs. Additionally, we introduce a new Video SceneGraph Reasoning (VSGR) dataset featuring 1.9M frames from third-person,egocentric, and drone views and supports five tasks: Scene Graph Generation,Scene Graph Anticipation, Video Question Answering, Video Captioning, andRelation Reasoning. Empirically, HyperGLM consistently outperformsstate-of-the-art methods across five tasks, effectively modeling and reasoningcomplex relationships in diverse video scenes.
  </details>

- **[How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?](http://arxiv.org/abs/2411.03962v5)**  `arXiv:2411.03962`  `cs.CL`  
  _Zhangcheng Qiang, Kerry Taylor, Weiqing Wang_
  <details open><summary>Abstract</summary>
  The classic text preprocessing pipeline, comprising Tokenisation,Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has beenimplemented in many systems for syntactic ontology matching (OM). However, thelack of standardisation in text preprocessing creates diversity in mappingresults. In this paper we investigate the effect of the text preprocessingpipeline on syntactic OM in 8 Ontology Alignment Evaluation Initiative (OAEI)tracks with 49 distinct alignments. We find that Phase 1 text preprocessing(Tokenisation and Normalisation) is more effective than Phase 2 textpreprocessing (Stop Words Removal and Stemming/Lemmatisation). To repair theunwanted false mappings caused by Phase 2 text preprocessing, we propose anovel context-based pipeline repair approach that employs a post hoc check tofind common words that cause false mappings. These words are stored in areserved word set and applied in text preprocessing. The experimental resultsshow that our approach improves the matching correctness and the overallmatching performance. We then consider the broader integration of the classictext preprocessing pipeline with modern large language models (LLMs) for OM. Werecommend that (1) the text preprocessing pipeline be injected via functioncalling into LLMs to avoid the tendency towards unstable true mappings producedby LLM prompting; or (2) LLMs be used to repair non-existent andcounter-intuitive false mappings generated by the text preprocessing pipeline.
  </details>

- **[CASA: Class-Agnostic Shared Attributes in Vision-Language Models for Efficient Incremental Object Detection](http://arxiv.org/abs/2410.05804v3)**  `arXiv:2410.05804`  `cs.CV`  
  _Mingyi Guo, Yuyang Liu, Zhiyuan Yan, Zongying Lin, Peixi Peng, Yonghong Tian_
  <details open><summary>Abstract</summary>
  Incremental object detection is fundamentally challenged by catastrophicforgetting. A major factor contributing to this issue is background shift,where background categories in sequential tasks may overlap with eitherpreviously learned or future unseen classes. To address this, we propose anovel method called Class-Agnostic Shared Attribute Base (CASA) that encouragesthe model to learn category-agnostic attributes shared across incrementalclasses. Our approach leverages an LLM to generate candidate textualattributes, selects the most relevant ones based on the current training data,and records their importance in an assignment matrix. For subsequent tasks, theretained attributes are frozen, and new attributes are selected from theremaining candidates, ensuring both knowledge retention and adaptability.Extensive experiments on the COCO dataset demonstrate the state-of-the-artperformance of our method.
  </details>

- **[ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery](http://arxiv.org/abs/2410.05080v3)**  `arXiv:2410.05080`  `cs.LG` `cs.CL` `cs.AI`  
  _Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, et al._
  <details open><summary>Abstract</summary>
  The advancements of large language models (LLMs) have piqued growing interestin developing LLM-based language agents to automate scientific discoveryend-to-end, which has sparked both excitement and skepticism about their truecapabilities. In this work, we call for rigorous assessment of agents onindividual tasks in a scientific workflow before making bold claims onend-to-end automation. To this end, we present ScienceAgentBench, a newbenchmark for evaluating language agents for data-driven scientific discovery.To ensure the scientific authenticity and real-world relevance of ourbenchmark, we extract 102 tasks from 44 peer-reviewed publications in fourdisciplines and engage nine subject matter experts to validate them. We unifythe target output for every task to a self-contained Python program file andemploy an array of evaluation metrics to examine the generated programs,execution results, and costs. Each task goes through multiple rounds of manualvalidation by annotators and subject matter experts to ensure its annotationquality and scientific plausibility. We also propose two effective strategiesto mitigate data contamination concerns. Using ScienceAgentBench, we evaluatefive open-weight and proprietary LLMs, each with three frameworks: directprompting, OpenHands CodeAct, and self-debug. Given three attempts for eachtask, the best-performing agent can only solve 32.4% of the tasks independentlyand 34.3% with expert-provided knowledge. In addition, we evaluate OpenAIo1-preview with direct prompting and self-debug, which can boost theperformance to 42.2%, demonstrating the effectiveness of increasinginference-time compute but with more than 10 times the cost of other LLMs.Still, our results underscore the limitations of current language agents ingenerating code for data-driven discovery, let alone end-to-end automation forscientific research.
  </details>

- **[Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-level Goal Decomposition](http://arxiv.org/abs/2409.19250v2)**  `arXiv:2409.19250`  `cs.RO`  
  _Minseo Kwon, Yaesol Kim, Young J. Kim_
  <details open><summary>Abstract</summary>
  In robotic task planning, symbolic planners using rule-based representationslike PDDL are effective but struggle with long-sequential tasks in complicatedenvironments due to exponentially increasing search space. Meanwhile, LLM-basedapproaches, which are grounded in artificial neural networks, offer fasterinference and commonsense reasoning but suffer from lower success rates. Toaddress the limitations of the current symbolic (slow speed) or LLM-basedapproaches (low accuracy), we propose a novel neuro-symbolic task planner thatdecomposes complex tasks into subgoals using LLM and carries out task planningfor each subgoal using either symbolic or MCTS-based LLM planners, depending onthe subgoal complexity. This decomposition reduces planning time and improvessuccess rates by narrowing the search space and enabling LLMs to focus on moremanageable tasks. Our method significantly reduces planning time whilemaintaining high success rates across task planning domains, as well asreal-world and simulated robotics environments. More details are available athttp://graphics.ewha.ac.kr/LLMTAMP/.
  </details>

- **[MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data Uncertainty](http://arxiv.org/abs/2408.06816v2)**  `arXiv:2408.06816`  `cs.CL` `cs.AI`  
  _Yongjin Yang, Haneul Yoo, Hwaran Lee_
  <details open><summary>Abstract</summary>
  Despite the massive advancements in large language models (LLMs), they stillsuffer from producing plausible but incorrect responses. To improve thereliability of LLMs, recent research has focused on uncertainty quantificationto predict whether a response is correct or not. However, most uncertaintyquantification methods have been evaluated on single-labeled questions, whichremoves data uncertainty: the irreducible randomness often present in userqueries, which can arise from factors like multiple possible answers. Thislimitation may cause uncertainty quantification results to be unreliable inpractical settings. In this paper, we investigate previous uncertaintyquantification methods under the presence of data uncertainty. Ourcontributions are two-fold: 1) proposing a new Multi-Answer Question Answeringdataset, MAQA, consisting of world knowledge, mathematical reasoning, andcommonsense reasoning tasks to evaluate uncertainty quantification regardingdata uncertainty, and 2) assessing 5 uncertainty quantification methods ofdiverse white- and black-box LLMs. Our findings show that previous methodsrelatively struggle compared to single-answer settings, though this variesdepending on the task. Moreover, we observe that entropy- and consistency-basedmethods effectively estimate model uncertainty, even in the presence of datauncertainty. We believe these observations will guide future work onuncertainty quantification in more realistic settings.
  </details>

- **[Training-Free Exponential Context Extension via Cascading KV Cache](http://arxiv.org/abs/2406.17808v4)**  `arXiv:2406.17808`  `cs.LG` `cs.CL` `cs.AI`  
  _Jeffrey Willette, Heejun Lee, Youngwan Lee, Myeongjae Jeon, Sung Ju Hwang_
  <details open><summary>Abstract</summary>
  The transformer's context window is vital for tasks such as few-shot learningand conditional generation as it preserves previous tokens for active memory.However, as the context lengths increase, the computational costs growquadratically, hindering the deployment of large language models (LLMs) inreal-world, long sequence scenarios. Although some recent key-value caching (KVCache) methods offer linear inference complexity, they naively manage thestored context, prematurely evicting tokens and losing valuable information.Moreover, they lack an optimized prefill/prompt stage strategy, resulting inhigher latency than even quadratic attention for realistic context sizes. Inresponse, we introduce a novel mechanism that leverages cascading sub-cachebuffers to selectively retain the most relevant tokens, enabling the model tomaintain longer context histories without increasing the cache size. Ourapproach outperforms linear caching baselines across key benchmarks, includingstreaming perplexity, question answering, book summarization, and passkeyretrieval, where it retains better retrieval accuracy at 1M tokens after fourdoublings of the cache size of 65K. Additionally, our method reduces prefillstage latency by a factor of 6.8 when compared to flash attention on 1M tokens.These innovations not only enhance the computational efficiency of LLMs butalso pave the way for their effective deployment in resource-constrainedenvironments, enabling large-scale, real-time applications with significantlyreduced latency.
  </details>
