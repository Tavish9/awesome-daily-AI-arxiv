# üöÄ Daily AI arXiv Digest

[![Total Papers](https://img.shields.io/badge/paper_today-310+-red)]()
[![Last Updated](https://img.shields.io/badge/dynamic/json?url=https://api.github.com/repos/tavish9/awesome-daily-AI-arxiv/commits/main&query=%24.commit.author.date&label=updated&color=orange)](https://github.com/Tavish9/awesome-daily-AI-arxiv/commits/main/)
[![arXiv API](https://img.shields.io/badge/powered_by-arXiv_API-009688)](https://arxiv.org/help/api)
[![License](https://img.shields.io/badge/license-CC_BY--SA_4.0-3989c9)](LICENSE)


üìå ‚Äã**Tracking Breakthroughs in**: `AI` ‚Ä¢ `NLP` ‚Ä¢ `CV` ‚Ä¢ `ML` ‚Ä¢ `Robotics`  
‚è∞ ‚Äã**Update Schedule**: [UTC 02:00](https://time.is/UTC) | [GMT+8 10:00](https://time.is/China)

## üåü Today's Highlights

- üî• Hot Topic
  - [LLM](hot_topic/LLM.md)
  - [Benchmark](hot_topic/Benchmark.md)
  - [Reasoning](hot_topic/Reasoning.md)
  - [MLLM](hot_topic/MLLM.md)
  - [Diffusion](hot_topic/Diffusion.md)
  - [3D_Reconstruction](hot_topic/3D_Reconstruction.md)
  - [3D_Generation](hot_topic/3D_Generation.md)
  - [Embodied_AI](hot_topic/Embodied_AI.md)
- üí´ Active Platform
  - [Huggingface](https://huggingface.co/papers)
  - [LlamaFactory](https://www.llamafactory.cn/daily-paper/)
  - [X (Twitter)](https://x.com/arxiv_daily)
  - [Paper Reading](https://paperreading.club/)
  - [Paper Digest](https://www.paperdigest.org/arxiv/)
  

## üìå Full Archive

| Category                                                                                | Count |
| --------------------------------------------------------------------------------------- | ----- |
| [Artificial Intelligence üß†](#artificial-intelligence-) | 22    |
| [Computation and Language üí¨](#computation-and-language-) | 53    |
| [Computer Vision and Pattern Recognition üì∏](#computer-vision-and-pattern-recognition-) | 134   |
| [Machine Learning üìä](#machine-learning-) | 74    |
| [Multiagent Systems üåê](#multiagent-systems-) | 2     |
| [Robotics ü§ñ](#robotics-) | 25    |

### Artificial Intelligence üß†

<details open><summary>Click to Collapse</summary>

- **[RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy](http://arxiv.org/abs/2503.24388v1)**  `arXiv:2503.24388`  
  _Zhonghan Zhao, Wenwei Zhang, Haian Huang, Kuikun Liu, Jianfei Gao, Gaoang Wang, et al._
  <details><summary>Abstract</summary>
  Reasoning before action and imagining potential outcomes (i.e., world models)are essential for embodied agents operating in complex open-world environments.Yet, prior work either incorporates only one of these abilities in anend-to-end agent or integrates multiple specialized models into an agentsystem, limiting the learning efficiency and generalization of the policy.Thus, this paper makes the first attempt to synergize Reasoning and Imaginationin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-endmanner, we construct a data pipeline that progressively integrates and enrichesthe content of imagination and reasoning in the trajectories collected fromexisting agents. The joint learning of reasoning and next image generationexplicitly models the inherent correlation between reasoning, action, anddynamics of environments, and thus exhibits more than $17\times$ sampleefficiency improvements and generalization in comparison with previous works.During inference, RIG first reasons about the next action, produces potentialaction, and then predicts the action outcomes, which offers the agent a chanceto review and self-correct based on the imagination before taking real actions.Experimental results show that the synergy of reasoning and imagination notonly improves the robustness, generalization, and interoperability ofgeneralist policy but also enables test-time scaling to enhance overallperformance.
  </details>

- **[ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning](http://arxiv.org/abs/2503.24378v1)**  `arXiv:2503.24378`  
  _Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi_
  <details><summary>Abstract</summary>
  The ACPBench dataset provides atomic reasoning tasks required for efficientplanning. The dataset is aimed at distilling the complex plan generation taskinto separate atomic reasoning tasks in their easiest possible form, boolean ormultiple-choice questions, where the model has to choose the right answer fromthe provided options. While the aim of ACPBench is to test the simplest form ofreasoning about action and change, when tasked with planning, a model does nottypically have options to choose from and thus the reasoning required forplanning dictates an open-ended, generative form for these tasks. To that end,we introduce ACPBench Hard, a generative version of ACPBench, with open-endedquestions which the model needs to answer. Models that perform well on thesetasks could in principle be integrated into a planner or be used directly as apolicy. We discuss the complexity of these tasks as well as the complexity ofvalidating the correctness of their answers and present validation algorithmsfor each task. Equipped with these validators, we test the performance of avariety of models on our tasks and find that for most of these tasks theperformance of even the largest models is still subpar. Our experiments showthat no model outperforms another in these tasks and with a few exceptions alltested language models score below 65%, indicating that even the currentfrontier language models have a long way to go before they can reliably reasonabout planning. In fact, even the so-called reasoning models struggle withsolving these reasoning tasks. ACPBench Hard collection is available at thefollowing link: https://ibm.github.io/ACPBench
  </details>

- **[Contextual Preference Collaborative Measure Framework Based on Belief System](http://arxiv.org/abs/2503.24328v1)**  `arXiv:2503.24328`  
  _Hang Yu, Wei Wei, Zheng Tan, Jing-lei Liu_
  <details><summary>Abstract</summary>
  To reduce the human intervention in the preference measure process,thisarticle proposes a preference collaborative measure framework based on anupdated belief system,which is also capable of improving the accuracy andefficiency of preferen-ce measure algorithms.Firstly,the distance of rules andthe average internal distance of rulesets are proposed for specifying therelationship between the rules.For discovering the most representativepreferences that are common in all users,namely common preference,a algorithmbased on average internal distance of ruleset,PRA algorithm,is proposed,whichaims to finish the discoveryprocess with minimum information lossrate.Furthermore,the concept of Common belief is proposed to update the beliefsystem,and the common preferences are the evidences of updated beliefsystem.Then,under the belief system,the proposed belief degree and deviationdegree are used to determine whether a rule confirms the belief system or notand classify the preference rules into two kinds(generalized orpersonalized),and eventually filters out Top-K interesting rules relying onbelief degree and deviation degree.Based on above,a scalable interestingnesscalculation framework that can apply various formulas is proposed foraccurately calculating interestingness in different conditions.At last,IMCosalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracyand efficiency of the framework by using weighted cosine similarity andcorrelation coefficients as belief degree.In experiments,the proposedalgorithms are compared to two state-of-the-art algorithms and the results showthat IMCos and IMCov outperform than the other two in most aspects.
  </details>

- **[PAARS: Persona Aligned Agentic Retail Shoppers](http://arxiv.org/abs/2503.24228v1)**  `arXiv:2503.24228`  
  _Saab Mansour, Leonardo Perelli, Lorenzo Mainetti, George Davidson, Stefano D'Amato_
  <details><summary>Abstract</summary>
  In e-commerce, behavioral data is collected for decision making which can becostly and slow. Simulation with LLM powered agents is emerging as a promisingalternative for representing human population behavior. However, LLMs are knownto exhibit certain biases, such as brand bias, review rating bias and limitedrepresentation of certain groups in the population, hence they need to becarefully benchmarked and aligned to user behavior. Ultimately, our goal is tosynthesise an agent population and verify that it collectively approximates areal sample of humans. To this end, we propose a framework that: (i) createssynthetic shopping agents by automatically mining personas from anonymisedhistorical shopping data, (ii) equips agents with retail-specific tools tosynthesise shopping sessions and (iii) introduces a novel alignment suitemeasuring distributional differences between humans and shopping agents at thegroup (i.e. population) level rather than the traditional "individual" level.Experimental results demonstrate that using personas improves performance onthe alignment suite, though a gap remains to human behaviour. We showcase aninitial application of our framework for automated agentic A/B testing andcompare the findings to human results. Finally, we discuss applications,limitations and challenges setting the stage for impactful future work.
  </details>

- **[All You Need is Sally-Anne: ToM in AI Strongly Supported After Surpassing Tests for 3-Year-Olds](http://arxiv.org/abs/2503.24215v1)**  `arXiv:2503.24215`  
  _Nitay Alon, Joseph Barnby, Reuth Mirsky, Stefan Sarkadi_
  <details><summary>Abstract</summary>
  Theory of Mind (ToM) is a hallmark of human cognition, allowing individualsto reason about others' beliefs and intentions. Engineers behind recentadvances in Artificial Intelligence (AI) have claimed to demonstrate comparablecapabilities. This paper presents a model that surpasses traditional ToM testsdesigned for 3-year-old children, providing strong support for the presence ofToM in AI systems.
  </details>

- **[Agent-Based Simulations of Online Political Discussions: A Case Study on Elections in Germany](http://arxiv.org/abs/2503.24199v1)**  `arXiv:2503.24199`  
  _Abdul Sittar, Simon M√ºnker, Fabio Sartori, Andreas Reitenbach, Achim Rettinger, Michael M√§s, et al._
  <details><summary>Abstract</summary>
  User engagement on social media platforms is influenced by historicalcontext, time constraints, and reward-driven interactions. This study presentsan agent-based simulation approach that models user interactions, consideringpast conversation history, motivation, and resource constraints. UtilizingGerman Twitter data on political discourse, we fine-tune AI models to generateposts and replies, incorporating sentiment analysis, irony detection, andoffensiveness classification. The simulation employs a myopic best-responsemodel to govern agent behavior, accounting for decision-making based onexpected rewards. Our results highlight the impact of historical context onAI-generated responses and demonstrate how engagement evolves under varyingconstraints.
  </details>

- **[Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition](http://arxiv.org/abs/2503.24110v1)**  `arXiv:2503.24110`  
  _Fran√ßois Olivier, Zied Bouraoui_
  <details><summary>Abstract</summary>
  Despite advances in embodied AI, agent reasoning systems still struggle tocapture the fundamental conceptual structures that humans naturally use tounderstand and interact with their environment. To address this, we propose anovel framework that bridges embodied cognition theory and agent systems byleveraging a formal characterization of image schemas, which are defined asrecurring patterns of sensorimotor experience that structure human cognition.By customizing LLMs to translate natural language descriptions into formalrepresentations based on these sensorimotor patterns, we will be able to createa neurosymbolic system that grounds the agent's understanding in fundamentalconceptual structures. We argue that such an approach enhances both efficiencyand interpretability while enabling more intuitive human-agent interactionsthrough shared embodied understanding.
  </details>

- **[Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents](http://arxiv.org/abs/2503.24047v1)**  `arXiv:2503.24047`  
  _Shuo Ren, Pu Jian, Zhenjiang Ren, Chunlin Leng, Can Xie, Jiajun Zhang_
  <details><summary>Abstract</summary>
  As scientific research becomes increasingly complex, innovative tools areneeded to manage vast data, facilitate interdisciplinary collaboration, andaccelerate discovery. Large language models (LLMs) are now evolving intoLLM-based scientific agents that automate critical tasks, ranging fromhypothesis generation and experiment design to data analysis and simulation.Unlike general-purpose LLMs, these specialized agents integrate domain-specificknowledge, advanced tool sets, and robust validation mechanisms, enabling themto handle complex data types, ensure reproducibility, and drive scientificbreakthroughs. This survey provides a focused review of the architectures,design, benchmarks, applications, and ethical considerations surroundingLLM-based scientific agents. We highlight why they differ from general agentsand the ways in which they advance research across various scientific fields.By examining their development and challenges, this survey offers acomprehensive roadmap for researchers and practitioners to harness these agentsfor more efficient, reliable, and ethically sound scientific discovery.
  </details>

- **[Pay More Attention to the Robustness of Prompt for Instruction Data Mining](http://arxiv.org/abs/2503.24028v1)**  `arXiv:2503.24028`  
  _Qiang Wang, Dawei Feng, Xu Zhang, Ao Shen, Yang Xu, Bo Ding, et al._
  <details><summary>Abstract</summary>
  Instruction tuning has emerged as a paramount method for tailoring thebehaviors of LLMs. Recent work has unveiled the potential for LLMs to achievehigh performance through fine-tuning with a limited quantity of high-qualityinstruction data. Building upon this approach, we further explore the impact ofprompt's robustness on the selection of high-quality instruction data. Thispaper proposes a pioneering framework of high-quality online instruction datamining for instruction tuning, focusing on the impact of prompt's robustness onthe data mining process. Our notable innovation, is to generate the adversarialinstruction data by conducting the attack for the prompt of online instructiondata. Then, we introduce an Adversarial Instruction-Following Difficulty metricto measure how much help the adversarial instruction data can provide to thegeneration of the corresponding response. Apart from it, we propose a novelAdversarial Instruction Output Embedding Consistency approach to selecthigh-quality online instruction data. We conduct extensive experiments on twobenchmark datasets to assess the performance. The experimental results serve tounderscore the effectiveness of our proposed two methods. Moreover, the resultsunderscore the critical practical significance of considering prompt'srobustness.
  </details>

- **[AI2Agent: An End-to-End Framework for Deploying AI Projects as Autonomous Agents](http://arxiv.org/abs/2503.23948v1)**  `arXiv:2503.23948`  
  _Jiaxiang Chen, Jingwei Shi, Lei Gan, Jiale Zhang, Qingyu Zhang, Dongqian Zhang, et al._
  <details><summary>Abstract</summary>
  As AI technology advances, it is driving innovation across industries,increasing the demand for scalable AI project deployment. However, deploymentremains a critical challenge due to complex environment configurations,dependency conflicts, cross-platform adaptation, and debugging difficulties,which hinder automation and adoption. This paper introduces AI2Agent, anend-to-end framework that automates AI project deployment throughguideline-driven execution, self-adaptive debugging, and case \& solutionaccumulation. AI2Agent dynamically analyzes deployment challenges, learns frompast cases, and iteratively refines its approach, significantly reducing humanintervention. To evaluate its effectiveness, we conducted experiments on 30 AIdeployment cases, covering TTS, text-to-image generation, image editing, andother AI applications. Results show that AI2Agent significantly reducesdeployment time and improves success rates. The code and demo video are nowpublicly accessible.
  </details>

- **[What the F*ck Is Artificial General Intelligence?](http://arxiv.org/abs/2503.23923v1)**  `arXiv:2503.23923`  
  _Michael Timothy Bennett_
  <details><summary>Abstract</summary>
  Artificial general intelligence (AGI) is an established field of research.Yet Melanie Mitchell and others have questioned if the term still has meaning.AGI has been subject to so much hype and speculation it has become something ofa Rorschach test. Mitchell points out that the debate will only be settledthrough long term, scientific investigation. To that end here is a short,accessible and provocative overview of AGI. I compare definitions ofintelligence, settling on intelligence in terms of adaptation and AGI as anartificial scientist. Taking my queue from Sutton's Bitter Lesson I describetwo foundational tools used to build adaptive systems: search andapproximation. I compare pros, cons, hybrids and architectures like o3,AlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches tomaking systems behave more intelligently. I divide them into scale-maxing,simp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett'sRazors. These maximise resources, simplicity of form, and the weakness ofconstraints on functionality. I discuss examples including AIXI, the freeenergy principle and The Embiggening of language models. I conclude that thoughscale-maxed approximation dominates, AGI will be a fusion of tools andmeta-approaches. The Embiggening was enabled by improvements in hardware. Nowthe bottlenecks are sample and energy efficiency.
  </details>

- **[DebFlow: Automating Agent Creation via Agent Debate](http://arxiv.org/abs/2503.23781v1)**  `arXiv:2503.23781`  
  _Jinwei Su, Yinghui Xia, Ronghua Shi, Jianhui Wang, Jianuo Huang, Yijin Wang, et al._
  <details><summary>Abstract</summary>
  Large language models (LLMs) have demonstrated strong potential andimpressive performance in automating the generation and optimization ofworkflows. However, existing approaches are marked by limited reasoningcapabilities, high computational demands, and significant resourcerequirements. To address these issues, we propose DebFlow, a framework thatemploys a debate mechanism to optimize workflows and integrates reflexion toimprove based on previous experiences. We evaluated our method across sixbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approachachieved a 3\% average performance improvement over the latest baselines,demonstrating its effectiveness in diverse problem domains. In particular,during training, our framework reduces resource consumption by 37\% compared tothe state-of-the-art baselines. Additionally, we performed ablation studies.Removing the Debate component resulted in a 4\% performance drop across twobenchmark datasets, significantly greater than the 2\% drop observed when theReflection component was removed. These findings strongly demonstrate thecritical role of Debate in enhancing framework performance, while alsohighlighting the auxiliary contribution of reflexion to overall optimization.
  </details>

- **[MolGround: A Benchmark for Molecular Grounding](http://arxiv.org/abs/2503.23668v1)**  `arXiv:2503.23668`  
  _Jiaxin Wu, Ting Zhang, Rubing Chen, Wengyu Zhang, Chen Jason Zhang, Xiaoyong Wei, et al._
  <details><summary>Abstract</summary>
  Current molecular understanding approaches predominantly focus on thedescriptive aspect of human perception, providing broad, topic-level insights.However, the referential aspect -- linking molecular concepts to specificstructural components -- remains largely unexplored. To address this gap, wepropose a molecular grounding benchmark designed to evaluate a model'sreferential abilities. We align molecular grounding with establishedconventions in NLP, cheminformatics, and molecular science, showcasing thepotential of NLP techniques to advance molecular understanding within the AIfor Science movement. Furthermore, we constructed the largest molecularunderstanding benchmark to date, comprising 79k QA pairs, and developed amulti-agent grounding prototype as proof of concept. This system outperformsexisting models, including GPT-4o, and its grounding outputs have beenintegrated to enhance traditional tasks such as molecular captioning and ATC(Anatomical, Therapeutic, Chemical) classification.
  </details>

- **[GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS](http://arxiv.org/abs/2503.23633v1)**  `arXiv:2503.23633`  
  _Zhenlong Li, Huan Ning, Song Gao, Krzysztof Janowicz, Wenwen Li, Samantha T. Arundel, et al._
  <details><summary>Abstract</summary>
  The advent of generative AI exemplified by large language models (LLMs) opensnew ways to represent and compute geographic information and transcend theprocess of geographic knowledge production, driving geographic informationsystems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core,autonomous GIS can independently generate and execute geoprocessing workflowsto perform spatial analysis. In this vision paper, we elaborate on the conceptof autonomous GIS and present a framework that defines its five autonomousgoals, five levels of autonomy, five core functions, and three operationalscales. We demonstrate how autonomous GIS could perform geospatial dataretrieval, spatial analysis, and map making with four proof-of-concept GISagents. We conclude by identifying critical challenges and future researchdirections, including fine-tuning and self-growing decision cores, autonomousmodeling, and examining the ethical and practical implications of autonomousGIS. By establishing the groundwork for a paradigm shift in GIScience, thispaper envisions a future where GIS moves beyond traditional workflows toautonomously reason, derive, innovate, and advance solutions to pressing globalchallenges.
  </details>

- **[Intrinsically-Motivated Humans and Agents in Open-World Exploration](http://arxiv.org/abs/2503.23631v1)**  `arXiv:2503.23631`  
  _Aly Lidayan, Yuqing Du, Eliza Kosoy, Maria Rufova, Pieter Abbeel, Alison Gopnik_
  <details><summary>Abstract</summary>
  What drives exploration? Understanding intrinsic motivation is along-standing challenge in both cognitive science and artificial intelligence;numerous objectives have been proposed and used to train agents, yet thereremains a gap between human and agent exploration. We directly compare adults,children, and AI agents in a complex open-ended environment, Crafter, and studyhow common intrinsic objectives: Entropy, Information Gain, and Empowerment,relate to their behavior. We find that only Entropy and Empowerment areconsistently positively correlated with human exploration progress, indicatingthat these objectives may better inform intrinsic reward design for agents.Furthermore, across agents and humans we observe that Entropy initiallyincreases rapidly, then plateaus, while Empowerment increases continuously,suggesting that state diversity may provide more signal in early exploration,while advanced exploration should prioritize control. Finally, we findpreliminary evidence that private speech utterances, and particularly goalverbalizations, may aid exploration in children.
  </details>

- **[ActionStudio: A Lightweight Framework for Data and Training of Large Action Models](http://arxiv.org/abs/2503.22673v2)**  `arXiv:2503.22673`  
  _Jianguo Zhang, Thai Hoang, Ming Zhu, Zuxin Liu, Shiyu Wang, Tulika Awalgaonkar, et al._
  <details><summary>Abstract</summary>
  Action models are essential for enabling autonomous agents to perform complextasks. However, training large action models remains challenging due to thediversity of agent environments and the complexity of agentic data. Despitegrowing interest, existing infrastructure provides limited support forscalable, agent-specific fine-tuning. We present ActionStudio, a lightweightand extensible data and training framework designed for large action models.ActionStudio unifies heterogeneous agent trajectories through a standardizedformat, supports diverse training paradigms including LoRA, full fine-tuning,and distributed setups, and integrates robust preprocessing and verificationtools. We validate its effectiveness across both public and realistic industrybenchmarks, demonstrating strong performance and practical scalability. Weopen-sourced code and data at https://github.com/SalesforceAIResearch/xLAM tofacilitate research in the community.
  </details>

- **[Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs](http://arxiv.org/abs/2503.22241v2)**  `arXiv:2503.22241`  
  _Ziye Chen, Yiqun Duan, Riheng Zhu, Zhenbang Sun, Mingming Gong_
  <details><summary>Abstract</summary>
  Personalized multiple clustering aims to generate diverse partitions of adataset based on different user-specific aspects, rather than a singleclustering. It has recently drawn research interest for accommodating varyinguser preferences. Recent approaches primarily use CLIP embeddings with proxylearning to extract representations biased toward user clustering preferences.However, CLIP primarily focuses on coarse image-text alignment, lacking a deepcontextual understanding of user interests. To overcome these limitations, wepropose an agent-centric personalized clustering framework that leveragesmulti-modal large language models (MLLMs) as agents to comprehensively traversea relational graph to search for clusters based on user interests. Due to theadvanced reasoning mechanism of MLLMs, the obtained clusters align more closelywith user-defined criteria than those obtained from CLIP-based representations.To reduce computational overhead, we shorten the agents' traversal path byconstructing a relational graph using user-interest-biased embeddings extractedby MLLMs. A large number of weakly connected edges can be filtered out based onembedding similarity, facilitating an efficient traversal search for agents.Experimental results show that the proposed method achieves NMI scores of0.9667 and 0.9481 on the Card Order and Card Suits benchmarks, respectively,largely improving the SOTA model by over 140%.
  </details>

- **[Quantifying the Capability Boundary of DeepSeek Models: An Application-Driven Performance Analysis](http://arxiv.org/abs/2502.11164v4)**  `arXiv:2502.11164`  
  _Kaikai Zhao, Zhaoxiang Liu, Xuejiao Lei, Jiaojiao Zhao, Zhenhong Long, Zipeng Wang, et al._
  <details><summary>Abstract</summary>
  DeepSeek-R1, known for its low training cost and exceptional reasoningcapabilities, has achieved state-of-the-art performance on various benchmarks.However, detailed evaluations for DeepSeek Series models from the perspectiveof real-world applications are lacking, making it challenging for users toselect the most suitable DeepSeek models for their specific needs. To addressthis gap, we conduct a systematic evaluation of the DeepSeek-V3, DeepSeek-R1,DeepSeek-R1-Distill-Qwen series, DeepSeek-R1-Distill-Llama series, theircorresponding 4-bit quantized models, and the reasoning model QwQ-32B using theenhanced A-Eval benchmark, A-Eval-2.0. Through a comparative analysis oforiginal instruction-tuned models and their distilled counterparts, weinvestigate how reasoning enhancements impact performance across diversepractical tasks. To assist users in model selection, we quantify the capabilityboundary of DeepSeek models through performance tier classifications. Based onthe quantification results, we develop a model selection handbook that clearlyillustrates the relation among models, their capabilities and practicalapplications. This handbook enables users to select the most cost-effectivemodels without efforts, ensuring optimal performance and resource efficiency inreal-world applications. It should be noted that, despite our efforts toestablish a comprehensive, objective, and authoritative evaluation benchmark,the selection of test samples, characteristics of data distribution, and thesetting of evaluation criteria may inevitably introduce certain biases into theevaluation results. We will continuously optimize the evaluation benchmarks andperiodically update this paper to provide more comprehensive and accurateevaluation results. Please refer to the latest version of the paper for themost current results and conclusions.
  </details>

- **[PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models](http://arxiv.org/abs/2502.01584v3)**  `arXiv:2502.01584`  
  _Zixuan Wu, Francesca Lucchetti, Aleksander Boruch-Gruszecki, Jingmiao Zhao, Carolyn Jane Anderson, Joydeep Biswas, et al._
  <details><summary>Abstract</summary>
  Existing benchmarks for frontier models often test specialized, "PhD-level"knowledge that is difficult for non-experts to grasp. In contrast, we present abenchmark with 594 problems based on the NPR Sunday Puzzle Challenge thatrequires only general knowledge. Our benchmark is challenging for both humansand models; however correct solutions are easy to verify, and models' mistakesare easy to spot. As LLMs are more widely deployed in society, we believe it isuseful to develop benchmarks for frontier models that humans can understandwithout the need for deep domain expertise.  Our work reveals capability gaps that are not evident in existing benchmarks:OpenAI o1 significantly outperforms other reasoning models on our benchmark,despite being on par with other models when tested on benchmarks that testspecialized knowledge. Furthermore, our analysis of reasoning outputs uncoversnew kinds of failures. DeepSeek R1, for instance, often concedes with "I giveup" before providing an answer that it knows is wrong. R1 can also beremarkably "uncertain" in its output and in rare cases, it does not "finishthinking," which suggests the need for techniques to "wrap up" before thecontext window limit is reached. We also quantify the effectiveness ofreasoning longer to identify the point beyond which more reasoning is unlikelyto improve accuracy on our benchmark.
  </details>

- **[AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines](http://arxiv.org/abs/2408.12491v2)**  `arXiv:2408.12491`  
  _Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, et al._
  <details><summary>Abstract</summary>
  Soft-tissue and bone tumours (STBT) are rare, diagnostically challenginglesions with variable clinical behaviours and treatment approaches. Thissystematic review provides an overview of Artificial Intelligence (AI) methodsusing radiological imaging for diagnosis and prognosis of these tumours,highlighting challenges in clinical translation, and evaluating study alignmentwith the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AIinternational consensus guidelines for trustworthy and deployable AI to promotethe clinical translation of AI methods. The review covered literature fromseveral bibliographic databases, including papers published before 17/07/2024.Original research in peer-reviewed journals focused on radiology-based AI fordiagnosing or prognosing primary STBT was included. Exclusion criteria wereanimal, cadaveric, or laboratory studies, and non-English papers. Abstractswere screened by two of three independent reviewers for eligibility. Eligiblepapers were assessed against guidelines by one of three independent reviewers.The search identified 15,015 abstracts, from which 325 articles were includedfor evaluation. Most studies performed moderately on CLAIM, averaging a scoreof 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 outof 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,indicating significant room for improvement. Future efforts by AI developersshould focus on design (e.g. define unmet clinical need, intended clinicalsetting and how AI would be integrated in clinical workflow), development (e.g.build on previous work, explainability), evaluation (e.g. evaluating andaddressing biases, evaluating AI against best practices), and datareproducibility and availability (making documented code and data publiclyavailable). Following these recommendations could improve clinical translationof AI methods.
  </details>

- **[MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data Uncertainty](http://arxiv.org/abs/2408.06816v2)**  `arXiv:2408.06816`  
  _Yongjin Yang, Haneul Yoo, Hwaran Lee_
  <details><summary>Abstract</summary>
  Despite the massive advancements in large language models (LLMs), they stillsuffer from producing plausible but incorrect responses. To improve thereliability of LLMs, recent research has focused on uncertainty quantificationto predict whether a response is correct or not. However, most uncertaintyquantification methods have been evaluated on single-labeled questions, whichremoves data uncertainty: the irreducible randomness often present in userqueries, which can arise from factors like multiple possible answers. Thislimitation may cause uncertainty quantification results to be unreliable inpractical settings. In this paper, we investigate previous uncertaintyquantification methods under the presence of data uncertainty. Ourcontributions are two-fold: 1) proposing a new Multi-Answer Question Answeringdataset, MAQA, consisting of world knowledge, mathematical reasoning, andcommonsense reasoning tasks to evaluate uncertainty quantification regardingdata uncertainty, and 2) assessing 5 uncertainty quantification methods ofdiverse white- and black-box LLMs. Our findings show that previous methodsrelatively struggle compared to single-answer settings, though this variesdepending on the task. Moreover, we observe that entropy- and consistency-basedmethods effectively estimate model uncertainty, even in the presence of datauncertainty. We believe these observations will guide future work onuncertainty quantification in more realistic settings.
  </details>

- **[ShapG: new feature importance method based on the Shapley value](http://arxiv.org/abs/2407.00506v2)**  `arXiv:2407.00506`  
  _Chi Zhao, Jing Liu, Elena Parilina_
  <details><summary>Abstract</summary>
  With wide application of Artificial Intelligence (AI), it has becomeparticularly important to make decisions of AI systems explainable andtransparent. In this paper, we proposed a new Explainable ArtificialIntelligence (XAI) method called ShapG (Explanations based on Shapley value forGraphs) for measuring feature importance. ShapG is a model-agnostic globalexplanation method. At the first stage, it defines an undirected graph based onthe dataset, where nodes represent features and edges are added based oncalculation of correlation coefficients between features. At the second stage,it calculates an approximated Shapley value by sampling the data taking intoaccount this graph structure. The sampling approach of ShapG allows tocalculate the importance of features efficiently, i.e. to reduce computationalcomplexity. Comparison of ShapG with other existing XAI methods shows that itprovides more accurate explanations for two examined datasets. We also comparedother XAI methods developed based on cooperative game theory with ShapG inrunning time, and the results show that ShapG exhibits obvious advantages inits running time, which further proves efficiency of ShapG. In addition,extensive experiments demonstrate a wide range of applicability of the ShapGmethod for explaining complex models. We find ShapG an important tool inimproving explainability and transparency of AI systems and believe it can bewidely used in various fields.
  </details>

[‚Üë Back to Top](#-full-archive)

</details>

### Computation and Language üí¨

<details open><summary>Click to Collapse</summary>

- **[Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models](http://arxiv.org/abs/2503.24377v1)**  `arXiv:2503.24377`  
  _Rui Wang, Hongru Wang, Boyang Xue, Jianhui Pang, Shudong Liu, Yi Chen, et al._
  <details><summary>Abstract</summary>
  Recent advancements in Large Language Models (LLMs) have significantlyenhanced their ability to perform complex reasoning tasks, transitioning fromfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).While System 2 reasoning improves task accuracy, it often incurs substantialcomputational costs due to its slow thinking nature and inefficient orunnecessary reasoning behaviors. In contrast, System 1 reasoning iscomputationally efficient but leads to suboptimal performance. Consequently, itis critical to balance the trade-off between performance (benefits) andcomputational costs (budgets), giving rise to the concept of reasoning economy.In this survey, we provide a comprehensive analysis of reasoning economy inboth the post-training and test-time inference stages of LLMs, encompassing i)the cause of reasoning inefficiency, ii) behavior analysis of differentreasoning patterns, and iii) potential solutions to achieve reasoning economy.By offering actionable insights and highlighting open challenges, we aim toshed light on strategies for improving the reasoning economy of LLMs, therebyserving as a valuable resource for advancing research in this evolving area. Wealso provide a public repository to continually track developments in thisfast-evolving field.
  </details>

- **[Query and Conquer: Execution-Guided SQL Generation](http://arxiv.org/abs/2503.24364v1)**  `arXiv:2503.24364`  
  _≈Åukasz Borchmann, Marek Wydmuch_
  <details><summary>Abstract</summary>
  We propose a novel approach for generating complex outputs that significantlyimproves accuracy in text-to-SQL tasks. Our method leverages execution resultsto select the most semantically consistent query from multiple candidates,enabling smaller, cost-effective models to surpass computationally intensivereasoning methods such as o1, o3-mini, and DeepSeek R1 while reducing inferencecost by as much as 30 times. It integrates effortlessly with existing models,offering a practical and scalable pathway to state-of-the-art SQL generation.
  </details>

- **[BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models](http://arxiv.org/abs/2503.24310v1)**  `arXiv:2503.24310`  
  _Alok Abhishek, Lisa Erickson, Tushar Bandopadhyay_
  <details><summary>Abstract</summary>
  In this research, we introduce BEATS, a novel framework for evaluating Bias,Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building uponthe BEATS framework, we present a bias benchmark for LLMs that measureperformance across 29 distinct metrics. These metrics span a broad range ofcharacteristics, including demographic, cognitive, and social biases, as wellas measures of ethical reasoning, group fairness, and factuality relatedmisinformation risk. These metrics enable a quantitative assessment of theextent to which LLM generated responses may perpetuate societal prejudices thatreinforce or expand systemic inequities. To achieve a high score on thisbenchmark a LLM must show very equitable behavior in their responses, making ita rigorous standard for responsible AI evaluation. Empirical results based ondata from our experiment show that, 37.65\% of outputs generated by industryleading models contained some form of bias, highlighting a substantial risk ofusing these models in critical decision making systems. BEATS framework andbenchmark offer a scalable and statistically rigorous methodology to benchmarkLLMs, diagnose factors driving biases, and develop mitigation strategies. Withthe BEATS framework, our goal is to help the development of more sociallyresponsible and ethically aligned AI models.
  </details>

- **[A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG](http://arxiv.org/abs/2503.24307v1)**  `arXiv:2503.24307`  
  _Arshia Kermani, Veronica Perez-Rosas, Vangelis Metsis_
  <details><summary>Abstract</summary>
  This study presents a systematic comparison of three approaches for theanalysis of mental health text using large language models (LLMs): promptengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA3, we evaluate these approaches on emotion classification and mental healthcondition detection tasks across two datasets. Fine-tuning achieves the highestaccuracy (91% for emotion classification, 80% for mental health conditions) butrequires substantial computational resources and large training sets, whileprompt engineering and RAG offer more flexible deployment with moderateperformance (40-68% accuracy). Our findings provide practical insights forimplementing LLM-based solutions in mental health applications, highlightingthe trade-offs between accuracy, computational requirements, and deploymentflexibility.
  </details>

- **[Is analogy enough to draw novel adjective-noun inferences?](http://arxiv.org/abs/2503.24293v1)**  `arXiv:2503.24293`  
  _Hayley Ross, Kathryn Davidson, Najoung Kim_
  <details><summary>Abstract</summary>
  Recent work (Ross et al., 2025, 2024) has argued that the ability of humansand LLMs respectively to generalize to novel adjective-noun combinations showsthat they each have access to a compositional mechanism to determine thephrase's meaning and derive inferences. We study whether these inferences caninstead be derived by analogy to known inferences, without need forcomposition. We investigate this by (1) building a model of analogicalreasoning using similarity over lexical items, and (2) asking humanparticipants to reason by analogy. While we find that this strategy works wellfor a large proportion of the dataset of Ross et al. (2025), there are novelcombinations for which both humans and LLMs derive convergent inferences butwhich are not well handled by analogy. We thus conclude that the mechanismhumans and LLMs use to generalize in these cases cannot be fully reduced toanalogy, and likely involves composition.
  </details>

- **[Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation](http://arxiv.org/abs/2503.24245v1)**  `arXiv:2503.24245`  
  _Dun Yuan, Hao Zhou, Di Wu, Xue Liu, Hao Chen, Yan Xin, et al._
  <details><summary>Abstract</summary>
  Large language models (LLMs) have made significant progress ingeneral-purpose natural language processing tasks. However, LLMs are stillfacing challenges when applied to domain-specific areas liketelecommunications, which demands specialized expertise and adaptability toevolving standards. This paper presents a novel framework that combinesknowledge graph (KG) and retrieval-augmented generation (RAG) techniques toenhance LLM performance in the telecom domain. The framework leverages a KG tocapture structured, domain-specific information about network protocols,standards, and other telecom-related entities, comprehensively representingtheir relationships. By integrating KG with RAG, LLMs can dynamically accessand utilize the most relevant and up-to-date knowledge during responsegeneration. This hybrid approach bridges the gap between structured knowledgerepresentation and the generative capabilities of LLMs, significantly enhancingaccuracy, adaptability, and domain-specific comprehension. Our resultsdemonstrate the effectiveness of the KG-RAG framework in addressing complextechnical queries with precision. The proposed KG-RAG model attained anaccuracy of 88% for question answering tasks on a frequently usedtelecom-specific dataset, compared to 82% for the RAG-only and 48% for theLLM-only approaches.
  </details>

- **[What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models](http://arxiv.org/abs/2503.24235v1)**  `arXiv:2503.24235`  
  _Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Zhihan Guo, et al._
  <details><summary>Abstract</summary>
  As enthusiasm for scaling computation (data and parameters) in thepretraining era gradually diminished, test-time scaling (TTS), also referred toas ``test-time computing'' has emerged as a prominent research focus. Recentstudies demonstrate that TTS can further elicit the problem-solvingcapabilities of large language models (LLMs), enabling significantbreakthroughs not only in specialized reasoning tasks, such as mathematics andcoding, but also in general tasks like open-ended Q&A. However, despite theexplosion of recent efforts in this area, there remains an urgent need for acomprehensive survey offering a systemic understanding. To fill this gap, wepropose a unified, multidimensional framework structured along four coredimensions of TTS research: what to scale, how to scale, where to scale, andhow well to scale. Building upon this taxonomy, we conduct an extensive reviewof methods, application scenarios, and assessment aspects, and present anorganized decomposition that highlights the unique functional roles ofindividual techniques within the broader TTS landscape. From this analysis, wedistill the major developmental trajectories of TTS to date and offer hands-onguidelines for practical deployment. Furthermore, we identify several openchallenges and offer insights into promising future directions, includingfurther scaling, clarifying the functional essence of techniques, generalizingto more tasks, and more attributions.
  </details>

- **[BAR-Analytics: A Web-based Platform for Analyzing Information Spreading Barriers in News: Comparative Analysis Across Multiple Barriers and Events](http://arxiv.org/abs/2503.24220v1)**  `arXiv:2503.24220`  
  _Abdul Sittar, Dunja Mladenic, Alenka Gucek, Marko Grobelnik_
  <details><summary>Abstract</summary>
  This paper presents BAR-Analytics, a web-based, open-source platform designedto analyze news dissemination across geographical, economic, political, andcultural boundaries. Using the Russian-Ukrainian and Israeli-Palestinianconflicts as case studies, the platform integrates four analytical methods:propagation analysis, trend analysis, sentiment analysis, and temporal topicmodeling. Over 350,000 articles were collected and analyzed, with a focus oneconomic disparities and geographical influences using metadata enrichment. Weevaluate the case studies using coherence, sentiment polarity, topic frequency,and trend shifts as key metrics. Our results show distinct patterns in newscoverage: the Israeli-Palestinian conflict tends to have more negativesentiment with a focus on human rights, while the Russia-Ukraine conflict ismore positive, emphasizing election interference. These findings highlight theinfluence of political, economic, and regional factors in shaping medianarratives across different conflicts.
  </details>

- **[Synthetic News Generation for Fake News Classification](http://arxiv.org/abs/2503.24206v1)**  `arXiv:2503.24206`  
  _Abdul Sittar, Luka Golob, Mateja Smiljanic_
  <details><summary>Abstract</summary>
  This study explores the generation and evaluation of synthetic fake newsthrough fact based manipulations using large language models (LLMs). Weintroduce a novel methodology that extracts key facts from real articles,modifies them, and regenerates content to simulate fake news while maintainingcoherence. To assess the quality of the generated content, we propose a set ofevaluation metrics coherence, dissimilarity, and correctness. The research alsoinvestigates the application of synthetic data in fake news classification,comparing traditional machine learning models with transformer based modelssuch as BERT. Our experiments demonstrate that transformer models, especiallyBERT, effectively leverage synthetic data for fake news detection, showingimprovements with smaller proportions of synthetic data. Additionally, we findthat fact verification features, which focus on identifying factualinconsistencies, provide the most promising results in distinguishing syntheticfake news. The study highlights the potential of synthetic data to enhance fakenews detection systems, offering valuable insights for future research andsuggesting that targeted improvements in synthetic data generation can furtherstrengthen detection models.
  </details>

- **[TwT: Thinking without Tokens by Habitual Reasoning Distillation with Multi-Teachers' Guidance](http://arxiv.org/abs/2503.24198v1)**  `arXiv:2503.24198`  
  _Jingxian Xu, Mengyu Zhou, Weichang Liu, Hanbing Liu, Shi Han, Dongmei Zhang_
  <details><summary>Abstract</summary>
  Large Language Models (LLMs) have made significant strides in problem-solvingby incorporating reasoning processes. However, this enhanced reasoningcapability results in an increased number of output tokens during inference,leading to higher computational costs. To address this challenge, we proposeTwT (Thinking without Tokens), a method that reduces inference-time coststhrough habitual reasoning distillation with multi-teachers' guidance, whilemaintaining high performance. Our approach introduces a Habitual ReasoningDistillation method, which internalizes explicit reasoning into the model'shabitual behavior through a Teacher-Guided compression strategy inspired byhuman cognition. Additionally, we propose Dual-Criteria Rejection Sampling(DCRS), a technique that generates a high-quality and diverse distillationdataset using multiple teacher models, making our method suitable forunsupervised scenarios. Experimental results demonstrate that TwT effectivelyreduces inference costs while preserving superior performance, achieving up toa 13.6% improvement in accuracy with fewer output tokens compared to otherdistillation methods, offering a highly practical solution for efficient LLMdeployment.
  </details>

- **[Implicit In-Context Learning: Evidence from Artificial Language Experiments](http://arxiv.org/abs/2503.24190v1)**  `arXiv:2503.24190`  
  _Xiaomeng Ma, Qihui Xu_
  <details><summary>Abstract</summary>
  Humans acquire language through implicit learning, absorbing complex patternswithout explicit awareness. While LLMs demonstrate impressive linguisticcapabilities, it remains unclear whether they exhibit human-like patternrecognition during in-context learning at inferencing level. We adapted threeclassic artificial language learning experiments spanning morphology,morphosyntax, and syntax to systematically evaluate implicit learning atinferencing level in two state-of-the-art OpenAI models: gpt-4o and o3-mini.Our results reveal linguistic domain-specific alignment between models andhuman behaviors, o3-mini aligns better in morphology while both models align insyntax.
  </details>

- **[Multi-Task Learning for Extracting Menstrual Characteristics from Clinical Notes](http://arxiv.org/abs/2503.24116v1)**  `arXiv:2503.24116`  
  _Anna Shopova, Cristoph Lippert, Leslee J. Shaw, Eugenia Alleva_
  <details><summary>Abstract</summary>
  Menstrual health is a critical yet often overlooked aspect of women'shealthcare. Despite its clinical relevance, detailed data on menstrualcharacteristics is rarely available in structured medical records. To addressthis gap, we propose a novel Natural Language Processing pipeline to extractkey menstrual cycle attributes -- dysmenorrhea, regularity, flow volume, andintermenstrual bleeding. Our approach utilizes the GatorTron model withMulti-Task Prompt-based Learning, enhanced by a hybrid retrieval preprocessingstep to identify relevant text segments. It out- performs baseline methods,achieving an average F1-score of 90% across all menstrual characteristics,despite being trained on fewer than 100 annotated clinical notes. The retrievalstep consistently improves performance across all approaches, allowing themodel to focus on the most relevant segments of lengthy clinical notes. Theseresults show that combining multi-task learning with retrieval improvesgeneralization and performance across menstrual charac- teristics, advancingautomated extraction from clinical notes and supporting women's healthresearch.
  </details>

- **[TeleAntiFraud-28k: A Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection](http://arxiv.org/abs/2503.24115v1)**  `arXiv:2503.24115`  
  _Zhiming Ma, Peidong Wang, Minhua Huang, Jingpeng Wang, Kai Wu, Xiangzhao Lv, et al._
  <details><summary>Abstract</summary>
  The detection of telecom fraud faces significant challenges due to the lackof high-quality multimodal training data that integrates audio signals withreasoning-oriented textual analysis. To address this gap, we presentTeleAntiFraud-28k, the first open-source audio-text slow-thinking datasetspecifically designed for automated telecom fraud analysis. Our dataset isconstructed through three strategies: (1) Privacy-preserved text-truth samplegeneration using automatically speech recognition (ASR)-transcribed callrecordings (with anonymized original audio), ensuring real-world consistencythrough text-to-speech (TTS) model regeneration; (2) Semantic enhancement vialarge language model (LLM)-based self-instruction sampling on authentic ASRoutputs to expand scenario coverage; (3) Multi-agent adversarial synthesis thatsimulates emerging fraud tactics through predefined communication scenarios andfraud typologies. The generated dataset contains 28,511 rigorously processedspeech-text pairs, complete with detailed annotations for fraud reasoning. Thedataset is divided into three tasks: scenario classification, fraud detection,fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, astandardized evaluation benchmark comprising proportionally sampled instancesfrom the dataset, to facilitate systematic testing of model performance ontelecom fraud detection tasks. We also contribute a production-optimizedsupervised fine-tuning (SFT) model trained on hybrid real/synthetic data, whileopen-sourcing the data processing framework to enable community-driven datasetexpansion. This work establishes a foundational framework for multimodalanti-fraud research while addressing critical challenges in data privacy andscenario diversity. The project will be released athttps://github.com/JimmyMa99/TeleAntiFraud.
  </details>

- **[Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?](http://arxiv.org/abs/2503.24102v1)**  `arXiv:2503.24102`  
  _Yewei Song, Lujun Li, Cedric Lothritz, Saad Ezzini, Lama Sleem, Niccolo Gentile, et al._
  <details><summary>Abstract</summary>
  Low-Resource Languages (LRLs) present significant challenges in naturallanguage processing due to their limited linguistic resources andunderrepresentation in standard datasets. While recent advancements in LargeLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantiallyimproved translation capabilities for high-resource languages, performancedisparities persist for LRLs, particularly impacting privacy-sensitive andresource-constrained scenarios. This paper systematically evaluates thelimitations of current LLMs across 200 languages using benchmarks such asFLORES-200. We also explore alternative data sources, including news articlesand bilingual dictionaries, and demonstrate how knowledge distillation fromlarge pre-trained models can significantly improve smaller LRL translations.Additionally, we investigate various fine-tuning strategies, revealing thatincremental enhancements markedly reduce performance gaps on smaller LLMs.
  </details>

- **[Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data](http://arxiv.org/abs/2503.24062v1)**  `arXiv:2503.24062`  
  _Fatemeh Mohammadi, Tommaso Romano, Samira Maghool, Paolo Ceravolo_
  <details><summary>Abstract</summary>
  Collecting high-quality training data is essential for fine-tuning LargeLanguage Models (LLMs). However, acquiring such data is often costly andtime-consuming, especially for non-English languages such as Italian. Recently,researchers have begun to explore the use of LLMs to generate syntheticdatasets as a viable alternative. This study proposes a pipeline for generatingsynthetic data and a comprehensive approach for investigating the factors thatinfluence the validity of synthetic data generated by LLMs by examining howmodel performance is affected by metrics such as prompt strategy, text lengthand target position in a specific task, i.e. inclusive language detection inItalian job advertisements. Our results show that, in most cases and acrossdifferent metrics, the fine-tuned models trained on synthetic data consistentlyoutperformed other models on both real and synthetic test datasets. The studydiscusses the practical implications and limitations of using synthetic datafor language detection tasks with LLMs.
  </details>

- **[Crossing Boundaries: Leveraging Semantic Divergences to Explore Cultural Novelty in Cooking Recipes](http://arxiv.org/abs/2503.24027v1)**  `arXiv:2503.24027`  
  _Florian Carichon, Romain Rampa, Golnoosh Farnadi_
  <details><summary>Abstract</summary>
  Novelty modeling and detection is a core topic in Natural Language Processing(NLP), central to numerous tasks such as recommender systems and automaticsummarization. It involves identifying pieces of text that deviate in some wayfrom previously known information. However, novelty is also a crucialdeterminant of the unique perception of relevance and quality of an experience,as it rests upon each individual's understanding of the world. Social factors,particularly cultural background, profoundly influence perceptions of noveltyand innovation. Cultural novelty arises from differences in salience andnovelty as shaped by the distance between distinct communities. While culturaldiversity has garnered increasing attention in artificial intelligence (AI),the lack of robust metrics for quantifying cultural novelty hinders a deeperunderstanding of these divergences. This gap limits quantifying andunderstanding cultural differences within computational frameworks. To addressthis, we propose an interdisciplinary framework that integrates knowledge fromsociology and management. Central to our approach is GlobalFusion, a noveldataset comprising 500 dishes and approximately 100,000 cooking recipescapturing cultural adaptation from over 150 countries. By introducing a set ofJensen-Shannon Divergence metrics for novelty, we leverage this dataset toanalyze textual divergences when recipes from one community are modified byanother with a different cultural background. The results reveal significantcorrelations between our cultural novelty metrics and established culturalmeasures based on linguistic, religious, and geographical distances. Ourfindings highlight the potential of our framework to advance the understandingand measurement of cultural diversity in AI.
  </details>

- **[You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness Tradeoff in Translation](http://arxiv.org/abs/2503.24013v1)**  `arXiv:2503.24013`  
  _Gergely Flamich, David Vilar, Jan-Thorsten Peter, Markus Freitag_
  <details><summary>Abstract</summary>
  The goal of translation, be it by human or by machine, is, given some text ina source language, to produce text in a target language that simultaneously 1)preserves the meaning of the source text and 2) achieves natural expression inthe target language. However, researchers in the machine translation communityusually assess translations using a single score intended to capture semanticaccuracy and the naturalness of the output simultaneously. In this paper, webuild on recent advances in information theory to mathematically prove andempirically demonstrate that such single-score summaries do not and cannot givethe complete picture of a system's true performance. Concretely, we prove thata tradeoff exists between accuracy and naturalness and demonstrate it byevaluating the submissions to the WMT24 shared task. Our findings help explainwell-known empirical phenomena, such as the observation that optimizingtranslation systems for a specific accuracy metric (like BLEU) initiallyimproves the system's naturalness, while ``overfitting'' the system to themetric can significantly degrade its naturalness. Thus, we advocate for achange in how translations are evaluated: rather than comparing systems using asingle number, they should be compared on an accuracy-naturalness plane.
  </details>

- **[Comparing representations of long clinical texts for the task of patient note-identification](http://arxiv.org/abs/2503.24006v1)**  `arXiv:2503.24006`  
  _Safa Alsaidi, Marc Vincent, Olivia Boyer, Nicolas Garcelon, Miguel Couceiro, Adrien Coulet_
  <details><summary>Abstract</summary>
  In this paper, we address the challenge of patient-note identification, whichinvolves accurately matching an anonymized clinical note to its correspondingpatient, represented by a set of related notes. This task has broadapplications, including duplicate records detection and patient similarityanalysis, which require robust patient-level representations. We explorevarious embedding methods, including Hierarchical Attention Networks (HAN),three-level Hierarchical Transformer Networks (HTN), LongFormer, and advancedBERT-based models, focusing on their ability to process mediumto-long clinicaltexts effectively. Additionally, we evaluate different pooling strategies(mean, max, and mean_max) for aggregating wordlevel embeddings intopatient-level representations and we examine the impact of sliding windows onmodel performance. Our results indicate that BERT-based embeddings outperformtraditional and hierarchical models, particularly in processing lengthyclinical notes and capturing nuanced patient representations. Among the poolingstrategies, mean_max pooling consistently yields the best results, highlightingits ability to capture critical features from clinical notes. Furthermore, thereproduction of our results on both MIMIC dataset and Necker hospital datawarehouse illustrates the generalizability of these approaches to real-worldapplications, emphasizing the importance of both embedding methods andaggregation strategies in optimizing patient-note identification and enhancingpatient-level modeling.
  </details>

- **[BeMERC: Behavior-Aware MLLM-based Framework for Multimodal Emotion Recognition in Conversation](http://arxiv.org/abs/2503.23990v1)**  `arXiv:2503.23990`  
  _Yumeng Fu, Junjie Wu, Zhongjie Wang, Meishan Zhang, Yulin Wu, Bingquan Liu_
  <details><summary>Abstract</summary>
  Multimodal emotion recognition in conversation (MERC), the task ofidentifying the emotion label for each utterance in a conversation, is vitalfor developing empathetic machines. Current MLLM-based MERC studies focusmainly on capturing the speaker's textual or vocal characteristics, but ignorethe significance of video-derived behavior information. Different from text andaudio inputs, learning videos with rich facial expression, body language andposture, provides emotion trigger signals to the models for more accurateemotion predictions. In this paper, we propose a novel behavior-awareMLLM-based framework (BeMERC) to incorporate speaker's behaviors, includingsubtle facial micro-expression, body language and posture, into a vanillaMLLM-based MERC model, thereby facilitating the modeling of emotional dynamicsduring a conversation. Furthermore, BeMERC adopts a two-stage instructiontuning strategy to extend the model to the conversations scenario forend-to-end training of a MERC predictor. Experiments demonstrate that BeMERCachieves superior performance than the state-of-the-art methods on twobenchmark datasets, and also provides a detailed discussion on the significanceof video-derived behavior information in MERC.
  </details>

- **[Model Hemorrhage and the Robustness Limits of Large Language Models](http://arxiv.org/abs/2503.23924v1)**  `arXiv:2503.23924`  
  _Ziyang Ma, Zuchao Li, Lefei Zhang, Gui-Song Xia, Bo Du, Liangpei Zhang, et al._
  <details><summary>Abstract</summary>
  Large language models (LLMs) demonstrate strong performance across naturallanguage processing tasks, yet undergo significant performance degradation whenmodified for deployment through quantization, pruning, or decoding strategyadjustments. We define this phenomenon as model hemorrhage - performancedecline caused by parameter alterations and architectural changes. Throughsystematic analysis of various LLM frameworks, we identify key vulnerabilitypatterns: layer expansion frequently disrupts attention mechanisms, compressiontechniques induce information loss cascades, and decoding adjustments amplifyprediction divergences. Our investigation reveals transformer architecturesexhibit inherent robustness thresholds that determine hemorrhage severityacross modification types. We propose three mitigation strategies:gradient-aware pruning preserves critical weight pathways, dynamic quantizationscaling maintains activation integrity, and decoding calibration alignsgeneration trajectories with original model distributions. This workestablishes foundational metrics for evaluating model stability duringadaptation, providing practical guidelines for maintaining performance whileenabling efficient LLM deployment. Our findings advance understanding of neuralnetwork resilience under architectural transformations, particularly forlarge-scale language models.
  </details>

- **[Entropy-Based Adaptive Weighting for Self-Training](http://arxiv.org/abs/2503.23913v1)**  `arXiv:2503.23913`  
  _Xiaoxuan Wang, Yihe Deng, Mingyu Derek Ma, Wei Wang_
  <details><summary>Abstract</summary>
  The mathematical problem-solving capabilities of large language models havebecome a focal point of research, with growing interests in leveragingself-generated reasoning paths as a promising way to refine and enhance thesemodels. These paths capture step-by-step logical processes while requiring onlythe correct answer for supervision. The self-training method has been shown tobe effective in reasoning tasks while eliminating the need for external modelsand manual annotations. However, optimizing the use of self-generated data formodel training remains an open challenge. In this work, we proposeEntropy-Based Adaptive Weighting for Self-Training (EAST), an adaptiveweighting strategy designed to prioritize uncertain data during self-training.Specifically, EAST employs a mapping function with a tunable parameter thatcontrols the sharpness of the weighting, assigning higher weights to data wherethe model exhibits greater uncertainty. This approach guides the model to focuson more informative and challenging examples, thereby enhancing its reasoningability. We evaluate our approach on GSM8K and MATH benchmarks. Empiricalresults show that, while the vanilla method yields virtually no improvement(0%) on MATH, EAST achieves around a 1% gain over backbone model. On GSM8K,EAST attains a further 1-2% performance boost compared to the vanilla method.
  </details>

- **[Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset](http://arxiv.org/abs/2503.23899v1)**  `arXiv:2503.23899`  
  _Diana Galvan-Sosa, Gabrielle Gaudeau, Pride Kavumba, Yunmeng Li, Hongyi gu, Zheng Yuan, et al._
  <details><summary>Abstract</summary>
  The performance and usability of Large-Language Models (LLMs) are drivingtheir use in explanation generation tasks. However, despite their widespreadadoption, LLM explanations have been found to be unreliable, making itdifficult for users to distinguish good from bad explanations. To address thisissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of26k explanations, written and later quality-annotated using the rubric by bothhumans and six open- and closed-source LLMs. The CUBE dataset focuses on tworeasoning and two language tasks, providing the necessary diversity for us toeffectively test our proposed rubric. Using Rubrik, we find that explanationsare influenced by both task and perceived difficulty. Low quality stemsprimarily from a lack of conciseness in LLM-generated explanations, rather thancohesion and word choice. The full dataset, rubric, and code will be madeavailable upon acceptance.
  </details>

- **[Better wit than wealth: Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement](http://arxiv.org/abs/2503.23895v1)**  `arXiv:2503.23895`  
  _Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu_
  <details><summary>Abstract</summary>
  Retrieval-augmented generation (RAG) enhances large language models (LLMs) byretrieving relevant documents from external sources and incorporating them intothe context. While it improves reliability by providing factual texts, itsignificantly increases inference costs as context length grows and introduceschallenging issue of RAG hallucination, primarily caused by the lack ofcorresponding parametric knowledge in LLMs. An efficient solution is to enhancethe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this byembedding document into LLMs parameters to perform test-time knowledgeenhancement, effectively reducing inference costs through offline training.However, its high training and storage costs, along with limited generalizationability, significantly restrict its practical adoption. To address thesechallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework thatleverages a lightweight parameter translator model to efficiently convertdocuments into parametric knowledge. DyPRAG not only reduces inference,training, and storage costs but also dynamically generates parametricknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledgeconflicts in a plug-and-play manner at test-time. Extensive experiments onmultiple datasets demonstrate the effectiveness and generalization capabilitiesof DyPRAG, offering a powerful and practical RAG paradigm which enablessuperior knowledge fusion and mitigates RAG hallucination in real-worldapplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.
  </details>

- **[SpeechDialogueFactory: Generating High-Quality Speech Dialogue Data to Accelerate Your Speech-LLM Development](http://arxiv.org/abs/2503.23848v1)**  `arXiv:2503.23848`  
  _Minghan Wang, Ye Bai, Yuxia Wang, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari_
  <details><summary>Abstract</summary>
  High-quality speech dialogue datasets are crucial for Speech-LLM development,yet existing acquisition methods face significant limitations. Human recordingsincur high costs and privacy concerns, while synthetic approaches often lackconversational authenticity. To address these challenges, we introduce\textsc{SpeechDialogueFactory}, a production-ready framework for generatingnatural speech dialogues efficiently. Our solution employs a comprehensivepipeline including metadata generation, dialogue scripting,paralinguistic-enriched utterance simulation, and natural speech synthesis withvoice cloning. Additionally, the system provides an interactive UI for detailedsample inspection and a high-throughput batch synthesis mode. Evaluations showthat dialogues generated by our system achieve a quality comparable to humanrecordings while significantly reducing production costs. We release our workas an open-source toolkit, alongside example datasets available in English andChinese, empowering researchers and developers in Speech-LLM research anddevelopment.
  </details>

- **[Expanding RL with Verifiable Rewards Across Diverse Domains](http://arxiv.org/abs/2503.23829v1)**  `arXiv:2503.23829`  
  _Yi Su, Dian Yu, Linfeng Song, Juntao Li, Haitao Mi, Zhaopeng Tu, et al._
  <details><summary>Abstract</summary>
  Reinforcement learning (RL) with verifiable rewards (RLVR) has shownpromising results in mathematical reasoning and coding tasks wherewell-structured reference answers are available. However, its applicability tobroader domains remains underexplored. In this work, we study the extension ofRLVR to more diverse domains such as medicine, chemistry, psychology, andeconomics. We observe high agreement in binary judgments across different largelanguage models (LLMs) when objective reference answers exist, which challengesthe necessity of large-scale annotation for training domain-specific rewardmodels. To address the limitations of binary rewards when handling unstructuredreference answers, we further incorporate model-based soft scoring into RLVR toimprove its flexibility. Our experiments show that a distilled generativereward model can serve as an effective cross-domain verifier, providingreliable reward signals for RL without requiring domain-specific annotations.By fine-tuning a base 7B model using various RL algorithms against our rewardmodel, we obtain policies that outperform state-of-the-art open-source alignedLLMs such as Qwen2.5-72B-Instruct and DeepSeek-R1-Distill-Qwen-32B by a largemargin, across domains in free-form answer settings. This also strengthensRLVR's robustness and scalability, highlighting its potential for real-worldapplications with noisy or weak labels.
  </details>

- **[Did ChatGPT or Copilot use alter the style of internet news headlines? A time series regression analysis](http://arxiv.org/abs/2503.23811v1)**  `arXiv:2503.23811`  
  _Chris Brogly, Connor McElroy_
  <details><summary>Abstract</summary>
  The release of advanced Large Language Models (LLMs) such as ChatGPT andCopilot is changing the way text is created and may influence the content thatwe find on the web. This study investigated whether the release of these twopopular LLMs coincided with a change in writing style in headlines and links onworldwide news websites. 175 NLP features were obtained for each text in adataset of 451 million headlines/links. An interrupted time series analysis wasapplied for each of the 175 NLP features to evaluate whether there were anystatistically significant sustained changes after the release dates of ChatGPTand/or Copilot. There were a total of 44 features that did not appear to haveany significant sustained change after the release of ChatGPT/Copilot. A totalof 91 other features did show significant change with ChatGPT and/or Copilotalthough significance with earlier control LLM release dates (GPT-1/2/3,Gopher) removed them from consideration. This initial analysis suggests theselanguage models may have had a limited impact on the style of individual newsheadlines/links, with respect to only some NLP measures.
  </details>

- **[Adaptive Layer-skipping in Pre-trained LLMs](http://arxiv.org/abs/2503.23798v1)**  `arXiv:2503.23798`  
  _Xuan Luo, Weizhi Wang, Xifeng Yan_
  <details><summary>Abstract</summary>
  Various layer-skipping methods have been proposed to accelerate tokengeneration in large language models (LLMs). However, they have overlooked afundamental question: How do computational demands vary across the generationof different tokens? In this work, we introduce FlexiDepth, a method thatdynamically adjusts the number of Transformer layers used in text generation.By incorporating a plug-in router and adapter, FlexiDepth enables adaptivelayer-skipping in LLMs without modifying their original parameters. IntroducingFlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32,and meanwhile maintains the full 100\% benchmark performance. Experimentalresults with FlexiDepth demonstrate that computational demands in LLMssignificantly vary based on token type. Specifically, generating repetitivetokens or fixed phrases requires fewer layers, whereas producing tokensinvolving computation or high uncertainty requires more layers. Interestingly,this adaptive allocation pattern aligns with human intuition. To advanceresearch in this area, we open sourced FlexiDepth and a dataset documentingFlexiDepth's layer allocation patterns for future exploration.
  </details>

- **[WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with Common Sense Categorization](http://arxiv.org/abs/2503.23779v1)**  `arXiv:2503.23779`  
  _Ine Gevers, Victor De Marez, Luna De Bruyne, Walter Daelemans_
  <details><summary>Abstract</summary>
  In this study, we take a closer look at how Winograd schema challenges can beused to evaluate common sense reasoning in LLMs. Specifically, we evaluategenerative models of different sizes on the popular WinoGrande benchmark. Werelease WinoWhat, a new corpus, in which each instance of the WinoGrandevalidation set is paraphrased. Additionally, we evaluate the performance on thechallenge across five common sense knowledge categories, giving morefine-grained insights on what types of knowledge are more challenging for LLMs.Surprisingly, all models perform significantly worse on WinoWhat, implying thatLLM reasoning capabilities are overestimated on WinoGrande. To verify whetherthis is an effect of benchmark memorization, we match benchmark instances toLLM trainingdata and create two test-suites. We observe that memorization has aminimal effect on model performance on WinoGrande.
  </details>

- **[CONGRAD:Conflicting Gradient Filtering for Multilingual Preference Alignment](http://arxiv.org/abs/2503.23777v1)**  `arXiv:2503.23777`  
  _Jiangnan Li, Thuy-Trang Vu, Christian Herold, Amirhossein Tebbifakhr, Shahram Khadivi, Gholamreza Haffari_
  <details><summary>Abstract</summary>
  Naive joint training of large language models (LLMs) for multilingualpreference alignment can suffer from negative interference. This is a knownissue in multilingual training, where conflicting objectives degrade overallperformance. However, the impact of this phenomenon in the context ofmultilingual preference alignment remains largely underexplored. To addressthis issue, we propose CONGRAD, a scalable and effective filtering method thatselects high-quality preference samples with minimal gradient conflicts acrosslanguages. Our method leverages gradient surgery to retain samples aligned withan aggregated multilingual update direction. Additionally, we incorporate asublinear gradient compression strategy that reduces memory overhead duringgradient accumulation. We integrate CONGRAD into self-rewarding framework andevaluate on LLaMA3-8B and Gemma2-2B across 10 languages. Results show thatCONGRAD consistently outperforms strong baselines in both seen and unseenlanguages, with minimal alignment tax.
  </details>

- **[Texture or Semantics? Vision-Language Models Get Lost in Font Recognition](http://arxiv.org/abs/2503.23768v1)**  `arXiv:2503.23768`  
  _Zhecheng Li, Guoxian Song, Yujun Cai, Zhen Xiong, Junsong Yuan, Yiwei Wang_
  <details><summary>Abstract</summary>
  Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguisticcapabilities, achieving impressive performance in various tasks such as imagerecognition and object localization. However, their effectiveness infine-grained tasks remains an open question. In everyday scenarios, individualsencountering design materials, such as magazines, typography tutorials,research papers, or branding content, may wish to identify aestheticallypleasing fonts used in the text. Given their multimodal capabilities and freeaccessibility, many VLMs are often considered potential tools for fontrecognition. This raises a fundamental question: Do VLMs truly possess thecapability to recognize fonts? To investigate this, we introduce the FontRecognition Benchmark (FRB), a compact and well-structured dataset comprising15 commonly used fonts. FRB includes two versions: (i) an easy version, where10 sentences are rendered in different fonts, and (ii) a hard version, whereeach text sample consists of the names of the 15 fonts themselves, introducinga stroop effect that challenges model perception. Through extensive evaluationof various VLMs on font recognition tasks, we arrive at the following keyfindings: (i) Current VLMs exhibit limited font recognition capabilities, withmany state-of-the-art models failing to achieve satisfactory performance. (ii)Few-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefitsin improving font recognition accuracy across different VLMs. (iii) Attentionanalysis sheds light on the inherent limitations of VLMs in capturing semanticfeatures.
  </details>

- **[LANID: LLM-assisted New Intent Discovery](http://arxiv.org/abs/2503.23740v1)**  `arXiv:2503.23740`  
  _Lu Fan, Jiashu Pu, Rongsheng Zhang, Xiao-Ming Wu_
  <details><summary>Abstract</summary>
  Task-oriented Dialogue Systems (TODS) often face the challenge ofencountering new intents. New Intent Discovery (NID) is a crucial task thataims to identify these novel intents while maintaining the capability torecognize existing ones. Previous efforts to adapt TODS to new intents havestruggled with inadequate semantic representation or have depended on externalknowledge, which is often not scalable or flexible. Recently, Large LanguageModels (LLMs) have demonstrated strong zero-shot capabilities; however, theirscale can be impractical for real-world applications that involve extensivequeries. To address the limitations of existing NID methods by leveraging LLMs,we propose LANID, a framework that enhances the semantic representation oflightweight NID encoders with the guidance of LLMs. Specifically, LANID employsthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applicationswith Noise (DBSCAN) algorithms to sample selective utterance pairs from thetraining set. It then queries an LLM to ascertain the relationships betweenthese pairs. The data produced from this process is utilized to design acontrastive fine-tuning task, which is then used to train a small encoder witha contrastive triplet loss. Our experimental results demonstrate the efficacyof the proposed method across three distinct NID datasets, surpassing strongbaselines in both unsupervised and semi-supervised settings. Our code isavailable at https://github.com/floatSDSDS/LANID.
  </details>

- **[AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization](http://arxiv.org/abs/2503.23733v1)**  `arXiv:2503.23733`  
  _Yiyang Du, Xiaochen Wang, Chi Chen, Jiabo Ye, Yiru Wang, Peng Li, et al._
  <details><summary>Abstract</summary>
  Recently, model merging methods have demonstrated powerful strengths incombining abilities on various tasks from multiple Large Language Models(LLMs). While previous model merging methods mainly focus on merginghomogeneous models with identical architecture, they meet challenges whendealing with Multimodal Large Language Models (MLLMs) with inherentheterogeneous property, including differences in model architecture and theasymmetry in the parameter space. In this work, we propose AdaMMS, a novelmodel merging method tailored for heterogeneous MLLMs. Our method tackles thechallenges in three steps: mapping, merging and searching. Specifically, wefirst design mapping function between models to apply model merging on MLLMswith different architecture. Then we apply linear interpolation on modelweights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally inthe hyper-parameter searching step, we propose an unsupervised hyper-parameterselection method for model merging. As the first model merging method capableof merging heterogeneous MLLMs without labeled data, extensive experiments onvarious model combinations demonstrated that AdaMMS outperforms previous modelmerging methods on various vision-language benchmarks.
  </details>

- **[Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models](http://arxiv.org/abs/2503.23714v1)**  `arXiv:2503.23714`  
  _Youmi Ma, Sakae Mizuki, Kazuki Fujii, Taishi Nakamura, Masanari Ohi, Hinari Shimada, et al._
  <details><summary>Abstract</summary>
  Instruction tuning is crucial for enabling Large Language Models (LLMs) tosolve real-world tasks. Prior work has shown the effectiveness ofinstruction-tuning data synthesized solely from LLMs, raising a fundamentalquestion: Do we still need human-originated signals for instruction tuning?This work answers the question affirmatively: we build state-of-the-artinstruction-tuning datasets sourced from human-written instructions, by simplypairing them with LLM-generated responses. LLMs fine-tuned on our datasetsconsistently outperform those fine-tuned on existing ones. Our dataconstruction approach can be easily adapted to other languages; we builddatasets for Japanese and confirm that LLMs tuned with our data reachstate-of-the-art performance. Analyses suggest that instruction-tuning in a newlanguage allows LLMs to follow instructions, while the tuned models exhibit anotable lack of culture-specific knowledge in that language. The datasets andfine-tuned models will be publicly available. Our datasets, synthesized withopen-weight LLMs, are openly distributed under permissive licenses, allowingfor diverse use cases.
  </details>

- **[Mapping Geopolitical Bias in 11 Large Language Models: A Bilingual, Dual-Framing Analysis of U.S.-China Tensions](http://arxiv.org/abs/2503.23688v1)**  `arXiv:2503.23688`  
  _William Guey, Pierrick Bougault, Vitor D. de Moura, Wei Zhang, Jose O. Gomes_
  <details><summary>Abstract</summary>
  This study systematically analyzes geopolitical bias across 11 prominentLarge Language Models (LLMs) by examining their responses to seven criticaltopics in U.S.-China relations. Utilizing a bilingual (English and Chinese) anddual-framing (affirmative and reverse) methodology, we generated 19,712 promptsdesigned to detect ideological leanings in model outputs. Responses werequantitatively assessed on a normalized scale from -2 (strongly Pro-China) to+2 (strongly Pro-U.S.) and categorized according to stance, neutrality, andrefusal rates. The findings demonstrate significant and consistent ideologicalalignments correlated with the LLMs' geographic origins; U.S.-based modelspredominantly favored Pro-U.S. stances, while Chinese-origin models exhibitedpronounced Pro-China biases. Notably, language and prompt framing substantiallyinfluenced model responses, with several LLMs exhibiting stance reversals basedon prompt polarity or linguistic context. Additionally, we introducedcomprehensive metrics to evaluate response consistency across languages andframing conditions, identifying variability and vulnerabilities in modelbehaviors. These results offer practical insights that can guide organizationsand individuals in selecting LLMs best aligned with their operationalpriorities and geopolitical considerations, underscoring the importance ofcareful model evaluation in politically sensitive applications. Furthermore,the research highlights specific prompt structures and linguistic variationsthat can strategically trigger distinct responses from models, revealingmethods for effectively navigating and influencing LLM outputs.
  </details>

- **[MKA: Leveraging Cross-Lingual Consensus for Model Abstention](http://arxiv.org/abs/2503.23687v1)**  `arXiv:2503.23687`  
  _Sharad Duwal_
  <details><summary>Abstract</summary>
  Reliability of LLMs is questionable even as they get better at more tasks. Awider adoption of LLMs is contingent on whether they are usably factual. And ifthey are not, on whether they can properly calibrate their confidence in theirresponses. This work focuses on utilizing the multilingual knowledge of an LLMto inform its decision to abstain or answer when prompted. We develop amultilingual pipeline to calibrate the model's confidence and let it abstainwhen uncertain. We run several multilingual models through the pipeline toprofile them across different languages. We find that the performance of thepipeline varies by model and language, but that in general they benefit fromit. This is evidenced by the accuracy improvement of $71.2\%$ for Bengali overa baseline performance without the pipeline. Even a high-resource language likeEnglish sees a $15.5\%$ improvement. These results hint at possible furtherimprovements.
  </details>

- **[Large Language Models Pass the Turing Test](http://arxiv.org/abs/2503.23674v1)**  `arXiv:2503.23674`  
  _Cameron R. Jones, Benjamin K. Bergen_
  <details><summary>Abstract</summary>
  We evaluated 4 systems (ELIZA, GPT-4o, LLaMa-3.1-405B, and GPT-4.5) in tworandomised, controlled, and pre-registered Turing tests on independentpopulations. Participants had 5 minute conversations simultaneously withanother human participant and one of these systems before judging whichconversational partner they thought was human. When prompted to adopt ahumanlike persona, GPT-4.5 was judged to be the human 73% of the time:significantly more often than interrogators selected the real humanparticipant. LLaMa-3.1, with the same prompt, was judged to be the human 56% ofthe time -- not significantly more or less often than the humans they werebeing compared to -- while baseline models (ELIZA and GPT-4o) achieved winrates significantly below chance (23% and 21% respectively). The resultsconstitute the first empirical evidence that any artificial system passes astandard three-party Turing test. The results have implications for debatesabout what kind of intelligence is exhibited by Large Language Models (LLMs),and the social and economic impacts these systems are likely to have.
  </details>

- **[WHERE and WHICH: Iterative Debate for Biomedical Synthetic Data Augmentation](http://arxiv.org/abs/2503.23673v1)**  `arXiv:2503.23673`  
  _Zhengyi Zhao, Shubo Zhang, Bin Liang, Binyang Li, Kam-Fai Wong_
  <details><summary>Abstract</summary>
  In Biomedical Natural Language Processing (BioNLP) tasks, such as RelationExtraction, Named Entity Recognition, and Text Classification, the scarcity ofhigh-quality data remains a significant challenge. This limitation poisonslarge language models to correctly understand relationships between biologicalentities, such as molecules and diseases, or drug interactions, and furtherresults in potential misinterpretation of biomedical documents. To address thisissue, current approaches generally adopt the Synthetic Data Augmentationmethod which involves similarity computation followed by word replacement, butcounterfactual data are usually generated. As a result, these methods disruptmeaningful word sets or produce sentences with meanings that deviatesubstantially from the original context, rendering them ineffective inimproving model performance. To this end, this paper proposes abiomedical-dedicated rationale-based synthetic data augmentation method. Beyondthe naive lexicon similarity, specific bio-relation similarity is measured tohold the augmented instance having a strong correlation with bio-relationinstead of simply increasing the diversity of augmented data. Moreover, amulti-agents-involved reflection mechanism helps the model iterativelydistinguish different usage of similar entities to escape falling into themis-replace trap. We evaluate our method on the BLURB and BigBIO benchmark,which includes 9 common datasets spanning four major BioNLP tasks. Ourexperimental results demonstrate consistent performance improvements across alltasks, highlighting the effectiveness of our approach in addressing thechallenges associated with data scarcity and enhancing the overall performanceof biomedical NLP models.
  </details>

- **[CrossFormer: Cross-Segment Semantic Fusion for Document Segmentation](http://arxiv.org/abs/2503.23671v1)**  `arXiv:2503.23671`  
  _Tongke Ni, Yang Fan, Junru Zhou, Xiangping Wu, Qingcai Chen_
  <details><summary>Abstract</summary>
  Text semantic segmentation involves partitioning a document into multipleparagraphs with continuous semantics based on the subject matter, contextualinformation, and document structure. Traditional approaches have typicallyrelied on preprocessing documents into segments to address input lengthconstraints, resulting in the loss of critical semantic information acrosssegments. To address this, we present CrossFormer, a transformer-based modelfeaturing a novel cross-segment fusion module that dynamically models latentsemantic dependencies across document segments, substantially elevatingsegmentation accuracy. Additionally, CrossFormer can replace rule-based chunkmethods within the Retrieval-Augmented Generation (RAG) system, producing moresemantically coherent chunks that enhance its efficacy. Comprehensiveevaluations confirm CrossFormer's state-of-the-art performance on public textsemantic segmentation datasets, alongside considerable gains on RAG benchmarks.
  </details>

- **[EQ-Negotiator: An Emotion-Reasoning LLM Agent in Credit Dialogues](http://arxiv.org/abs/2503.21080v3)**  `arXiv:2503.21080`  
  _Yuhan Liu, Yunbo Long_
  <details><summary>Abstract</summary>
  While large language model (LLM)-based chatbots have been applied foreffective engagement in credit dialogues, their capacity for dynamic emotionalexpression remains limited. Current agents primarily rely on passive empathyrather than affective reasoning. For instance, when faced with persistentclient negativity, the agent should employ strategic emotional adaptation byexpressing measured anger to discourage counterproductive behavior and guidethe conversation toward resolution. This context-aware emotional modulation isessential for imitating the nuanced decision-making of human negotiators. Thispaper introduces an EQ-negotiator that combines emotion sensing frompre-trained language models (PLMs) with emotional reasoning based on GameTheory and Hidden Markov Models. It takes into account both the current andhistorical emotions of the client to better manage and address negativeemotions during interactions. By fine-tuning pre-trained language models (PLMs)on public emotion datasets and validating them on the credit dialogue datasets,our approach enables LLM-based agents to effectively capture shifts in clientemotions and dynamically adjust their response tone based on our emotiondecision policies in real-world financial negotiations. This EQ-negotiator canalso help credit agencies foster positive client relationships, enhancingsatisfaction in credit services.
  </details>

- **[Surgical Action Planning with Large Language Models](http://arxiv.org/abs/2503.18296v2)**  `arXiv:2503.18296`  
  _Mengya Xu, Zhongzhen Huang, Jie Zhang, Xiaofan Zhang, Qi Dou_
  <details><summary>Abstract</summary>
  In robot-assisted minimally invasive surgery, we introduce the SurgicalAction Planning (SAP) task, which generates future action plans from visualinputs to address the absence of intraoperative predictive planning in currentintelligent applications. SAP shows great potential for enhancingintraoperative guidance and automating procedures. However, it faces challengessuch as understanding instrument-action relationships and tracking surgicalprogress. Large Language Models (LLMs) show promise in understanding surgicalvideo content but remain underexplored for predictive decision-making in SAP,as they focus mainly on retrospective analysis. Challenges like data privacy,computational demands, and modality-specific constraints further highlightsignificant research gaps. To tackle these challenges, we introduce LLM-SAP, aLarge Language Models-based Surgical Action Planning framework that predictsfuture actions and generates text responses by interpreting natural languageprompts of surgical goals. The text responses potentially support surgicaleducation, intraoperative decision-making, procedure documentation, and skillanalysis. LLM-SAP integrates two novel modules: the Near-History Focus MemoryModule (NHF-MM) for modeling historical states and the prompts factory foraction planning. We evaluate LLM-SAP on our constructed CholecT50-SAP datasetusing models like Qwen2.5 and Qwen2-VL, demonstrating its effectiveness innext-action prediction. Pre-trained LLMs are tested in a zero-shot setting, andsupervised fine-tuning (SFT) with LoRA is implemented. Our experiments showthat Qwen2.5-72B-SFT surpasses Qwen2.5-72B with a 19.3% higher accuracy.
  </details>

- **[Self-Vocabularizing Training for Neural Machine Translation](http://arxiv.org/abs/2503.13837v3)**  `arXiv:2503.13837`  
  _Pin-Jie Lin, Ernie Chang_
  <details><summary>Abstract</summary>
  Past vocabulary learning techniques identify relevant vocabulary beforetraining, relying on statistical and entropy-based assumptions that largelyneglect the role of model training. Empirically, we observe that trainedtranslation models are induced to use a byte-pair encoding (BPE) vocabularysubset distinct from the original BPE vocabulary, leading to performanceimprovements when retrained with the induced vocabulary. In this paper, weanalyze this discrepancy in neural machine translation by examining vocabularyand entropy shifts during self-training--where each iteration generates alabeled dataset by pairing source sentences with the model's predictions todefine a new vocabulary. Building on these insights, we proposeself-vocabularizing training, an iterative method that self-selects a smaller,more optimal vocabulary, yielding up to a 1.49 BLEU improvement. Moreover, wefind that deeper model architectures lead to both an increase in unique tokenusage and a 6-8% reduction in vocabulary size.
  </details>

- **[TablePilot: Recommending Human-Preferred Tabular Data Analysis with Large Language Models](http://arxiv.org/abs/2503.13262v4)**  `arXiv:2503.13262`  
  _Deyin Yi, Yihao Liu, Lang Cao, Mengyu Zhou, Haoyu Dong, Shi Han, et al._
  <details><summary>Abstract</summary>
  Tabular data analysis is crucial in many scenarios, yet efficientlyidentifying the most relevant data analysis queries and results for a new tableremains a significant challenge. The complexity of tabular data, diverseanalytical operations, and the demand for high-quality analysis make theprocess tedious. To address these challenges, we aim to recommendquery-code-result triplets tailored for new tables in tabular data analysisworkflows. In this paper, we present TablePilot, a pioneering tabular dataanalysis framework leveraging large language models to autonomously generatecomprehensive and superior analytical results without relying on user profilesor prior interactions. The framework incorporates key designs in analysispreparation and analysis optimization to enhance accuracy. Additionally, wepropose Rec-Align, a novel method to further improve recommendation quality andbetter align with human preferences. Experiments on DART, a datasetspecifically designed for comprehensive tabular data analysis recommendation,demonstrate the effectiveness of our framework. Based on GPT-4o, the tunedTablePilot achieves 77.0% top-5 recommendation recall. Human evaluationsfurther highlight its effectiveness in optimizing tabular data analysisworkflows.
  </details>

- **[DCAD-2000: A Multilingual Dataset across 2000+ Languages with Data Cleaning as Anomaly Detection](http://arxiv.org/abs/2502.11546v2)**  `arXiv:2502.11546`  
  _Yingli Shen, Wen Lai, Shuo Wang, Xueren Zhang, Kangyang Luo, Alexander Fraser, et al._
  <details><summary>Abstract</summary>
  The rapid development of multilingual large language models (LLMs) highlightsthe need for high-quality, diverse, and clean multilingual datasets. In thispaper, we introduce DCAD-2000 (Data Cleaning as Anomaly Detection), alarge-scale multilingual corpus built using newly extracted Common Crawl dataand existing multilingual datasets. DCAD-2000 includes over 2,282 languages,46.72TB of data, and 8.63 billion documents, spanning 155 high- andmedium-resource languages and 159 writing scripts. To overcome the limitationsof current data cleaning methods, which rely on manual heuristic thresholds, wepropose reframing data cleaning as an anomaly detection task. This dynamicfiltering approach significantly enhances data quality by identifying andremoving noisy or anomalous content. We evaluate the quality of DCAD-2000 onthe FineTask benchmark, demonstrating substantial improvements in multilingualdataset quality and task performance.
  </details>

- **[Concept Navigation and Classification via Open-Source Large Language Model Processing](http://arxiv.org/abs/2502.04756v2)**  `arXiv:2502.04756`  
  _Ma√´l Kubli_
  <details><summary>Abstract</summary>
  This paper presents a novel methodological framework for detecting andclassifying latent constructs, including frames, narratives, and topics, fromtextual data using Open-Source Large Language Models (LLMs). The proposedhybrid approach combines automated summarization with human-in-the-loopvalidation to enhance the accuracy and interpretability of constructidentification. By employing iterative sampling coupled with expert refinement,the framework guarantees methodological robustness and ensures conceptualprecision. Applied to diverse data sets, including AI policy debates, newspaperarticles on encryption, and the 20 Newsgroups data set, this approachdemonstrates its versatility in systematically analyzing complex politicaldiscourses, media framing, and topic classification tasks.
  </details>

- **[Evil twins are not that evil: Qualitative insights into machine-generated prompts](http://arxiv.org/abs/2412.08127v3)**  `arXiv:2412.08127`  
  _Nathana√´l Carraz Rakotonirina, Corentin Kervadec, Francesca Franzon, Marco Baroni_
  <details><summary>Abstract</summary>
  It has been widely observed that language models (LMs) respond in predictableways to algorithmically generated prompts that are seemingly unintelligible.This is both a sign that we lack a full understanding of how LMs work, and apractical challenge, because opaqueness can be exploited for harmful uses ofLMs, such as jailbreaking. We present the first thorough analysis of opaquemachine-generated prompts, or autoprompts, pertaining to 6 LMs of differentsizes and families. We find that machine-generated prompts are characterized bya last token that is often intelligible and strongly affects the generation. Asmall but consistent proportion of the previous tokens are prunable, probablyappearing in the prompt as a by-product of the fact that the optimizationprocess fixes the number of tokens. The remaining tokens fall into twocategories: filler tokens, which can be replaced with semantically unrelatedsubstitutes, and keywords, that tend to have at least a loose semantic relationwith the generation, although they do not engage in well-formed syntacticrelations with it. Additionally, human experts can reliably identify the mostinfluential tokens in an autoprompt a posteriori, suggesting these prompts arenot entirely opaque. Finally, some of the ablations we applied to autopromptsyield similar effects in natural language inputs, suggesting that autopromptsemerge naturally from the way LMs process linguistic inputs in general.
  </details>

- **[EmoVerse: Exploring Multimodal Large Language Models for Sentiment and Emotion Understanding](http://arxiv.org/abs/2412.08049v3)**  `arXiv:2412.08049`  
  _Ao Li, Longwei Xu, Chen Ling, Jinghui Zhang, Pengwei Wang_
  <details><summary>Abstract</summary>
  Sentiment and emotion understanding are essential to applications such ashuman-computer interaction and depression detection. While Multimodal LargeLanguage Models (MLLMs) demonstrate robust general capabilities, they faceconsiderable challenges in the field of affective computing, particularly indetecting subtle facial expressions and handling complex emotion-related tasks,such as emotion reason inference and understanding emotions in long-contextscenarios. Furthermore, there is a lack of a unified MLLM that can effectivelyhandle both sentiment and emotion-related tasks. To address these challenges,we explore multi-task training strategies for MLLMs in affective computing andintroduce Emotion Universe (EmoVerse), an MLLM designed to handle a broadspectrum of sentiment and emotion-related tasks. In addition, EmoVerse iscapable of deeply analyzing the underlying causes of emotional states. We alsointroduce the Affective Multitask (AMT) Dataset, which supports multimodalsentiment analysis, multimodal emotion recognition, facial expressionrecognition, emotion reason inference, and emotion cause-pair extraction tasks.Extensive experiments demonstrate that EmoVerse outperforms existing methods,achieving state-of-the-art results in sentiment and emotion-related tasks. Thecode is available at https://github.com/liaolea/EmoVerse.
  </details>

- **[Truth or Mirage? Towards End-to-End Factuality Evaluation with LLM-Oasis](http://arxiv.org/abs/2411.19655v3)**  `arXiv:2411.19655`  
  _Alessandro Scir√®, Andrei Stefan Bejgu, Simone Tedeschi, Karim Ghonim, Federico Martelli, Roberto Navigli_
  <details><summary>Abstract</summary>
  After the introduction of Large Language Models (LLMs), there have beensubstantial improvements in the performance of Natural Language Generation(NLG) tasks, including Text Summarization and Machine Translation. However,LLMs still produce outputs containing hallucinations, that is, content notgrounded in factual information. Therefore, developing methods to assess thefactuality of LLMs has become urgent.  Indeed, resources for factuality evaluation have recently emerged. Althoughchallenging, these resources face one or more of the following limitations: (i)they are tailored to a specific task or domain; (ii) they are limited in size,thereby preventing the training of new factuality evaluators; (iii) they aredesigned for simpler verification tasks, such as claim verification.  To address these issues, we introduce LLM-Oasis, to the best of our knowledgethe largest resource for training end-to-end factuality evaluators. LLM-Oasisis constructed by extracting claims from Wikipedia, falsifying a subset ofthese claims, and generating pairs of factual and unfactual texts. We then relyon human annotators to both validate the quality of our dataset and to create agold standard test set for benchmarking factuality evaluation systems.  Our experiments demonstrate that LLM-Oasis presents a significant challengefor state-of-the-art LLMs, with GPT-4o achieving up to 60% accuracy in ourproposed end-to-end factuality evaluation task, highlighting its potential todrive future research in the field.
  </details>

- **[How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?](http://arxiv.org/abs/2411.03962v5)**  `arXiv:2411.03962`  
  _Zhangcheng Qiang, Kerry Taylor, Weiqing Wang_
  <details><summary>Abstract</summary>
  The classic text preprocessing pipeline, comprising Tokenisation,Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has beenimplemented in many systems for syntactic ontology matching (OM). However, thelack of standardisation in text preprocessing creates diversity in mappingresults. In this paper we investigate the effect of the text preprocessingpipeline on syntactic OM in 8 Ontology Alignment Evaluation Initiative (OAEI)tracks with 49 distinct alignments. We find that Phase 1 text preprocessing(Tokenisation and Normalisation) is more effective than Phase 2 textpreprocessing (Stop Words Removal and Stemming/Lemmatisation). To repair theunwanted false mappings caused by Phase 2 text preprocessing, we propose anovel context-based pipeline repair approach that employs a post hoc check tofind common words that cause false mappings. These words are stored in areserved word set and applied in text preprocessing. The experimental resultsshow that our approach improves the matching correctness and the overallmatching performance. We then consider the broader integration of the classictext preprocessing pipeline with modern large language models (LLMs) for OM. Werecommend that (1) the text preprocessing pipeline be injected via functioncalling into LLMs to avoid the tendency towards unstable true mappings producedby LLM prompting; or (2) LLMs be used to repair non-existent andcounter-intuitive false mappings generated by the text preprocessing pipeline.
  </details>

- **[SwiftCoder: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning](http://arxiv.org/abs/2410.10209v3)**  `arXiv:2410.10209`  
  _Dong Huang, Guangtao Zeng, Jianbo Dai, Meng Luo, Han Weng, Yuhao Qing, et al._
  <details><summary>Abstract</summary>
  As large language models (LLMs) play an increasingly important role in codegeneration, enhancing both correctness and efficiency has become crucial.Current methods primarily focus on correctness, often overlooking efficiency.To address this gap, we introduce \dataset to improve both aspects byfine-tuning LLMs on a high-quality dataset comprising correct and efficientcode samples. Our methodology involves leveraging multiple LLMs to generatediverse candidate code solutions for various tasks across different programminglanguages. We then evaluate these solutions by directly measuring theirexecution time and memory usage through local execution. The code solution withthe lowest execution time and memory consumption is selected as the finaloutput for each task. Experimental results demonstrate significant improvementswhen fine-tuning with \dataset. For instance, Qwen2.5-Coder-7B-Instruct'spass@1 score increases from 44.8\% to 57.7\%, while the average execution timefor correct tasks decreases by 48.4\%. \dataset offers a scalable and effectivesolution for advancing AI-driven code generation, benefiting both softwaredevelopment and computational problem-solving. The source code of Effi-Code wasreleased in https://github.com/huangd1999/Effi-Code.
  </details>

- **[ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery](http://arxiv.org/abs/2410.05080v3)**  `arXiv:2410.05080`  
  _Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, et al._
  <details><summary>Abstract</summary>
  The advancements of large language models (LLMs) have piqued growing interestin developing LLM-based language agents to automate scientific discoveryend-to-end, which has sparked both excitement and skepticism about their truecapabilities. In this work, we call for rigorous assessment of agents onindividual tasks in a scientific workflow before making bold claims onend-to-end automation. To this end, we present ScienceAgentBench, a newbenchmark for evaluating language agents for data-driven scientific discovery.To ensure the scientific authenticity and real-world relevance of ourbenchmark, we extract 102 tasks from 44 peer-reviewed publications in fourdisciplines and engage nine subject matter experts to validate them. We unifythe target output for every task to a self-contained Python program file andemploy an array of evaluation metrics to examine the generated programs,execution results, and costs. Each task goes through multiple rounds of manualvalidation by annotators and subject matter experts to ensure its annotationquality and scientific plausibility. We also propose two effective strategiesto mitigate data contamination concerns. Using ScienceAgentBench, we evaluatefive open-weight and proprietary LLMs, each with three frameworks: directprompting, OpenHands CodeAct, and self-debug. Given three attempts for eachtask, the best-performing agent can only solve 32.4% of the tasks independentlyand 34.3% with expert-provided knowledge. In addition, we evaluate OpenAIo1-preview with direct prompting and self-debug, which can boost theperformance to 42.2%, demonstrating the effectiveness of increasinginference-time compute but with more than 10 times the cost of other LLMs.Still, our results underscore the limitations of current language agents ingenerating code for data-driven discovery, let alone end-to-end automation forscientific research.
  </details>

- **[Banyan: Improved Representation Learning with Explicit Structure](http://arxiv.org/abs/2407.17771v3)**  `arXiv:2407.17771`  
  _Mattia Opper, N. Siddharth_
  <details><summary>Abstract</summary>
  We present Banyan, a model that efficiently learns semantic representationsby leveraging explicit hierarchical structure. While transformers excel atscale, they struggle in low-resource settings. Conversely recent structuredmodels have shown promise as efficient learners, but lack performance. Banyanbridges this gap with two key innovations: an entangled hierarchical treestructure and diagonalized message passing, enabling it to outperform largertransformer models with just 14 non-embedding parameters. It excels inlow-resource settings, offering a viable alternative for under-representedlanguages and highlighting its potential for efficient, interpretable NLP inresource-constrained environments.
  </details>

- **[Cascade Reward Sampling for Efficient Decoding-Time Alignment](http://arxiv.org/abs/2406.16306v2)**  `arXiv:2406.16306`  
  _Bolian Li, Yifan Wang, Anamika Lochab, Ananth Grama, Ruqi Zhang_
  <details><summary>Abstract</summary>
  Aligning large language models (LLMs) with human preferences is essential fortheir applications. Recently, decoding-time alignment has emerged as aneffective plug-and-play technique that avoids fine-tuning model parameters.This approach retains the general utility of pretrained LLMs but often suffersfrom significant inefficiencies during decoding, primarily due to wasted tokengeneration and excessive reward evaluations. To address these challenges, weintroduce Cascade Reward Sampling (CARDS) to resolve both efficiencybottlenecks in decoding-time alignment. Specifically, we develop asegment-level rejection sampling algorithm that minimizes redundantcomputations of both LLMs and reward models (RMs). Central to CARDS is anuncertainty-based segmentation mechanism, which ensures the accuracy of RMsevaluations on incomplete segments. Furthermore, we provide a detailed analysisof reward scores on segments to elucidate the improved alignment performance.Experimental results demonstrate that CARDS significantly improves decodingefficiency, alignment quality, and general utility compared to existingdecoding-time alignment methods, achieving approximately a 70% reduction indecoding time and over 90% win-ties in utility and safety benchmarks.
  </details>

- **[Training-Free Exponential Context Extension via Cascading KV Cache](http://arxiv.org/abs/2406.17808v4)**  `arXiv:2406.17808`  
  _Jeffrey Willette, Heejun Lee, Youngwan Lee, Myeongjae Jeon, Sung Ju Hwang_
  <details><summary>Abstract</summary>
  The transformer's context window is vital for tasks such as few-shot learningand conditional generation as it preserves previous tokens for active memory.However, as the context lengths increase, the computational costs growquadratically, hindering the deployment of large language models (LLMs) inreal-world, long sequence scenarios. Although some recent key-value caching (KVCache) methods offer linear inference complexity, they naively manage thestored context, prematurely evicting tokens and losing valuable information.Moreover, they lack an optimized prefill/prompt stage strategy, resulting inhigher latency than even quadratic attention for realistic context sizes. Inresponse, we introduce a novel mechanism that leverages cascading sub-cachebuffers to selectively retain the most relevant tokens, enabling the model tomaintain longer context histories without increasing the cache size. Ourapproach outperforms linear caching baselines across key benchmarks, includingstreaming perplexity, question answering, book summarization, and passkeyretrieval, where it retains better retrieval accuracy at 1M tokens after fourdoublings of the cache size of 65K. Additionally, our method reduces prefillstage latency by a factor of 6.8 when compared to flash attention on 1M tokens.These innovations not only enhance the computational efficiency of LLMs butalso pave the way for their effective deployment in resource-constrainedenvironments, enabling large-scale, real-time applications with significantlyreduced latency.
  </details>

[‚Üë Back to Top](#-full-archive)

</details>

### Computer Vision and Pattern Recognition üì∏

<details open><summary>Click to Collapse</summary>

- **[Easi3R: Estimating Disentangled Motion from DUSt3R Without Training](http://arxiv.org/abs/2503.24391v1)**  `arXiv:2503.24391`  
  _Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen_
  <details><summary>Abstract</summary>
  Recent advances in DUSt3R have enabled robust estimation of dense pointclouds and camera parameters of static scenes, leveraging Transformer networkarchitectures and direct supervision on large-scale 3D datasets. In contrast,the limited scale and diversity of available 4D datasets present a majorbottleneck for training a highly generalizable 4D model. This constraint hasdriven conventional 4D methods to fine-tune 3D models on scalable dynamic videodata with additional geometric priors such as optical flow and depths. In thiswork, we take an opposite path and introduce Easi3R, a simple yet efficienttraining-free method for 4D reconstruction. Our approach applies attentionadaptation during inference, eliminating the need for from-scratch pre-trainingor network fine-tuning. We find that the attention layers in DUSt3R inherentlyencode rich information about camera and object motion. By carefullydisentangling these attention maps, we achieve accurate dynamic regionsegmentation, camera pose estimation, and 4D dense point map reconstruction.Extensive experiments on real-world dynamic videos demonstrate that ourlightweight attention adaptation significantly outperforms previousstate-of-the-art methods that are trained or finetuned on extensive dynamicdatasets. Our code is publicly available for research purpose athttps://easi3r.github.io/
  </details>

- **[SU-YOLO: Spiking Neural Network for Efficient Underwater Object Detection](http://arxiv.org/abs/2503.24389v1)**  `arXiv:2503.24389`  
  _Chenyang Li, Wenxuan Liu, Guoqiang Gong, Xiaobo Ding, Xian Zhong_
  <details><summary>Abstract</summary>
  Underwater object detection is critical for oceanic research and industrialsafety inspections. However, the complex optical environment and the limitedresources of underwater equipment pose significant challenges to achieving highaccuracy and low power consumption. To address these issues, we propose SpikingUnderwater YOLO (SU-YOLO), a Spiking Neural Network (SNN) model. Leveraging thelightweight and energy-efficient properties of SNNs, SU-YOLO incorporates anovel spike-based underwater image denoising method based solely on integeraddition, which enhances the quality of feature maps with minimal computationaloverhead. In addition, we introduce Separated Batch Normalization (SeBN), atechnique that normalizes feature maps independently across multiple time stepsand is optimized for integration with residual structures to capture thetemporal dynamics of SNNs more effectively. The redesigned spiking residualblocks integrate the Cross Stage Partial Network (CSPNet) with the YOLOarchitecture to mitigate spike degradation and enhance the model's featureextraction capabilities. Experimental results on URPC2019 underwater datasetdemonstrate that SU-YOLO achieves mAP of 78.8% with 6.97M parameters and anenergy consumption of 2.98 mJ, surpassing mainstream SNN models in bothdetection accuracy and computational efficiency. These results underscore thepotential of SNNs for engineering applications. The code is available inhttps://github.com/lwxfight/snn-underwater.
  </details>

- **[Consistent Subject Generation via Contrastive Instantiated Concepts](http://arxiv.org/abs/2503.24387v1)**  `arXiv:2503.24387`  
  _Lee Hsin-Ying, Kelvin C. K. Chan, Ming-Hsuan Yang_
  <details><summary>Abstract</summary>
  While text-to-image generative models can synthesize diverse and faithfulcontents, subject variation across multiple creations limits the application inlong content generation. Existing approaches require time-consuming tuning,references for all subjects, or access to other creations. We introduceContrastive Concept Instantiation (CoCoIns) to effectively synthesizeconsistent subjects across multiple independent creations. The frameworkconsists of a generative model and a mapping network, which transforms inputlatent codes into pseudo-words associated with certain instances of concepts.Users can generate consistent subjects with the same latent codes. To constructsuch associations, we propose a contrastive learning approach that trains thenetwork to differentiate the combination of prompts and latent codes. Extensiveevaluations of human faces with a single subject show that CoCoIns performscomparably to existing methods while maintaining higher flexibility. We alsodemonstrate the potential of extending CoCoIns to multiple subjects and otherobject categories.
  </details>

- **[Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views](http://arxiv.org/abs/2503.24382v1)**  `arXiv:2503.24382`  
  _Chong Bao, Xiyu Zhang, Zehao Yu, Jiale Shi, Guofeng Zhang, Songyou Peng, et al._
  <details><summary>Abstract</summary>
  Neural rendering has demonstrated remarkable success in high-quality 3Dneural reconstruction and novel view synthesis with dense input views andaccurate poses. However, applying it to extremely sparse, unposed views inunbounded 360{\deg} scenes remains a challenging problem. In this paper, wepropose a novel neural rendering framework to accomplish the unposed andextremely sparse-view 3D reconstruction in unbounded 360{\deg} scenes. Toresolve the spatial ambiguity inherent in unbounded scenes with sparse inputviews, we propose a layered Gaussian-based representation to effectively modelthe scene with distinct spatial layers. By employing a dense stereoreconstruction model to recover coarse geometry, we introduce a layer-specificbootstrap optimization to refine the noise and fill occluded regions in thereconstruction. Furthermore, we propose an iterative fusion of reconstructionand generation alongside an uncertainty-aware training approach to facilitatemutual conditioning and enhancement between these two processes. Comprehensiveexperiments show that our approach outperforms existing state-of-the-artmethods in terms of rendering quality and surface reconstruction accuracy.Project page: https://zju3dv.github.io/free360/
  </details>

- **[UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving](http://arxiv.org/abs/2503.24381v1)**  `arXiv:2503.24381`  
  _Yuping Wang, Xiangyu Huang, Xiaokang Sun, Mingxuan Yan, Shuo Xing, Zhengzhong Tu, et al._
  <details><summary>Abstract</summary>
  We introduce UniOcc, a comprehensive, unified benchmark for occupancyforecasting (i.e., predicting future occupancies based on historicalinformation) and current-frame occupancy prediction from camera images. UniOccunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) andhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3Doccupancy labels with per-voxel flow annotations and support for cooperativeautonomous driving. In terms of evaluation, unlike existing studies that relyon suboptimal pseudo labels for evaluation, UniOcc incorporates novel metricsthat do not depend on ground-truth occupancy, enabling robust assessment ofadditional aspects of occupancy quality. Through extensive experiments onstate-of-the-art models, we demonstrate that large-scale, diverse training dataand explicit flow information significantly enhance occupancy prediction andforecasting performance.
  </details>

- **[Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation](http://arxiv.org/abs/2503.24379v1)**  `arXiv:2503.24379`  
  _Shengqiong Wu, Weicai Ye, Jiahao Wang, Quande Liu, Xintao Wang, Pengfei Wan, et al._
  <details><summary>Abstract</summary>
  To address the bottleneck of accurate user intent interpretation within thecurrent video generation community, we present Any2Caption, a novel frameworkfor controllable video generation under any condition. The key idea is todecouple various condition interpretation steps from the video synthesis step.By leveraging modern multimodal large language models (MLLMs), Any2Captioninterprets diverse inputs--text, images, videos, and specialized cues such asregion, motion, and camera poses--into dense, structured captions that offerbackbone video generators with better guidance. We also introduce Any2CapIns, alarge-scale dataset with 337K instances and 407K conditions forany-condition-to-caption instruction tuning. Comprehensive evaluationsdemonstrate significant improvements of our system in controllability and videoquality across various aspects of existing video generation models. ProjectPage: https://sqwu.top/Any2Cap/
  </details>

- **[Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1](http://arxiv.org/abs/2503.24376v1)**  `arXiv:2503.24376`  
  _Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Lu Qiu, Ying Shan, et al._
  <details><summary>Abstract</summary>
  Recent advancements in Chain of Thought (COT) generation have significantlyimproved the reasoning capabilities of Large Language Models (LLMs), withreinforcement learning (RL) emerging as an effective post-training approach.Multimodal Large Language Models (MLLMs) inherit this reasoning potential butremain underexplored in tasks requiring both perception and logical reasoning.To address this, we introduce SEED-Bench-R1, a benchmark designed tosystematically evaluate post-training methods for MLLMs in video understanding.It includes intricate real-world videos and complex everyday planning tasks inthe format of multiple-choice questions, requiring sophisticated perception andreasoning. SEED-Bench-R1 assesses generalization through a three-levelhierarchy: in-distribution, cross-environment, and cross-environment-taskscenarios, equipped with a large-scale training dataset with easily verifiableground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RLwith supervised fine-tuning (SFT), demonstrating RL's data efficiency andsuperior performance on both in-distribution and out-of-distribution tasks,even outperforming SFT on general video understanding benchmarks likeLongVideoBench. Our detailed analysis reveals that RL enhances visualperception but often produces less logically coherent reasoning chains. Weidentify key limitations such as inconsistent reasoning and overlooked visualcues, and suggest future improvements in base model reasoning, reward modeling,and RL robustness against noisy signals.
  </details>

- **[ERUPT: Efficient Rendering with Unposed Patch Transformer](http://arxiv.org/abs/2503.24374v1)**  `arXiv:2503.24374`  
  _Maxim V. Shugaev, Vincent Chen, Maxim Karrenbach, Kyle Ashley, Bridget Kennedy, Naresh P. Cuntoor_
  <details><summary>Abstract</summary>
  This work addresses the problem of novel view synthesis in diverse scenesfrom small collections of RGB images. We propose ERUPT (Efficient Renderingwith Unposed Patch Transformer) a state-of-the-art scene reconstruction modelcapable of efficient scene rendering using unposed imagery. We introducepatch-based querying, in contrast to existing pixel-based queries, to reducethe compute required to render a target view. This makes our model highlyefficient both during training and at inference, capable of rendering at 600fps on commercial hardware. Notably, our model is designed to use a learnedlatent camera pose which allows for training using unposed targets in datasetswith sparse or inaccurate ground truth camera pose. We show that our approachcan generalize on large real-world data and introduce a new benchmark dataset(MSVS-1M) for latent view synthesis using street-view imagery collected fromMapillary. In contrast to NeRF and Gaussian Splatting, which require denseimagery and precise metadata, ERUPT can render novel views of arbitrary sceneswith as few as five unposed input images. ERUPT achieves better rendered imagequality than current state-of-the-art methods for unposed image synthesistasks, reduces labeled data requirements by ~95\% and decreases computationalrequirements by an order of magnitude, providing efficient novel view synthesisfor diverse real-world scenes.
  </details>

- **[Adapting Vision Foundation Models for Real-time Ultrasound Image Segmentation](http://arxiv.org/abs/2503.24368v1)**  `arXiv:2503.24368`  
  _Xiaoran Zhang, Eric Z. Chen, Lin Zhao, Xiao Chen, Yikang Liu, Boris Maihe, et al._
  <details><summary>Abstract</summary>
  We propose a novel approach that adapts hierarchical vision foundation modelsfor real-time ultrasound image segmentation. Existing ultrasound segmentationmethods often struggle with adaptability to new tasks, relying on costly manualannotations, while real-time approaches generally fail to matchstate-of-the-art performance. To overcome these limitations, we introduce anadaptive framework that leverages the vision foundation model Hiera to extractmulti-scale features, interleaved with DINOv2 representations to enhance visualexpressiveness. These enriched features are then decoded to produce precise androbust segmentation. We conduct extensive evaluations on six public datasetsand one in-house dataset, covering both cardiac and thyroid ultrasoundsegmentation. Experiments show that our approach outperforms state-of-the-artmethods across multiple datasets and excels with limited supervision,surpassing nnUNet by over 20\% on average in the 1\% and 10\% data settings.Our method achieves $\sim$77 FPS inference speed with TensorRT on a single GPU,enabling real-time clinical applications.
  </details>

- **[StochasticSplats: Stochastic Rasterization for Sorting-Free 3D Gaussian Splatting](http://arxiv.org/abs/2503.24366v1)**  `arXiv:2503.24366`  
  _Shakiba Kheradmand, Delio Vicini, George Kopanas, Dmitry Lagun, Kwang Moo Yi, Mark Matthews, et al._
  <details><summary>Abstract</summary>
  3D Gaussian splatting (3DGS) is a popular radiance field method, with manyapplication-specific extensions. Most variants rely on the same core algorithm:depth-sorting of Gaussian splats then rasterizing in primitive order. Thisensures correct alpha compositing, but can cause rendering artifacts due tobuilt-in approximations. Moreover, for a fixed representation, sorted renderingoffers little control over render cost and visual fidelity. For example, andcounter-intuitively, rendering a lower-resolution image is not necessarilyfaster. In this work, we address the above limitations by combining 3D Gaussiansplatting with stochastic rasterization. Concretely, we leverage an unbiasedMonte Carlo estimator of the volume rendering equation. This removes the needfor sorting, and allows for accurate 3D blending of overlapping Gaussians. Thenumber of Monte Carlo samples further imbues 3DGS with a way to trade offcomputation time and quality. We implement our method using OpenGL shaders,enabling efficient rendering on modern GPU hardware. At a reasonable visualquality, our method renders more than four times faster than sortedrasterization.
  </details>

- **[InstructRestore: Region-Customized Image Restoration with Human Instructions](http://arxiv.org/abs/2503.24357v1)**  `arXiv:2503.24357`  
  _Shuaizheng Liu, Jianqi Ma, Lingchen Sun, Xiangtao Kong, Lei Zhang_
  <details><summary>Abstract</summary>
  Despite the significant progress in diffusion prior-based image restoration,most existing methods apply uniform processing to the entire image, lacking thecapability to perform region-customized image restoration according to userinstructions. In this work, we propose a new framework, namely InstructRestore,to perform region-adjustable image restoration following human instructions. Toachieve this, we first develop a data generation engine to produce trainingtriplets, each consisting of a high-quality image, the target regiondescription, and the corresponding region mask. With this engine and carefuldata screening, we construct a comprehensive dataset comprising 536,945triplets to support the training and evaluation of this task. We then examinehow to integrate the low-quality image features under the ControlNetarchitecture to adjust the degree of image details enhancement. Consequently,we develop a ControlNet-like model to identify the target region and allocatedifferent integration scales to the target and surrounding regions, enablingregion-customized image restoration that aligns with user instructions.Experimental results demonstrate that our proposed InstructRestore approachenables effective human-instructed image restoration, such as images with bokeheffects and user-instructed local enhancement. Our work advances theinvestigation of interactive image restoration and enhancement techniques.Data, code, and models will be found athttps://github.com/shuaizhengliu/InstructRestore.git.
  </details>

- **[PathOrchestra: A Comprehensive Foundation Model for Computational Pathology with Over 100 Diverse Clinical-Grade Tasks](http://arxiv.org/abs/2503.24345v1)**  `arXiv:2503.24345`  
  _Fang Yan, Jianfeng Wu, Jiawen Li, Wei Wang, Jiaxuan Lu, Wen Chen, et al._
  <details><summary>Abstract</summary>
  The complexity and variability inherent in high-resolution pathologicalimages present significant challenges in computational pathology. Whilepathology foundation models leveraging AI have catalyzed transformativeadvancements, their development demands large-scale datasets, considerablestorage capacity, and substantial computational resources. Furthermore,ensuring their clinical applicability and generalizability requires rigorousvalidation across a broad spectrum of clinical tasks. Here, we presentPathOrchestra, a versatile pathology foundation model trained viaself-supervised learning on a dataset comprising 300K pathological slides from20 tissue and organ types across multiple centers. The model was rigorouslyevaluated on 112 clinical tasks using a combination of 61 private and 51 publicdatasets. These tasks encompass digital slide preprocessing, pan-cancerclassification, lesion identification, multi-cancer subtype classification,biomarker assessment, gene expression prediction, and the generation ofstructured reports. PathOrchestra demonstrated exceptional performance across27,755 WSIs and 9,415,729 ROIs, achieving over 0.950 accuracy in 47 tasks,including pan-cancer classification across various organs, lymphoma subtypediagnosis, and bladder cancer screening. Notably, it is the first model togenerate structured reports for high-incidence colorectal cancer anddiagnostically complex lymphoma-areas that are infrequently addressed byfoundational models but hold immense clinical potential. Overall, PathOrchestraexemplifies the feasibility and efficacy of a large-scale, self-supervisedpathology foundation model, validated across a broad range of clinical-gradetasks. Its high accuracy and reduced reliance on extensive data annotationunderline its potential for clinical integration, offering a pathway towardmore efficient and high-quality medical services.
  </details>

- **[Self-Supervised Pretraining for Aerial Road Extraction](http://arxiv.org/abs/2503.24326v1)**  `arXiv:2503.24326`  
  _Rupert Polley, Sai Vignesh Abishek Deenadayalan, J. Marius Z√∂llner_
  <details><summary>Abstract</summary>
  Deep neural networks for aerial image segmentation require large amounts oflabeled data, but high-quality aerial datasets with precise annotations arescarce and costly to produce. To address this limitation, we propose aself-supervised pretraining method that improves segmentation performance whilereducing reliance on labeled data. Our approach uses inpainting-basedpretraining, where the model learns to reconstruct missing regions in aerialimages, capturing their inherent structure before being fine-tuned for roadextraction. This method improves generalization, enhances robustness to domainshifts, and is invariant to model architecture and dataset choice. Experimentsshow that our pretraining significantly boosts segmentation accuracy,especially in low-data regimes, making it a scalable solution for aerial imageanalysis.
  </details>

- **[Can Test-Time Scaling Improve World Foundation Model?](http://arxiv.org/abs/2503.24320v1)**  `arXiv:2503.24320`  
  _Wenyan Cong, Hanqing Zhu, Peihao Wang, Bangya Liu, Dejia Xu, Kevin Wang, et al._
  <details><summary>Abstract</summary>
  World foundation models, which simulate the physical world by predictingfuture states from current observations and inputs, have become central to manyapplications in physical intelligence, including autonomous driving androbotics. However, these models require substantial computational resources forpretraining and are further constrained by available data during post-training.As such, scaling computation at test time emerges as both a critical andpractical alternative to traditional model enlargement or re-training. In thiswork, we introduce SWIFT, a test-time scaling framework tailored for WFMs.SWIFT integrates our extensible WFM evaluation toolkit with process-levelinference strategies, including fast tokenization, probability-based Top-Kpruning, and efficient beam search. Empirical results on the COSMOS modeldemonstrate that test-time scaling exists even in a compute-optimal way. Ourfindings reveal that test-time scaling laws hold for WFMs and that SWIFTprovides a scalable and effective pathway for improving WFM inference withoutretraining or increasing model size. The code is available athttps://github.com/Mia-Cong/SWIFT.git.
  </details>

- **[Point Tracking in Surgery--The 2024 Surgical Tattoos in Infrared (STIR) Challenge](http://arxiv.org/abs/2503.24306v1)**  `arXiv:2503.24306`  
  _Adam Schmidt, Mert Asim Karaoglu, Soham Sinha, Mingang Jang, Ho-Gun Ha, Kyungmin Jung, et al._
  <details><summary>Abstract</summary>
  Understanding tissue motion in surgery is crucial to enable applications indownstream tasks such as segmentation, 3D reconstruction, virtual tissuelandmarking, autonomous probe-based scanning, and subtask autonomy. Labeleddata are essential to enabling algorithms in these downstream tasks since theyallow us to quantify and train algorithms. This paper introduces a pointtracking challenge to address this, wherein participants can submit theiralgorithms for quantification. The submitted algorithms are evaluated using adataset named surgical tattoos in infrared (STIR), with the challenge aptlynamed the STIR Challenge 2024. The STIR Challenge 2024 comprises twoquantitative components: accuracy and efficiency. The accuracy component teststhe accuracy of algorithms on in vivo and ex vivo sequences. The efficiencycomponent tests the latency of algorithm inference. The challenge was conductedas a part of MICCAI EndoVis 2024. In this challenge, we had 8 total teams, with4 teams submitting before and 4 submitting after challenge day. This paperdetails the STIR Challenge 2024, which serves to move the field towards moreaccurate and efficient algorithms for spatial understanding in surgery. In thispaper we summarize the design, submissions, and results from the challenge. Thechallenge dataset is available here: https://zenodo.org/records/14803158 , andthe code for baseline models and metric calculation is available here:https://github.com/athaddius/STIRMetrics
  </details>

- **[Order Matters: On Parameter-Efficient Image-to-Video Probing for Recognizing Nearly Symmetric Actions](http://arxiv.org/abs/2503.24298v1)**  `arXiv:2503.24298`  
  _Thinesh Thiyakesan Ponbagavathi, Alina Roitberg_
  <details><summary>Abstract</summary>
  We study parameter-efficient image-to-video probing for the unaddressedchallenge of recognizing nearly symmetric actions - visually similar actionsthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).Existing probing mechanisms for image-pretrained models, such as DinoV2 andCLIP, rely on attention mechanism for temporal modeling but are inherentlypermutation-invariant, leading to identical predictions regardless of frameorder. To address this, we introduce Self-attentive Temporal Embedding Probing(STEP), a simple yet effective approach designed to enforce temporalsensitivity in parameter-efficient image-to-video transfer. STEP enhancesself-attentive probing with three key modifications: (1) a learnable frame-wisepositional encoding, explicitly encoding temporal order; (2) a single globalCLS token, for sequence coherence; and (3) a simplified attention mechanism toimprove parameter efficiency. STEP outperforms existing image-to-video probingmechanisms by 3-15% across four activity recognition benchmarks with only 1/3of the learnable parameters. On two datasets, it surpasses all publishedmethods, including fully fine-tuned models. STEP shows a distinct advantage inrecognizing nearly symmetric actions, surpassing other probing mechanisms by9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code andmodels will be made publicly available.
  </details>

- **[Style Quantization for Data-Efficient GAN Training](http://arxiv.org/abs/2503.24282v1)**  `arXiv:2503.24282`  
  _Jian Wang, Xin Lan, Jizhe Zhou, Yuxin Tian, Jiancheng Lv_
  <details><summary>Abstract</summary>
  Under limited data setting, GANs often struggle to navigate and effectivelyexploit the input latent space. Consequently, images generated from adjacentvariables in a sparse input latent space may exhibit significant discrepanciesin realism, leading to suboptimal consistency regularization (CR) outcomes. Toaddress this, we propose \textit{SQ-GAN}, a novel approach that enhances CR byintroducing a style space quantization scheme. This method transforms thesparse, continuous input latent space into a compact, structured discrete proxyspace, allowing each element to correspond to a specific real data point,thereby improving CR performance. Instead of direct quantization, we first mapthe input latent variables into a less entangled ``style'' space and applyquantization using a learnable codebook. This enables each quantized code tocontrol distinct factors of variation. Additionally, we optimize the optimaltransport distance to align the codebook codes with features extracted from thetraining data by a foundation model, embedding external knowledge into thecodebook and establishing a semantically rich vocabulary that properlydescribes the training dataset. Extensive experiments demonstrate significantimprovements in both discriminator robustness and generation quality with ourmethod.
  </details>

- **[Learning Velocity and Acceleration: Self-Supervised Motion Consistency for Pedestrian Trajectory Prediction](http://arxiv.org/abs/2503.24272v1)**  `arXiv:2503.24272`  
  _Yizhou Huang, Yihua Cheng, Kezhi Wang_
  <details><summary>Abstract</summary>
  Understanding human motion is crucial for accurate pedestrian trajectoryprediction. Conventional methods typically rely on supervised learning, whereground-truth labels are directly optimized against predicted trajectories. Thisamplifies the limitations caused by long-tailed data distributions, making itdifficult for the model to capture abnormal behaviors. In this work, we proposea self-supervised pedestrian trajectory prediction framework that explicitlymodels position, velocity, and acceleration. We leverage velocity andacceleration information to enhance position prediction through featureinjection and a self-supervised motion consistency mechanism. Our modelhierarchically injects velocity features into the position stream. Accelerationfeatures are injected into the velocity stream. This enables the model topredict position, velocity, and acceleration jointly. From the predictedposition, we compute corresponding pseudo velocity and acceleration, allowingthe model to learn from data-generated pseudo labels and thus achieveself-supervised learning. We further design a motion consistency evaluationstrategy grounded in physical principles; it selects the most reasonablepredicted motion trend by comparing it with historical dynamics and uses thistrend to guide and constrain trajectory generation. We conduct experiments onthe ETH-UCY and Stanford Drone datasets, demonstrating that our method achievesstate-of-the-art performance on both datasets.
  </details>

- **[Visual Acoustic Fields](http://arxiv.org/abs/2503.24270v1)**  `arXiv:2503.24270`  
  _Yuelei Li, Hyunjin Kim, Fangneng Zhan, Ri-Zhao Qiu, Mazeyu Ji, Xiaojun Shan, et al._
  <details><summary>Abstract</summary>
  Objects produce different sounds when hit, and humans can intuitively inferhow an object might sound based on its appearance and material properties.Inspired by this intuition, we propose Visual Acoustic Fields, a framework thatbridges hitting sounds and visual signals within a 3D space using 3D GaussianSplatting (3DGS). Our approach features two key modules: sound generation andsound localization. The sound generation module leverages a conditionaldiffusion model, which takes multiscale features rendered from afeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, thesound localization module enables querying the 3D scene, represented by thefeature-augmented 3DGS, to localize hitting positions based on the soundsources. To support this framework, we introduce a novel pipeline forcollecting scene-level visual-sound sample pairs, achieving alignment betweencaptured images, impact locations, and corresponding sounds. To the best of ourknowledge, this is the first dataset to connect visual and acoustic signals ina 3D context. Extensive experiments on our dataset demonstrate theeffectiveness of Visual Acoustic Fields in generating plausible impact soundsand accurately localizing impact sources. Our project page is athttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.
  </details>

- **[FakeScope: Large Multimodal Expert Model for Transparent AI-Generated Image Forensics](http://arxiv.org/abs/2503.24267v1)**  `arXiv:2503.24267`  
  _Yixuan Li, Yu Tian, Yipo Huang, Wei Lu, Shiqi Wang, Weisi Lin, et al._
  <details><summary>Abstract</summary>
  The rapid and unrestrained advancement of generative artificial intelligence(AI) presents a double-edged sword: while enabling unprecedented creativity, italso facilitates the generation of highly convincing deceptive content,undermining societal trust. As image generation techniques become increasinglysophisticated, detecting synthetic images is no longer just a binary task: itnecessitates interpretable, context-aware methodologies that enhancetrustworthiness and transparency. However, existing detection models primarilyfocus on classification, offering limited explanatory insights into imageauthenticity. In this work, we propose FakeScope, an expert multimodal model(LMM) tailored for AI-generated image forensics, which not only identifiesAI-synthetic images with high accuracy but also provides rich, interpretable,and query-driven forensic insights. We first construct FakeChain dataset thatcontains linguistic authenticity reasoning based on visual trace evidence,developed through a novel human-machine collaborative framework. Building uponit, we further present FakeInstruct, the largest multimodal instruction tuningdataset containing 2 million visual instructions tailored to enhance forensicawareness in LMMs. FakeScope achieves state-of-the-art performance in bothclosed-ended and open-ended forensic scenarios. It can distinguish syntheticimages with high accuracy while offering coherent and insightful explanations,free-form discussions on fine-grained forgery attributes, and actionableenhancement strategies. Notably, despite being trained exclusively onqualitative hard labels, FakeScope demonstrates remarkable zero-shotquantitative capability on detection, enabled by our proposed token-basedprobability estimation strategy. Furthermore, FakeScope exhibits stronggeneralization and in-the-wild ability, ensuring its applicability inreal-world scenarios.
  </details>

- **[Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation](http://arxiv.org/abs/2503.24258v1)**  `arXiv:2503.24258`  
  _Lorenzo Tronchin, Tommy L√∂fstedt, Paolo Soda, Valerio Guarrasi_
  <details><summary>Abstract</summary>
  The advancement of generative AI, particularly in medical imaging, confrontsthe trilemma of ensuring high fidelity, diversity, and efficiency in syntheticdata generation. While Generative Adversarial Networks (GANs) have shownpromise across various applications, they still face challenges like modecollapse and insufficient coverage of real data distributions. This workexplores the use of GAN ensembles to overcome these limitations, specificallyin the context of medical imaging. By solving a multi-objective optimisationproblem that balances fidelity and diversity, we propose a method for selectingan optimal ensemble of GANs tailored for medical data. The selected ensemble iscapable of generating diverse synthetic medical images that are representativeof true data distributions and computationally efficient. Each model in theensemble brings a unique contribution, ensuring minimal redundancy. Weconducted a comprehensive evaluation using three distinct medical datasets,testing 22 different GAN architectures with various loss functions andregularisation techniques. By sampling models at different training epochs, wecrafted 110 unique configurations. The results highlight the capability of GANensembles to enhance the quality and utility of synthetic medical images,thereby improving the efficacy of downstream tasks such as diagnosticmodelling.
  </details>

- **[Pre-training with 3D Synthetic Data: Learning 3D Point Cloud Instance Segmentation from 3D Synthetic Scenes](http://arxiv.org/abs/2503.24229v1)**  `arXiv:2503.24229`  
  _Daichi Otsuka, Shinichi Mae, Ryosuke Yamada, Hirokatsu Kataoka_
  <details><summary>Abstract</summary>
  In the recent years, the research community has witnessed growing use of 3Dpoint cloud data for the high applicability in various real-world applications.By means of 3D point cloud, this modality enables to consider the actual sizeand spatial understanding. The applied fields include mechanical control ofrobots, vehicles, or other real-world systems. Along this line, we would liketo improve 3D point cloud instance segmentation which has emerged as aparticularly promising approach for these applications. However, the creationof 3D point cloud datasets entails enormous costs compared to 2D imagedatasets. To train a model of 3D point cloud instance segmentation, it isnecessary not only to assign categories but also to provide detailedannotations for each point in the large-scale 3D space. Meanwhile, the increaseof recent proposals for generative models in 3D domain has spurred proposalsfor using a generative model to create 3D point cloud data. In this work, wepropose a pre-training with 3D synthetic data to train a 3D point cloudinstance segmentation model based on generative model for 3D scenes representedby point cloud data. We directly generate 3D point cloud data with Point-E forinserting a generated data into a 3D scene. More recently in 2025, althoughthere are other accurate 3D generation models, even using the Point-E as anearly 3D generative model can effectively support the pre-training with 3Dsynthetic data. In the experimental section, we compare our pre-training methodwith baseline methods indicated improved performance, demonstrating theefficacy of 3D generative models for 3D point cloud instance segmentation.
  </details>

- **[MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing](http://arxiv.org/abs/2503.24219v1)**  `arXiv:2503.24219`  
  _Karim Radouane, Hanane Azzag, Mustapha lebbah_
  <details><summary>Abstract</summary>
  We propose a unified framework that integrates object detection (OD) andvisual grounding (VG) for remote sensing (RS) imagery. To support conventionalOD and establish an intuitive prior for VG task, we fine-tune an open-setobject detector using referring expression data, framing it as a partiallysupervised OD task. In the first stage, we construct a graph representation ofeach image, comprising object queries, class embeddings, and proposallocations. Then, our task-aware architecture processes this graph to performthe VG task. The model consists of: (i) a multi-branch network that integratesspatial, visual, and categorical features to generate task-aware proposals, and(ii) an object reasoning network that assigns probabilities across proposals,followed by a soft selection mechanism for final referring object localization.Our model demonstrates superior performance on the OPT-RSVG and DIOR-RSVGdatasets, achieving significant improvements over state-of-the-art methodswhile retaining classical OD capabilities. The code will be available in ourrepository: \url{https://github.com/rd20karim/MB-ORES}.
  </details>

- **[DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting](http://arxiv.org/abs/2503.24210v1)**  `arXiv:2503.24210`  
  _Seungjun Lee, Gim Hee Lee_
  <details><summary>Abstract</summary>
  Reconstructing sharp 3D representations from blurry multi-view images arelong-standing problem in computer vision. Recent works attempt to enhancehigh-quality novel view synthesis from the motion blur by leveragingevent-based cameras, benefiting from high dynamic range and microsecondtemporal resolution. However, they often reach sub-optimal visual quality ineither restoring inaccurate color or losing fine-grained details. In thispaper, we present DiET-GS, a diffusion prior and event stream-assisted motiondeblurring 3DGS. Our framework effectively leverages both blur-free eventstreams and diffusion prior in a two-stage training strategy. Specifically, weintroduce the novel framework to constraint 3DGS with event double integral,achieving both accurate color and well-defined details. Additionally, wepropose a simple technique to leverage diffusion prior to further enhance theedge details. Qualitative and quantitative results on both synthetic andreal-world data demonstrate that our DiET-GS is capable of producingsignificantly better quality of novel views compared to the existing baselines.Our project page is https://diet-gs.github.io
  </details>

- **[CIBR: Cross-modal Information Bottleneck Regularization for Robust CLIP Generalization](http://arxiv.org/abs/2503.24182v1)**  `arXiv:2503.24182`  
  _Yingrui Ji, Xi Xiao, Gaofei Chen, Hao Xu, Chenrui Ma, Lijing Zhu, et al._
  <details><summary>Abstract</summary>
  Contrastive Language-Image Pretraining (CLIP) has achieved remarkable successin cross-modal tasks such as zero-shot image classification and text-imageretrieval by effectively aligning visual and textual representations. However,the theoretical foundations underlying CLIP's strong generalization remainunclear. In this work, we address this gap by proposing the Cross-modalInformation Bottleneck (CIB) framework. CIB offers a principled interpretationof CLIP's contrastive learning objective as an implicit Information Bottleneckoptimization. Under this view, the model maximizes shared cross-modalinformation while discarding modality-specific redundancies, thereby preservingessential semantic alignment across modalities. Building on this insight, weintroduce a Cross-modal Information Bottleneck Regularization (CIBR) methodthat explicitly enforces these IB principles during training. CIBR introduces apenalty term to discourage modality-specific redundancy, thereby enhancingsemantic alignment between image and text features. We validate CIBR onextensive vision-language benchmarks, including zero-shot classification acrossseven diverse image datasets and text-image retrieval on MSCOCO and Flickr30K.The results show consistent performance gains over standard CLIP. Thesefindings provide the first theoretical understanding of CLIP's generalizationthrough the IB lens. They also demonstrate practical improvements, offeringguidance for future cross-modal representation learning.
  </details>

- **[Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up](http://arxiv.org/abs/2503.24180v1)**  `arXiv:2503.24180`  
  _Ziming Cheng, Zhiyuan Huang, Junting Pan, Zhaohui Hou, Mingjie Zhan_
  <details><summary>Abstract</summary>
  Graphical user interfaces (GUI) automation agents are emerging as powerfultools, enabling humans to accomplish increasingly complex tasks on smartdevices. However, users often inadvertently omit key information when conveyingtasks, which hinders agent performance in the current agent paradigm that doesnot support immediate user intervention. To address this issue, we introduce a$\textbf{Self-Correction GUI Navigation}$ task that incorporates interactiveinformation completion capabilities within GUI agents. We developed the$\textbf{Navi-plus}$ dataset with GUI follow-up question-answer pairs,alongside a $\textbf{Dual-Stream Trajectory Evaluation}$ method to benchmarkthis new capability. Our results show that agents equipped with the ability toask GUI follow-up questions can fully recover their performance when faced withambiguous user tasks.
  </details>

- **[Foundation Models For Seismic Data Processing: An Extensive Review](http://arxiv.org/abs/2503.24166v1)**  `arXiv:2503.24166`  
  _Fabian Fuchs, Mario Ruben Fernandez, Norman Ettrich, Janis Keuper_
  <details><summary>Abstract</summary>
  Seismic processing plays a crucial role in transforming raw data intohigh-quality subsurface images, pivotal for various geoscience applications.Despite its importance, traditional seismic processing techniques facechallenges such as noisy and damaged data and the reliance on manual,time-consuming workflows. The emergence of deep learning approaches hasintroduced effective and user-friendly alternatives, yet many of these deeplearning approaches rely on synthetic datasets and specialized neural networks.Recently, foundation models have gained traction in the seismic domain, due totheir success in natural imaging. This paper investigates the application offoundation models in seismic processing on the tasks: demultiple,interpolation, and denoising. It evaluates the impact of different modelcharacteristics, such as pre-training technique and neural networkarchitecture, on performance and efficiency. Rather than proposing a singleseismic foundation model, this paper critically examines various natural imagefoundation models and suggest some promising candidates for future exploration.
  </details>

- **[PixelCAM: Pixel Class Activation Mapping for Histology Image Classification and ROI Localization](http://arxiv.org/abs/2503.24135v1)**  `arXiv:2503.24135`  
  _Alexis Guichemerre, Soufiane Belharbi, Mohammadhadi Shateri, Luke McCaffrey, Eric Granger_
  <details><summary>Abstract</summary>
  Weakly supervised object localization (WSOL) methods allow training models toclassify images and localize ROIs. WSOL only requires low-cost image-classannotations yet provides a visually interpretable classifier, which isimportant in histology image analysis. Standard WSOL methods rely on classactivation mapping (CAM) methods to produce spatial localization maps accordingto a single- or two-step strategy. While both strategies have made significantprogress, they still face several limitations with histology images.Single-step methods can easily result in under- or over-activation due to thelimited visual ROI saliency in histology images and the limited localizationcues. They also face the well-known issue of asynchronous convergence betweenclassification and localization tasks. The two-step approach is sub-optimalbecause it is tied to a frozen classifier, limiting the capacity forlocalization. Moreover, these methods also struggle when applied toout-of-distribution (OOD) datasets. In this paper, a multi-task approach forWSOL is introduced for simultaneous training of both tasks to address theasynchronous convergence problem. In particular, localization is performed inthe pixel-feature space of an image encoder that is shared with classification.This allows learning discriminant features and accurate delineation offoreground/background regions to support ROI localization and imageclassification. We propose PixelCAM, a cost-effective foreground/backgroundpixel-wise classifier in the pixel-feature space that allows for spatial objectlocalization. PixelCAM is trained using pixel pseudo-labels collected from apretrained WSOL model. Both image and pixel-wise classifiers are trainedsimultaneously using standard gradient descent. In addition, our pixelclassifier can easily be integrated into CNN- and transformer-basedarchitectures without any modifications.
  </details>

- **[It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data](http://arxiv.org/abs/2503.24129v1)**  `arXiv:2503.24129`  
  _Dominik Schnaus, Nikita Araslanov, Daniel Cremers_
  <details><summary>Abstract</summary>
  The platonic representation hypothesis suggests that vision and languageembeddings become more homogeneous as model and dataset sizes increase. Inparticular, pairwise distances within each modality become more similar. Thissuggests that as foundation models mature, it may become possible to matchvision and language embeddings in a fully unsupervised fashion, i.e. withoutparallel data. We present the first feasibility study, and investigateconformity of existing vision and language foundation models in the context ofunsupervised, or "blind", matching. First, we formulate unsupervised matchingas a quadratic assignment problem and introduce a novel heuristic thatoutperforms previous solvers. We also develop a technique to find optimalmatching problems, for which a non-trivial match is very likely. Second, weconduct an extensive study deploying a range of vision and language models onfour datasets. Our analysis reveals that for many problem instances, vision andlanguage representations can be indeed matched without supervision. Thisfinding opens up the exciting possibility of embedding semantic knowledge intoother modalities virtually annotation-free. As a proof of concept, we showcasean unsupervised classifier, which achieves non-trivial classification accuracywithout any image-text annotation.
  </details>

- **[IMPACT: A Generic Semantic Loss for Multimodal Medical Image Registration](http://arxiv.org/abs/2503.24121v1)**  `arXiv:2503.24121`  
  _Valentin Boussot, C√©dric H√©mon, Jean-Claude Nunes, Jason Downling, Simon Rouz√©, Caroline Lafond, et al._
  <details><summary>Abstract</summary>
  Image registration is fundamental in medical imaging, enabling precisealignment of anatomical structures for diagnosis, treatment planning,image-guided treatment or longitudinal monitoring. This work introduces IMPACT(Image Metric with Pretrained model-Agnostic Comparison for Transmodalityregistration), a generic semantic similarity metric designed for seamlessintegration into diverse image registration frameworks (such as Elastix andVoxelmorph). It compares deep learning-based features extracted from medicalimages without requiring task-specific training, ensuring broad applicabilityacross various modalities. By leveraging the features of the large-scalepretrained TotalSegmentator models and the ability to integrate SegmentAnything Model (SAM) and other large-scale segmentation networks, this approachoffers significant advantages. It provides robust, scalable, and efficientsolutions for multimodal image registration. The IMPACT loss was evaluated onfive challenging registration tasks involving thoracic CT/CBCT, and pelvicMR/CT datasets. Quantitative metrics, such as Target Registration Error andDice Similarity Coefficient, demonstrated significant improvements inanatomical alignment compared to baseline methods. Qualitative analyses furtherconfirmed the increased robustness of the proposed metric in the face of noise,artifacts, and modality variations. IMPACT's versatility and efficiency make ita valuable tool for advancing registration performance in clinical and researchapplications, addressing critical challenges in multimodal medical imaging.
  </details>

- **[PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis](http://arxiv.org/abs/2503.24108v1)**  `arXiv:2503.24108`  
  _Anwesa Choudhuri, Zhongpai Gao, Meng Zheng, Benjamin Planche, Terrence Chen, Ziyan Wu_
  <details><summary>Abstract</summary>
  Early detection, accurate segmentation, classification and tracking of polypsduring colonoscopy are critical for preventing colorectal cancer. Many existingdeep-learning-based methods for analyzing colonoscopic videos either requiretask-specific fine-tuning, lack tracking capabilities, or rely ondomain-specific pre-training. In this paper, we introduce\textit{PolypSegTrack}, a novel foundation model that jointly addresses polypdetection, segmentation, classification and unsupervised tracking incolonoscopic videos. Our approach leverages a novel conditional mask loss,enabling flexible training across datasets with either pixel-level segmentationmasks or bounding box annotations, allowing us to bypass task-specificfine-tuning. Our unsupervised tracking module reliably associates polypinstances across frames using object queries, without relying on anyheuristics. We leverage a robust vision foundation model backbone that ispre-trained unsupervisedly on natural images, thereby removing the need fordomain-specific pre-training. Extensive experiments on multiple polypbenchmarks demonstrate that our method significantly outperforms existingstate-of-the-art approaches in detection, segmentation, classification, andtracking.
  </details>

- **[DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description](http://arxiv.org/abs/2503.24096v1)**  `arXiv:2503.24096`  
  _Adrienne Deganutti, Simon Hadfield, Andrew Gilbert_
  <details><summary>Abstract</summary>
  Audio Description is a narrated commentary designed to aid vision-impairedaudiences in perceiving key visual elements in a video. While short-form videounderstanding has advanced rapidly, a solution for maintaining coherentlong-term visual storytelling remains unresolved. Existing methods rely solelyon frame-level embeddings, effectively describing object-based content butlacking contextual information across scenes. We introduce DANTE-AD, anenhanced video description model leveraging a dual-vision Transformer-basedarchitecture to address this gap. DANTE-AD sequentially fuses both frame andscene level embeddings to improve long-term contextual understanding. Wepropose a novel, state-of-the-art method for sequential cross-attention toachieve contextual grounding for fine-grained audio description generation.Evaluated on a broad range of key scenes from well-known movie clips, DANTE-ADoutperforms existing methods across traditional NLP metrics and LLM-basedevaluations.
  </details>

- **[4D mmWave Radar in Adverse Environments for Autonomous Driving: A Survey](http://arxiv.org/abs/2503.24091v1)**  `arXiv:2503.24091`  
  _Xiangyuan Peng, Miao Tang, Huawei Sun, Lorenzo Servadei, Robert Wille_
  <details><summary>Abstract</summary>
  Autonomous driving systems require accurate and reliable perception. However,adverse environments, such as rain, snow, and fog, can significantly degradethe performance of LiDAR and cameras. In contrast, 4D millimeter-wave (mmWave)radar not only provides 3D sensing and additional velocity measurements butalso maintains robustness in challenging conditions, making it increasinglyvaluable for autonomous driving. Recently, research on 4D mmWave radar underadverse environments has been growing, but a comprehensive survey is stilllacking. To bridge this gap, this survey comprehensively reviews the currentresearch on 4D mmWave radar under adverse environments. First, we present anoverview of existing 4D mmWave radar datasets encompassing diverse weather andlighting scenarios. Next, we analyze methods and models according to differentadverse conditions. Finally, the challenges faced in current studies andpotential future directions are discussed for advancing 4D mmWave radarapplications in harsh environments. To the best of our knowledge, this is thefirst survey specifically focusing on 4D mmWave radar in adverse environmentsfor autonomous driving.
  </details>

- **[A Plasticity-Aware Method for Continual Self-Supervised Learning in Remote Sensing](http://arxiv.org/abs/2503.24088v1)**  `arXiv:2503.24088`  
  _Lars M√∂llenbrok, Behnood Rasti, Beg√ºm Demir_
  <details><summary>Abstract</summary>
  Continual self-supervised learning (CSSL) methods have gained increasingattention in remote sensing (RS) due to their capability to learn new taskssequentially from continuous streams of unlabeled data.  Existing CSSL methods, while learning new tasks, focus on preventingcatastrophic forgetting. To this end, most of them use regularizationstrategies to retain knowledge of previous tasks. This reduces the model'sability to adapt to the data of new tasks (i.e., learning plasticity), whichcan degrade performance. To address this problem, in this paper, we propose anovel CSSL method that aims to learn tasks sequentially, while achieving highlearning plasticity. To this end, the proposed method uses a knowledgedistillation strategy with an integrated decoupling mechanism. The decouplingis achieved by first dividing the feature dimensions into task-common andtask-specific parts. Then, the task-common features are forced to be correlatedto ensure memory stability while the task-specific features are forced to bede-correlated facilitating the learning of new features. Experimental resultsshow the effectiveness of the proposed method compared to CaSSLe, which is awidely used CSSL framework, with improvements of up to 1.12% in averageaccuracy and 2.33% in intransigence in a task-incremental scenario, and 1.24%in average accuracy and 2.01% in intransigence in a class-incremental scenario.
  </details>

- **[From Colors to Classes: Emergence of Concepts in Vision Transformers](http://arxiv.org/abs/2503.24071v1)**  `arXiv:2503.24071`  
  _Teresa Dorszewski, Lenka Tƒõtkov√°, Robert Jenssen, Lars Kai Hansen, Kristoffer Knutsen Wickstr√∏m_
  <details><summary>Abstract</summary>
  Vision Transformers (ViTs) are increasingly utilized in various computervision tasks due to their powerful representation capabilities. However, itremains understudied how ViTs process information layer by layer. Numerousstudies have shown that convolutional neural networks (CNNs) extract featuresof increasing complexity throughout their layers, which is crucial for taskslike domain adaptation and transfer learning. ViTs, lacking the same inductivebiases as CNNs, can potentially learn global dependencies from the first layersdue to their attention mechanisms. Given the increasing importance of ViTs incomputer vision, there is a need to improve the layer-wise understanding ofViTs. In this work, we present a novel, layer-wise analysis of concepts encodedin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTsencode concepts with increasing complexity throughout the network. Early layersprimarily encode basic features such as colors and textures, while later layersrepresent more specific classes, including objects and animals. As thecomplexity of encoded concepts increases, the number of concepts represented ineach layer also rises, reflecting a more diverse and specific set of features.Additionally, different pretraining strategies influence the quantity andcategory of encoded concepts, with finetuning to specific downstream tasksgenerally reducing the number of encoded concepts and shifting the concepts tomore relevant categories.
  </details>

- **[COSMO: Combination of Selective Memorization for Low-cost Vision-and-Language Navigation](http://arxiv.org/abs/2503.24065v1)**  `arXiv:2503.24065`  
  _Siqi Zhang, Yanyuan Qiao, Qunbo Wang, Zike Yan, Qi Wu, Zhihua Wei, et al._
  <details><summary>Abstract</summary>
  Vision-and-Language Navigation (VLN) tasks have gained prominence withinartificial intelligence research due to their potential application in fieldslike home assistants. Many contemporary VLN approaches, while based ontransformer architectures, have increasingly incorporated additional componentssuch as external knowledge bases or map information to enhance performance.These additions, while boosting performance, also lead to larger models andincreased computational costs. In this paper, to achieve both high performanceand low computational costs, we propose a novel architecture with theCOmbination of Selective MemOrization (COSMO). Specifically, COSMO integratesstate-space modules and transformer modules, and incorporates twoVLN-customized selective state space modules: the Round Selective Scan (RSS)and the Cross-modal Selective State Space Module (CS3). RSS facilitatescomprehensive inter-modal interactions within a single scan, while the CS3module adapts the selective state space module into a dual-stream architecture,thereby enhancing the acquisition of cross-modal interactions. Experimentalvalidations on three mainstream VLN benchmarks, REVERIE, R2R, and R2R-CE, notonly demonstrate competitive navigation performance of our model but also showa significant reduction in computational costs.
  </details>

- **[AMMSM: Adaptive Motion Magnification and Sparse Mamba for Micro-Expression Recognition](http://arxiv.org/abs/2503.24057v1)**  `arXiv:2503.24057`  
  _Xuxiong Liu, Tengteng Dong, Fei Wang, Weijie Feng, Xiao Sun_
  <details><summary>Abstract</summary>
  Micro-expressions are typically regarded as unconscious manifestations of aperson's genuine emotions. However, their short duration and subtle signalspose significant challenges for downstream recognition. We propose a multi-tasklearning framework named the Adaptive Motion Magnification and Sparse Mamba(AMMSM) to address this. This framework aims to enhance the accurate capture ofmicro-expressions through self-supervised subtle motion magnification, whilethe sparse spatial selection Mamba architecture combines sparse activation withthe advanced Visual Mamba model to model key motion regions and their valuablerepresentations more effectively. Additionally, we employ evolutionary searchto optimize the magnification factor and the sparsity ratios of spatialselection, followed by fine-tuning to improve performance further. Extensiveexperiments on two standard datasets demonstrate that the proposed AMMSMachieves state-of-the-art (SOTA) accuracy and robustness.
  </details>

- **[BBoxCut: A Targeted Data Augmentation Technique for Enhancing Wheat Head Detection Under Occlusions](http://arxiv.org/abs/2503.24032v1)**  `arXiv:2503.24032`  
  _Yasashwini Sai Gowri P, Karthik Seemakurthy, Andrews Agyemang Opoku, Sita Devi Bharatula_
  <details><summary>Abstract</summary>
  Wheat plays a critical role in global food security, making it one of themost extensively studied crops. Accurate identification and measurement of keycharacteristics of wheat heads are essential for breeders to select varietiesfor cross-breeding, with the goal of developing nutrient-dense, resilient, andsustainable cultivars. Traditionally, these measurements are performedmanually, which is both time-consuming and inefficient. Advances in digitaltechnologies have paved the way for automating this process. However, fieldconditions pose significant challenges, such as occlusions of leaves,overlapping wheat heads, varying lighting conditions, and motion blur. In thispaper, we propose a novel data augmentation technique, BBoxCut, which usesrandom localized masking to simulate occlusions caused by leaves andneighboring wheat heads. We evaluated our approach using three state-of-the-artobject detectors and observed mean average precision (mAP) gains of 2.76, 3.26,and 1.9 for Faster R-CNN, FCOS, and DETR, respectively. Our augmentationtechnique led to significant improvements both qualitatively andquantitatively. In particular, the improvements were particularly evident inscenarios involving occluded wheat heads, demonstrating the robustness of ourmethod in challenging field conditions.
  </details>

- **[HumanDreamer: Generating Controllable Human-Motion Videos via Decoupled Generation](http://arxiv.org/abs/2503.24026v1)**  `arXiv:2503.24026`  
  _Boyuan Wang, Xiaofeng Wang, Chaojun Ni, Guosheng Zhao, Zhiqin Yang, Zheng Zhu, et al._
  <details><summary>Abstract</summary>
  Human-motion video generation has been a challenging task, primarily due tothe difficulty inherent in learning human body movements. While some approacheshave attempted to drive human-centric video generation explicitly through posecontrol, these methods typically rely on poses derived from existing videos,thereby lacking flexibility. To address this, we propose HumanDreamer, adecoupled human video generation framework that first generates diverse posesfrom text prompts and then leverages these poses to generate human-motionvideos. Specifically, we propose MotionVid, the largest dataset forhuman-motion pose generation. Based on the dataset, we present MotionDiT, whichis trained to generate structured human-motion poses from text prompts.Besides, a novel LAMA loss is introduced, which together contribute to asignificant improvement in FID by 62.4%, along with respective enhancements inR-precision for top1, top2, and top3 by 41.8%, 26.3%, and 18.3%, therebyadvancing both the Text-to-Pose control accuracy and FID metrics. Ourexperiments across various Pose-to-Video baselines demonstrate that the posesgenerated by our method can produce diverse and high-quality human-motionvideos. Furthermore, our model can facilitate other downstream tasks, such aspose sequence prediction and 2D-3D motion lifting.
  </details>

- **[Crossmodal Knowledge Distillation with WordNet-Relaxed Text Embeddings for Robust Image Classification](http://arxiv.org/abs/2503.24017v1)**  `arXiv:2503.24017`  
  _Chenqi Guo, Mengshuo Rong, Qianli Feng, Rongfan Feng, Yinglong Ma_
  <details><summary>Abstract</summary>
  Crossmodal knowledge distillation (KD) aims to enhance a unimodal studentusing a multimodal teacher model. In particular, when the teacher's modalitiesinclude the student's, additional complementary information can be exploited toimprove knowledge transfer. In supervised image classification, image datasetstypically include class labels that represent high-level concepts, suggesting anatural avenue to incorporate textual cues for crossmodal KD. However, theselabels rarely capture the deeper semantic structures in real-world visuals andcan lead to label leakage if used directly as inputs, ultimately limiting KDperformance. To address these issues, we propose a multi-teacher crossmodal KDframework that integrates CLIP image embeddings with learnable WordNet-relaxedtext embeddings under a hierarchical loss. By avoiding direct use of exactclass names and instead using semantically richer WordNet expansions, wemitigate label leakage and introduce more diverse textual cues. Experimentsshow that this strategy significantly boosts student performance, whereas noisyor overly precise text embeddings hinder distillation efficiency.Interpretability analyses confirm that WordNet-relaxed prompts encourageheavier reliance on visual features over textual shortcuts, while stilleffectively incorporating the newly introduced textual cues. Our methodachieves state-of-the-art or second-best results on six public datasets,demonstrating its effectiveness in advancing crossmodal KD.
  </details>

- **[Optimization of Layer Skipping and Frequency Scaling for Convolutional Neural Networks under Latency Constraint](http://arxiv.org/abs/2503.24014v1)**  `arXiv:2503.24014`  
  _Minh David Thao Chan, Ruoyu Zhao, Yukuan Jia, Ruiqing Mao, Sheng Zhou_
  <details><summary>Abstract</summary>
  The energy consumption of Convolutional Neural Networks (CNNs) is a criticalfactor in deploying deep learning models on resource-limited equipment such asmobile devices and autonomous vehicles. We propose an approach involvingProportional Layer Skipping (PLS) and Frequency Scaling (FS). Layer skippingreduces computational complexity by selectively bypassing network layers,whereas frequency scaling adjusts the frequency of the processor to optimizeenergy use under latency constraints. Experiments of PLS and FS on ResNet-152with the CIFAR-10 dataset demonstrated significant reductions in computationaldemands and energy consumption with minimal accuracy loss. This study offerspractical solutions for improving real-time processing in resource-limitedsettings and provides insights into balancing computational efficiency andmodel performance.
  </details>

- **[H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding](http://arxiv.org/abs/2503.24008v1)**  `arXiv:2503.24008`  
  _Qi Wu, Quanlong Zheng, Yanhao Zhang, Junlin Xie, Jinguo Luo, Kuo Wang, et al._
  <details><summary>Abstract</summary>
  With the rapid development of multimodal models, the demand for assessingvideo understanding capabilities has been steadily increasing. However,existing benchmarks for evaluating video understanding exhibit significantlimitations in coverage, task diversity, and scene adaptability. Theseshortcomings hinder the accurate assessment of models' comprehensive videounderstanding capabilities. To tackle this challenge, we propose a hierarchicaland holistic video understanding (H2VU) benchmark designed to evaluate bothgeneral video and online streaming video comprehension. This benchmarkcontributes three key features:  Extended video duration: Spanning videos from brief 3-second clips tocomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found incurrent benchmarks. Comprehensive assessment tasks: Beyond traditionalperceptual and reasoning tasks, we have introduced modules forcountercommonsense comprehension and trajectory state tracking. These additionstest the models' deep understanding capabilities beyond mere prior knowledge.Enriched video data: To keep pace with the rapid evolution of current AIagents, we have expanded first-person streaming video datasets. This expansionallows for the exploration of multimodal models' performance in understandingstreaming videos from a first-person perspective. Extensive results from H2VUreveal that existing multimodal large language models (MLLMs) possesssubstantial potential for improvement in our newly proposed evaluation tasks.We expect that H2VU will facilitate advancements in video understandingresearch by offering a comprehensive and in-depth analysis of MLLMs.
  </details>

- **[DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via Conditional Diffusion Model](http://arxiv.org/abs/2503.23993v1)**  `arXiv:2503.23993`  
  _Ming Yuan, Sichao Wang, Chuang Zhang, Lei He, Qing Xu, Jianqiang Wang_
  <details><summary>Abstract</summary>
  The depth completion task is a critical problem in autonomous driving,involving the generation of dense depth maps from sparse depth maps and RGBimages. Most existing methods employ a spatial propagation network toiteratively refine the depth map after obtaining an initial dense depth. Inthis paper, we propose DenseFormer, a novel method that integrates thediffusion model into the depth completion task. By incorporating the denoisingmechanism of the diffusion model, DenseFormer generates the dense depth map byprogressively refining an initial random depth distribution through multipleiterations. We propose a feature extraction module that leverages a featurepyramid structure, along with multi-layer deformable attention, to effectivelyextract and integrate features from sparse depth maps and RGB images, whichserve as the guiding condition for the diffusion process. Additionally, thispaper presents a depth refinement module that applies multi-step iterativerefinement across various ranges to the dense depth results generated by thediffusion process. The module utilizes image features enriched with multi-scaleinformation and sparse depth input to further enhance the accuracy of thepredicted depth map. Extensive experiments on the KITTI outdoor scene datasetdemonstrate that DenseFormer outperforms classical depth completion methods.
  </details>

- **[SALT: A Flexible Semi-Automatic Labeling Tool for General LiDAR Point Clouds with Cross-Scene Adaptability and 4D Consistency](http://arxiv.org/abs/2503.23980v1)**  `arXiv:2503.23980`  
  _Yanbo Wang, Yongtao Chen, Chuan Cao, Tianchen Deng, Wentao Zhao, Jingchuan Wang, et al._
  <details><summary>Abstract</summary>
  We propose a flexible Semi-Automatic Labeling Tool (SALT) for general LiDARpoint clouds with cross-scene adaptability and 4D consistency. Unlike recentapproaches that rely on camera distillation, SALT operates directly on rawLiDAR data, automatically generating pre-segmentation results. To achieve this,we propose a novel zero-shot learning paradigm, termed data alignment, whichtransforms LiDAR data into pseudo-images by aligning with the trainingdistribution of vision foundation models. Additionally, we design a4D-consistent prompting strategy and 4D non-maximum suppression module toenhance SAM2, ensuring high-quality, temporally consistent presegmentation.SALT surpasses the latest zero-shot methods by 18.4% PQ on SemanticKITTI andachieves nearly 40-50% of human annotator performance on our newly collectedlow-resolution LiDAR data and on combined data from three LiDAR types,significantly boosting annotation efficiency. We anticipate that SALT'sopen-sourcing will catalyze substantial expansion of current LiDAR datasets andlay the groundwork for the future development of LiDAR foundation models. Codeis available at https://github.com/Cavendish518/SALT.
  </details>

- **[Video-based Traffic Light Recognition by Rockchip RV1126 for Autonomous Driving](http://arxiv.org/abs/2503.23965v1)**  `arXiv:2503.23965`  
  _Miao Fan, Xuxu Kong, Shengtong Xu, Haoyi Xiong, Xiangzeng Liu_
  <details><summary>Abstract</summary>
  Real-time traffic light recognition is fundamental for autonomous drivingsafety and navigation in urban environments. While existing approaches rely onsingle-frame analysis from onboard cameras, they struggle with complexscenarios involving occlusions and adverse lighting conditions. We present\textit{ViTLR}, a novel video-based end-to-end neural network that processesmultiple consecutive frames to achieve robust traffic light detection and stateclassification. The architecture leverages a transformer-like design withconvolutional self-attention modules, which is optimized specifically fordeployment on the Rockchip RV1126 embedded platform. Extensive evaluations ontwo real-world datasets demonstrate that \textit{ViTLR} achievesstate-of-the-art performance while maintaining real-time processingcapabilities (>25 FPS) on RV1126's NPU. The system shows superior robustnessacross temporal stability, varying target distances, and challengingenvironmental conditions compared to existing single-frame approaches. We havesuccessfully integrated \textit{ViTLR} into an ego-lane traffic lightrecognition system using HD maps for autonomous driving applications. Thecomplete implementation, including source code and datasets, is made publiclyavailable to facilitate further research in this domain.
  </details>

- **[A Benchmark for Vision-Centric HD Mapping by V2I Systems](http://arxiv.org/abs/2503.23963v1)**  `arXiv:2503.23963`  
  _Miao Fan, Shanshan Yu, Shengtong Xu, Kun Jiang, Haoyi Xiong, Xiangzeng Liu_
  <details><summary>Abstract</summary>
  Autonomous driving faces safety challenges due to a lack of globalperspective and the semantic information of vectorized high-definition (HD)maps. Information from roadside cameras can greatly expand the map perceptionrange through vehicle-to-infrastructure (V2I) communications. However, there isstill no dataset from the real world available for the study on mapvectorization onboard under the scenario of vehicle-infrastructure cooperation.To prosper the research on online HD mapping for Vehicle-InfrastructureCooperative Autonomous Driving (VICAD), we release a real-world dataset, whichcontains collaborative camera frames from both vehicles and roadsideinfrastructures, and provides human annotations of HD map elements. We alsopresent an end-to-end neural framework (i.e., V2I-HD) leveraging vision-centricV2I systems to construct vectorized maps. To reduce computation costs andfurther deploy V2I-HD on autonomous vehicles, we introduce a directionallydecoupled self-attention mechanism to V2I-HD. Extensive experiments show thatV2I-HD has superior performance in real-time inference speed, as tested by ourreal-world dataset. Abundant qualitative results also demonstrate stable androbust map construction quality with low cost in complex and various drivingscenes. As a benchmark, both source codes and the dataset have been released atOneDrive for the purpose of further study.
  </details>

- **[Local Information Matters: Inference Acceleration For Grounded Conversation Generation Models Through Adaptive Local-Aware Token Pruning](http://arxiv.org/abs/2503.23959v1)**  `arXiv:2503.23959`  
  _Bizhe Bai, Jianjian Cao, Yadan Luo, Tao Che_
  <details><summary>Abstract</summary>
  Grounded Conversation Generation (GCG) is an emerging vision-language taskthat requires models to generate natural language responses seamlesslyintertwined with corresponding object segmentation masks. Recent models, suchas GLaMM and OMG-LLaVA, achieve pixel-level grounding but incur significantcomputational costs due to processing a large number of visual tokens. Existingtoken pruning methods, like FastV and PyramidDrop, fail to preserve the localvisual features critical for accurate grounding, leading to substantialperformance drops in GCG tasks. To address this, we propose AdaptiveLocal-Aware Token Pruning (ALTP), a simple yet effective framework thataccelerates GCG models by prioritizing local object information. ALTPintroduces two key components: (1) Detail Density Capture (DDC), which usessuperpixel segmentation to retain tokens in object-centric regions, preservingfine-grained details, and (2) Dynamic Density Formation (DDF), whichdynamically allocates tokens based on information density, ensuring higherretention in semantically rich areas. Extensive experiments on the GranDfdataset demonstrate that ALTP significantly outperforms existing token pruningmethods, such as FastV and PyramidDrop, on both GLaMM and OMG-LLaVA models.Notably, when applied to GLaMM, ALTP achieves a 90% reduction in visual tokenswith a 4.9% improvement in AP50 and a 5.0% improvement in Recall compared toPyramidDrop. Similarly, on OMG-LLaVA, ALTP improves AP by 2.1% and mIOU by 3.0%at a 90% token reduction compared with PDrop.
  </details>

- **[A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei Segmentation and Classification in H&E-Stained Histological Images of Advanced Melanoma](http://arxiv.org/abs/2503.23958v1)**  `arXiv:2503.23958`  
  _Nima Torbati, Anastasia Meshcheryakova, Diana Mechtcheriakova, Amirreza Mahbod_
  <details><summary>Abstract</summary>
  Melanoma is the most lethal form of skin cancer, with an increasing incidencerate worldwide. Analyzing histological images of melanoma by localizing andclassifying tissues and cell nuclei is considered the gold standard method fordiagnosis and treatment options for patients. While many computerizedapproaches have been proposed for automatic analysis, most perform tissue-basedanalysis and nuclei (cell)-based analysis as separate tasks, which might besuboptimal.  In this work, using the PUMA challenge dataset, we proposed a novelmulti-stage deep learning approach by combining tissue and nuclei informationin a unified framework based on the auto-context concept to performsegmentation and classification in histological images of melanoma. Throughpre-training and further post-processing, our approach achieved second andfirst place rankings in the PUMA challenge, with average micro Dice tissuescore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,respectively. Our implementation for training and testing is available at:https://github.com/NimaTorbati/PumaSubmit
  </details>

- **[AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference](http://arxiv.org/abs/2503.23956v1)**  `arXiv:2503.23956`  
  _Kai Huang, Hao Zou, Bochen Wang, Ye Xi, Zhen Xie, Hao Wang_
  <details><summary>Abstract</summary>
  Recent advancements in Large Visual Language Models (LVLMs) have gainedsignificant attention due to their remarkable reasoning capabilities andproficiency in generalization. However, processing a large number of visualtokens and generating long-context outputs impose substantial computationaloverhead, leading to excessive demands for key-value (KV) cache. To addressthis critical bottleneck, we propose AirCache, a novel KV cache compressionmethod aimed at accelerating LVLMs inference. This work systematicallyinvestigates the correlations between visual and textual tokens within theattention mechanisms of LVLMs. Our empirical analysis reveals considerableredundancy in cached visual tokens, wherein strategically eliminating thesetokens preserves model performance while significantly accelerating contextgeneration. Inspired by these findings, we introduce an elite observationwindow for assessing the importance of visual components in the KV cache,focusing on stable inter-modal relevancy modeling with enhancedmulti-perspective consistency. Additionally, we develop an adaptive layer-wisebudget allocation strategy that capitalizes on the strength and skewness oftoken importance distribution, showcasing superior efficiency compared touniform allocation. Comprehensive evaluations across multiple LVLMs andbenchmarks demonstrate that our method achieves comparable performance to thefull cache while retaining only 10% of visual KV cache, thereby reducingdecoding latency by 29% to 66% across various batch size and prompt length ofinputs. Notably, as cache retention rates decrease, our method exhibitsincreasing performance advantages over existing approaches.
  </details>

- **[JointTuner: Appearance-Motion Adaptive Joint Training for Customized Video Generation](http://arxiv.org/abs/2503.23951v1)**  `arXiv:2503.23951`  
  _Fangda Chen, Shanshan Zhao, Chuanfu Xu, Long Lan_
  <details><summary>Abstract</summary>
  Recent text-to-video advancements have enabled coherent video synthesis fromprompts and expanded to fine-grained control over appearance and motion.However, existing methods either suffer from concept interference due tofeature domain mismatch caused by naive decoupled optimizations or exhibitappearance contamination induced by spatial feature leakage resulting from theentanglement of motion and appearance in reference video reconstructions. Inthis paper, we propose JointTuner, a novel adaptive joint training framework,to alleviate these issues. Specifically, we develop Adaptive LoRA, whichincorporates a context-aware gating mechanism, and integrate the gated LoRAcomponents into the spatial and temporal Transformers within the diffusionmodel. These components enable simultaneous optimization of appearance andmotion, eliminating concept interference. In addition, we introduce theAppearance-independent Temporal Loss, which decouples motion patterns fromintrinsic appearance in reference video reconstructions through anappearance-agnostic noise prediction task. The key innovation lies in addingframe-wise offset noise to the ground-truth Gaussian noise, perturbing itsdistribution, thereby disrupting spatial attributes associated with frameswhile preserving temporal coherence. Furthermore, we construct a benchmarkcomprising 90 appearance-motion customized combinations and 10 multi-typeautomatic metrics across four dimensions, facilitating a more comprehensiveevaluation for this customization task. Extensive experiments demonstrate thesuperior performance of our method compared to current advanced approaches.
  </details>

- **[Spectral-Adaptive Modulation Networks for Visual Perception](http://arxiv.org/abs/2503.23947v1)**  `arXiv:2503.23947`  
  _Guhnoo Yun, Juhan Yoo, Kijung Kim, Jeongho Lee, Paul Hongsuck Seo, Dong Hwan Kim_
  <details><summary>Abstract</summary>
  Recent studies have shown that 2D convolution and self-attention exhibitdistinct spectral behaviors, and optimizing their spectral properties canenhance vision model performance. However, theoretical analyses remain limitedin explaining why 2D convolution is more effective in high-pass filtering thanself-attention and why larger kernels favor shape bias, akin to self-attention.In this paper, we employ graph spectral analysis to theoretically simulate andcompare the frequency responses of 2D convolution and self-attention within aunified framework. Our results corroborate previous empirical findings andreveal that node connectivity, modulated by window size, is a key factor inshaping spectral functions. Leveraging this insight, we introduce a\textit{spectral-adaptive modulation} (SPAM) mixer, which processes visualfeatures in a spectral-adaptive manner using multi-scale convolutional kernelsand a spectral re-scaling mechanism to refine spectral components. Based onSPAM, we develop SPANetV2 as a novel vision backbone. Extensive experimentsdemonstrate that SPANetV2 outperforms state-of-the-art models across multiplevision tasks, including ImageNet-1K classification, COCO object detection, andADE20K semantic segmentation.
  </details>

- **[Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios](http://arxiv.org/abs/2503.23930v1)**  `arXiv:2503.23930`  
  _Jiankai Tang, Jiacheng Liu, Renling Tong, Kai Zhu, Zhe Li, Xin Yi, et al._
  <details><summary>Abstract</summary>
  Photoplethysmography (PPG) Sensors, widely deployed in smartwatches, offer asimple and non-invasive authentication approach for daily use. However, PPGauthentication faces reliability issues due to motion artifacts from physicalactivity and physiological variability over time. To address these challenges,we propose MTL-RAPID, an efficient and reliable PPG authentication model, thatemploys a multitask joint training strategy, simultaneously assessing signalquality and verifying user identity. The joint optimization of these two tasksin MTL-RAPID results in a structure that outperforms models trained onindividual tasks separately, achieving stronger performance with fewerparameters. In our comprehensive user studies regarding motion artifacts (N =30), time variations (N = 32), and user preferences (N = 16), MTL-RAPIDachieves a best AUC of 99.2\% and an EER of 3.5\%, outperforming existingbaselines. We opensource our PPG authentication dataset along with theMTL-RAPID model to facilitate future research on GitHub.
  </details>

- **[CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral Subpixel-Level Semi-Dense Image Matching](http://arxiv.org/abs/2503.23925v1)**  `arXiv:2503.23925`  
  _Zizhuo Li, Yifan Lu, Linfeng Tang, Shihua Zhang, Jiayi Ma_
  <details><summary>Abstract</summary>
  This prospective study proposes CoMatch, a novel semi-dense image matcherwith dynamic covisibility awareness and bilateral subpixel accuracy. Firstly,observing that modeling context interaction over the entire coarse feature mapelicits highly redundant computation due to the neighboring representationsimilarity of tokens, a covisibility-guided token condenser is introduced toadaptively aggregate tokens in light of their covisibility scores that aredynamically estimated, thereby ensuring computational efficiency whileimproving the representational capacity of aggregated tokens simultaneously.Secondly, considering that feature interaction with massive non-covisible areasis distracting, which may degrade feature distinctiveness, acovisibility-assisted attention mechanism is deployed to selectively suppressirrelevant message broadcast from non-covisible reduced tokens, resulting inrobust and compact attention to relevant rather than all ones. Thirdly, we findthat at the fine-level stage, current methods adjust only the target view'skeypoints to subpixel level, while those in the source view remain restrictedat the coarse level and thus not informative enough, detrimental to keypointlocation-sensitive usages. A simple yet potent fine correlation module isdeveloped to refine the matching candidates in both source and target views tosubpixel level, attaining attractive performance improvement. Thoroughexperimentation across an array of public benchmarks affirms CoMatch'spromising accuracy, efficiency, and generalizability.
  </details>

- **[FineCausal: A Causal-Based Framework for Interpretable Fine-Grained Action Quality Assessment](http://arxiv.org/abs/2503.23911v1)**  `arXiv:2503.23911`  
  _Ruisheng Han, Kanglei Zhou, Amir Atapour-Abarghouei, Xiaohui Liang, Hubert P. H. Shum_
  <details><summary>Abstract</summary>
  Action quality assessment (AQA) is critical for evaluating athleticperformance, informing training strategies, and ensuring safety in competitivesports. However, existing deep learning approaches often operate as black boxesand are vulnerable to spurious correlations, limiting both their reliabilityand interpretability. In this paper, we introduce FineCausal, a novelcausal-based framework that achieves state-of-the-art performance on theFineDiving-HM dataset. Our approach leverages a Graph Attention Network-basedcausal intervention module to disentangle human-centric foreground cues frombackground confounders, and incorporates a temporal causal attention module tocapture fine-grained temporal dependencies across action stages. Thisdual-module strategy enables FineCausal to generate detailed spatio-temporalrepresentations that not only achieve state-of-the-art scoring performance butalso provide transparent, interpretable feedback on which features drive theassessment. Despite its strong performance, FineCausal requires extensiveexpert knowledge to define causal structures and depends on high-qualityannotations, challenges that we discuss and address as future researchdirections. Code is available at https://github.com/Harrison21/FineCausal.
  </details>

- **[HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment](http://arxiv.org/abs/2503.23907v1)**  `arXiv:2503.23907`  
  _Zhichao Liao, Xiaokun Liu, Wenyu Qin, Qingyu Li, Qiulin Wang, Pengfei Wan, et al._
  <details><summary>Abstract</summary>
  Image Aesthetic Assessment (IAA) is a long-standing and challenging researchtask. However, its subset, Human Image Aesthetic Assessment (HIAA), has beenscarcely explored, even though HIAA is widely used in social media, AIworkflows, and related domains. To bridge this research gap, our work pioneersa holistic implementation framework tailored for HIAA. Specifically, weintroduce HumanBeauty, the first dataset purpose-built for HIAA, whichcomprises 108k high-quality human images with manual annotations. To achievecomprehensive and fine-grained HIAA, 50K human images are manually collectedthrough a rigorous curation process and annotated leveraging our trailblazing12-dimensional aesthetic standard, while the remaining 58K with overallaesthetic labels are systematically filtered from public datasets. Based on theHumanBeauty database, we propose HumanAesExpert, a powerful Vision LanguageModel for aesthetic evaluation of human images. We innovatively design anExpert head to incorporate human knowledge of aesthetic sub-dimensions whilejointly utilizing the Language Modeling (LM) and Regression head. This approachempowers our model to achieve superior proficiency in both overall andfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregatesscores from all three heads, to effectively balance the capabilities of eachhead, thereby realizing improved assessment precision. Extensive experimentsdemonstrate that our HumanAesExpert models deliver significantly betterperformance in HIAA than other state-of-the-art models. Our datasets, models,and codes are publicly released to advance the HIAA community. Project webpage:https://humanaesexpert.github.io/HumanAesExpert/
  </details>

- **[Boosting MLLM Reasoning with Text-Debiased Hint-GRPO](http://arxiv.org/abs/2503.23905v1)**  `arXiv:2503.23905`  
  _Qihan Huang, Long Chan, Jinlong Liu, Wanggui He, Hao Jiang, Mingli Song, et al._
  <details><summary>Abstract</summary>
  MLLM reasoning has drawn widespread research for its excellentproblem-solving capability. Current reasoning methods fall into two types: PRM,which supervises the intermediate reasoning steps, and ORM, which supervisesthe final results. Recently, DeepSeek-R1 has challenged the traditional viewthat PRM outperforms ORM, which demonstrates strong generalization performanceusing an ORM method (i.e., GRPO). However, current MLLM's GRPO algorithms stillstruggle to handle challenging and complex multimodal reasoning tasks (e.g.,mathematical reasoning). In this work, we reveal two problems that impede theperformance of GRPO on the MLLM: Low data utilization and Text-bias. Low datautilization refers to that GRPO cannot acquire positive rewards to update theMLLM on difficult samples, and text-bias is a phenomenon that the MLLM bypassesimage condition and solely relies on text condition for generation after GRPOtraining. To tackle these problems, this work proposes Hint-GRPO that improvesdata utilization by adaptively providing hints for samples of varyingdifficulty, and text-bias calibration that mitigates text-bias by calibratingthe token prediction logits with image condition in test-time. Experimentresults on three base MLLMs across eleven datasets demonstrate that ourproposed methods advance the reasoning capability of original MLLM by a largemargin, exhibiting superior performance to existing MLLM reasoning methods. Ourcode is available at https://github.com/hqhQAQ/Hint-GRPO.
  </details>

- **[Training-Free Text-Guided Image Editing with Visual Autoregressive Model](http://arxiv.org/abs/2503.23897v1)**  `arXiv:2503.23897`  
  _Yufei Wang, Lanqing Guo, Zhihao Li, Jiaxing Huang, Pichao Wang, Bihan Wen, et al._
  <details><summary>Abstract</summary>
  Text-guided image editing is an essential task that enables users to modifyimages through natural language descriptions. Recent advances in diffusionmodels and rectified flows have significantly improved editing quality,primarily relying on inversion techniques to extract structured noise frominput images. However, inaccuracies in inversion can propagate errors, leadingto unintended modifications and compromising fidelity. Moreover, even withperfect inversion, the entanglement between textual prompts and image featuresoften results in global changes when only local edits are intended. To addressthese challenges, we propose a novel text-guided image editing framework basedon VAR (Visual AutoRegressive modeling), which eliminates the need for explicitinversion while ensuring precise and controlled modifications. Our methodintroduces a caching mechanism that stores token indices and probabilitydistributions from the original image, capturing the relationship between thesource prompt and the image. Using this cache, we design an adaptivefine-grained masking strategy that dynamically identifies and constrainsmodifications to relevant regions, preventing unintended changes. A tokenreassembling approach further refines the editing process, enhancing diversity,fidelity, and control. Our framework operates in a training-free manner andachieves high-fidelity editing with faster inference speeds, processing a 1Kresolution image in as fast as 1.2 seconds. Extensive experiments demonstratethat our method achieves performance comparable to, or even surpassing,existing diffusion- and rectified flow-based approaches in both quantitativemetrics and visual quality. The code will be released.
  </details>

- **[MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation Approach](http://arxiv.org/abs/2503.23888v1)**  `arXiv:2503.23888`  
  _Xin Zhang, Siting Huang, Xiangyang Luo, Yifan Xie, Weijiang Yu, Heng Chang, et al._
  <details><summary>Abstract</summary>
  Face editing modifies the appearance of face, which plays a key role incustomization and enhancement of personal images. Although much work haveachieved remarkable success in text-driven face editing, they still facesignificant challenges as none of them simultaneously fulfill thecharacteristics of diversity, controllability and flexibility. To address thischallenge, we propose MuseFace, a text-driven face editing framework, whichrelies solely on text prompt to enable face editing. Specifically, MuseFaceintegrates a Text-to-Mask diffusion model and a semantic-aware face editingmodel, capable of directly generating fine-grained semantic masks from text andperforming face editing. The Text-to-Mask diffusion model provides\textit{diversity} and \textit{flexibility} to the framework, while thesemantic-aware face editing model ensures \textit{controllability} of theframework. Our framework can create fine-grained semantic masks, making preciseface editing possible, and significantly enhancing the controllability andflexibility of face editing models. Extensive experiments demonstrate thatMuseFace achieves superior high-fidelity performance.
  </details>

- **[GLane3D : Detecting Lanes with Graph of 3D Keypoints](http://arxiv.org/abs/2503.23882v1)**  `arXiv:2503.23882`  
  _Halil ƒ∞brahim √ñzt√ºrk, Muhammet Esat Kalfaoƒülu, Ozsel Kilinc_
  <details><summary>Abstract</summary>
  Accurate and efficient lane detection in 3D space is essential for autonomousdriving systems, where robust generalization is the foremost requirement for 3Dlane detection algorithms. Considering the extensive variation in lanestructures worldwide, achieving high generalization capacity is particularlychallenging, as algorithms must accurately identify a wide variety of lanepatterns worldwide. Traditional top-down approaches rely heavily on learninglane characteristics from training datasets, often struggling with lanesexhibiting previously unseen attributes. To address this generalizationlimitation, we propose a method that detects keypoints of lanes andsubsequently predicts sequential connections between them to construct complete3D lanes. Each key point is essential for maintaining lane continuity, and wepredict multiple proposals per keypoint by allowing adjacent grids to predictthe same keypoint using an offset mechanism. PointNMS is employed to eliminateoverlapping proposal keypoints, reducing redundancy in the estimated BEV graphand minimizing computational overhead from connection estimations. Our modelsurpasses previous state-of-the-art methods on both the Apollo and OpenLanedatasets, demonstrating superior F1 scores and a strong generalization capacitywhen models trained on OpenLane are evaluated on the Apollo dataset, comparedto prior approaches.
  </details>

- **[ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from a Single Image](http://arxiv.org/abs/2503.23881v1)**  `arXiv:2503.23881`  
  _Tianyi Gong, Boyan Li, Yifei Zhong, Fangxin Wang_
  <details><summary>Abstract</summary>
  The increasing demand for augmented and virtual reality applications hashighlighted the importance of crafting immersive 3D scenes from a simplesingle-view image. However, due to the partial priors provided by single-viewinput, existing methods are often limited to reconstruct low-consistency 3Dscenes with narrow fields of view from single-view input. These limitationsmake them less capable of generalizing to reconstruct immersive scenes. Toaddress this problem, we propose ExScene, a two-stage pipeline to reconstructan immersive 3D scene from any given single-view image. ExScene designs a novelmultimodal diffusion model to generate a high-fidelity and globally consistentpanoramic image. We then develop a panoramic depth estimation approach tocalculate geometric information from panorama, and we combine geometricinformation with high-fidelity panoramic image to train an initial 3D GaussianSplatting (3DGS) model. Following this, we introduce a GS refinement techniquewith 2D stable video diffusion priors. We add camera trajectory consistency andcolor-geometric priors into the denoising process of diffusion to improve colorand spatial consistency across image sequences. These refined sequences arethen used to fine-tune the initial 3DGS model, leading to better reconstructionquality. Experimental results demonstrate that our ExScene achieves consistentand immersive scene reconstruction using only single-view input, significantlysurpassing state-of-the-art baselines.
  </details>

- **[Learned Image Compression and Restoration for Digital Pathology](http://arxiv.org/abs/2503.23862v1)**  `arXiv:2503.23862`  
  _SeonYeong Lee, EonSeung Seong, DongEon Lee, SiYeoul Lee, Yubin Cho, Chunsu Park, et al._
  <details><summary>Abstract</summary>
  Digital pathology images play a crucial role in medical diagnostics, buttheir ultra-high resolution and large file sizes pose significant challengesfor storage, transmission, and real-time visualization. To address theseissues, we propose CLERIC, a novel deep learning-based image compressionframework designed specifically for whole slide images (WSIs). CLERICintegrates a learnable lifting scheme and advanced convolutional techniques toenhance compression efficiency while preserving critical pathological details.Our framework employs a lifting-scheme transform in the analysis stage todecompose images into low- and high-frequency components, enabling morestructured latent representations. These components are processed throughparallel encoders incorporating Deformable Residual Blocks (DRB) and RecurrentResidual Blocks (R2B) to improve feature extraction and spatial adaptability.The synthesis stage applies an inverse lifting transform for effective imagereconstruction, ensuring high-fidelity restoration of fine-grained tissuestructures. We evaluate CLERIC on a digital pathology image dataset and compareits performance against state-of-the-art learned image compression (LIC)models. Experimental results demonstrate that CLERIC achieves superiorrate-distortion (RD) performance, significantly reducing storage requirementswhile maintaining high diagnostic image quality. Our study highlights thepotential of deep learning-based compression in digital pathology, facilitatingefficient data management and long-term storage while ensuring seamlessintegration into clinical workflows and AI-assisted diagnostic systems. Codeand models are available at: https://github.com/pnu-amilab/CLERIC.
  </details>

- **[FlexiMo: A Flexible Remote Sensing Foundation Model](http://arxiv.org/abs/2503.23844v1)**  `arXiv:2503.23844`  
  _Xuyang Li, Chenyu Li, Pedram Ghamisi, Danfeng Hong_
  <details><summary>Abstract</summary>
  The rapid expansion of multi-source satellite imagery drives innovation inEarth observation, opening unprecedented opportunities for Remote SensingFoundation Models to harness diverse data. However, many existing models remainconstrained by fixed spatial resolutions and patch sizes, limiting theirability to fully exploit the heterogeneous spatial characteristics inherent insatellite imagery. To address these challenges, we propose FlexiMo, a flexibleremote sensing foundation model that endows the pre-trained model with theflexibility to adapt to arbitrary spatial resolutions. Central to FlexiMo is aspatial resolution-aware module that employs a parameter-free alignmentembedding mechanism to dynamically recalibrate patch embeddings based on theinput image's resolution and dimensions. This design not only preservescritical token characteristics and ensures multi-scale feature fidelity butalso enables efficient feature extraction without requiring modifications tothe underlying network architecture. In addition, FlexiMo incorporates alightweight channel adaptation module that leverages prior spectral informationfrom sensors. This mechanism allows the model to process images with varyingnumbers of channels while maintaining the data's intrinsic physical properties.Extensive experiments on diverse multimodal, multi-resolution, and multi-scaledatasets demonstrate that FlexiMo significantly enhances model generalizationand robustness. In particular, our method achieves outstanding performanceacross a range of downstream tasks, including scene classification, land coverclassification, urban building segmentation, and cloud detection. By enablingparameter-efficient and physically consistent adaptation, FlexiMo paves the wayfor more adaptable and effective foundation models in real-world remote sensingapplications.
  </details>

- **[Bridge the Gap Between Visual and Linguistic Comprehension for Generalized Zero-shot Semantic Segmentation](http://arxiv.org/abs/2503.23806v1)**  `arXiv:2503.23806`  
  _Xiaoqing Guo, Wuyang Li, Yixuan Yuan_
  <details><summary>Abstract</summary>
  Generalized zero-shot semantic segmentation (GZS3) aims to achieve thehuman-level capability of segmenting not only seen classes but also novel classregions unseen in the training data through introducing the bridge of semanticrepresentations, e.g., word vector. While effective, the way of utilizing onesemantic representation to associate the corresponding class and to enable theknowledge transfer from seen to unseen classes is insufficient as well asincompatible with human cognition. Inspired by the observation that humansoften use some `part' and `state' information to comprehend the seen objectsand imagine unseen classes, we decouple each class into detailed descriptions,including object parts and states. Based on the decoupling formulation, wepropose a Decoupled Vision-Language Matching (DeVLMatch) framework, composed ofspatial-part (SPMatch) and channel-state (CSMatch) matching modules, for GZS3.In SPMatch, we comprehend objects with spatial part information from bothvisual and linguistic perspectives and perform graph matching to bridge thegap. In CSMatch, states of objects from the linguistic perspective are matchedto compatible channel information from the visual perspective. By decouplingand matching objects across visual and linguistic comprehension, we canexplicitly introspect the relationship between seen and unseen classes infine-grained object part and state levels, thereby facilitating the knowledgetransfer from seen to unseen classes in visual space. The proposed DeVLMatchframework surpasses the previous GZS3 methods on standard benchmarks, includingPASCAL VOC, COCO-Stuff, and CATARACTS, demonstrating its effectiveness.
  </details>

- **[On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video Generation for Mobile Devices](http://arxiv.org/abs/2503.23796v1)**  `arXiv:2503.23796`  
  _Bosung Kim, Kyuhwan Lee, Isu Jeong, Jungmin Cheon, Yeojin Lee, Seulki Lee_
  <details><summary>Abstract</summary>
  We present On-device Sora, the first model training-free solution fordiffusion-based on-device text-to-video generation that operates efficiently onsmartphone-grade devices. To address the challenges of diffusion-basedtext-to-video generation on computation- and memory-limited mobile devices, theproposed On-device Sora applies three novel techniques to pre-trained videogenerative models. First, Linear Proportional Leap (LPL) reduces the excessivedenoising steps required in video diffusion through an efficient leap-basedapproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensivetoken-processing computation in attention layers by merging consecutive tokensalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading(CI-DL) dynamically partitions large models into smaller blocks and loads theminto memory for concurrent model inference, effectively addressing thechallenges of limited device memory. We implement On-device Sora on the iPhone15 Pro, and the experimental evaluations show that it is capable of generatinghigh-quality videos on the device, comparable to those produced by high-endGPUs. These results show that On-device Sora enables efficient and high-qualityvideo generation on resource-constrained mobile devices. We envision theproposed On-device Sora as a significant first step toward democratizingstate-of-the-art generative technologies, enabling video generation oncommodity mobile and embedded devices without resource-intensive re-trainingfor model optimization (compression). The code implementation is available at aGitHub repository(https://github.com/eai-lab/On-device-Sora).
  </details>

- **[Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables](http://arxiv.org/abs/2503.23793v1)**  `arXiv:2503.23793`  
  _Zhongnan Cai, Yingying Wang, Yunlong Lin, Hui Zheng, Ge Meng, Zixu Lin, et al._
  <details><summary>Abstract</summary>
  Recently, deep learning-based pan-sharpening algorithms have achieved notableadvancements over traditional methods. However, many deep learning-basedapproaches incur substantial computational overhead during inference,especially with high-resolution images. This excessive computational demandlimits the applicability of these methods in real-world scenarios, particularlyin the absence of dedicated computing devices such as GPUs and TPUs. To addressthese challenges, we propose Pan-LUT, a novel learnable look-up table (LUT)framework for pan-sharpening that strikes a balance between performance andcomputational efficiency for high-resolution remote sensing images. To finelycontrol the spectral transformation, we devise the PAN-guided look-up table(PGLUT) for channel-wise spectral mapping. To effectively capture fine-grainedspatial details and adaptively learn local contexts, we introduce the spatialdetails look-up table (SDLUT) and adaptive aggregation look-up table (AALUT).Our proposed method contains fewer than 300K parameters and processes a 8Kresolution image in under 1 ms using a single NVIDIA GeForce RTX 2080 Ti GPU,demonstrating significantly faster performance compared to other methods.Experiments reveal that Pan-LUT efficiently processes large remote sensingimages in a lightweight manner, bridging the gap to real-world applications.Furthermore, our model surpasses SOTA methods in full-resolution scenes underreal-world conditions, highlighting its effectiveness and efficiency.
  </details>

- **[MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for High-Resolution Class-agnostic Segmentation](http://arxiv.org/abs/2503.23786v1)**  `arXiv:2503.23786`  
  _Haoran Shen, Peixian Zhuang, Jiahao Kou, Yuxin Zeng, Haoying Xu, Jiangyun Li_
  <details><summary>Abstract</summary>
  Segment Anything Models (SAMs), as vision foundation models, havedemonstrated remarkable performance across various image analysis tasks.Despite their strong generalization capabilities, SAMs encounter challenges infine-grained detail segmentation for high-resolution class-independentsegmentation (HRCS), due to the limitations in the direct processing ofhigh-resolution inputs and low-resolution mask predictions, and the reliance onaccurate manual prompts. To address these limitations, we propose MGD-SAM2which integrates SAM2 with multi-view feature interaction between a globalimage and local patches to achieve precise segmentation. MGD-SAM2 incorporatesthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), theHierarchical Multi-view Interaction Module (HMIM), and the Detail RefinementModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2encoder for enhanced extraction of local details and global semantics in HRCSimages. Then, MCEM and HMIM are proposed to further exploit local texture andglobal context by aggregating multi-view features within and acrossmulti-scales. Finally, DRM is designed to generate gradually restoredhigh-resolution mask predictions, compensating for the loss of fine-graineddetails resulting from directly upsampling the low-resolution prediction maps.Experimental results demonstrate the superior performance and stronggeneralization of our model on multiple high-resolution and normal-resolutiondatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.
  </details>

- **[Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference Classification with Real-World Data Discrepancies](http://arxiv.org/abs/2503.23775v1)**  `arXiv:2503.23775`  
  _Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Tobias Brieger, Fin Heuer, Lennart Asbach, et al._
  <details><summary>Abstract</summary>
  The accuracy and reliability of vehicle localization on roads are crucial forapplications such as self-driving cars, toll systems, and digital tachographs.To achieve accurate positioning, vehicles typically use global navigationsatellite system (GNSS) receivers to validate their absolute positions.However, GNSS-based positioning can be compromised by interference signals,necessitating the identification, classification, determination of purpose, andlocalization of such interference to mitigate or eliminate it. Recentapproaches based on machine learning (ML) have shown superior performance inmonitoring interference. However, their feasibility in real-world applicationsand environments has yet to be assessed. Effective implementation of MLtechniques requires training datasets that incorporate realistic interferencesignals, including real-world noise and potential multipath effects that mayoccur between transmitter, receiver, and satellite in the operational area.Additionally, these datasets require reference labels. Creating such datasetsis often challenging due to legal restrictions, as causing interference to GNSSsources is strictly prohibited. Consequently, the performance of ML-basedmethods in practical applications remains unclear. To address this gap, wedescribe a series of large-scale measurement campaigns conducted in real-worldsettings at two highway locations in Germany and the Seetal Alps in Austria,and in large-scale controlled indoor environments. We evaluate the latestsupervised ML-based methods to report on their performance in real-worldsettings and present the applicability of pseudo-labeling for unsupervisedlearning. We demonstrate the challenges of combining datasets due to datadiscrepancies and evaluate outlier detection, domain adaptation, and dataaugmentation techniques to present the models' capabilities to adapt to changesin the datasets.
  </details>

- **[XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery?](http://arxiv.org/abs/2503.23771v1)**  `arXiv:2503.23771`  
  _Fengxiang Wang, Hongzhen Wang, Mingshuo Chen, Di Wang, Yulin Wang, Zonghao Guo, et al._
  <details><summary>Abstract</summary>
  The astonishing breakthrough of multimodal large language models (MLLMs) hasnecessitated new benchmarks to quantitatively assess their capabilities, revealtheir limitations, and indicate future research directions. However, this ischallenging in the context of remote sensing (RS), since the imagery featuresultra-high resolution that incorporates extremely complex semanticrelationships. Existing benchmarks usually adopt notably smaller image sizesthan real-world RS scenarios, suffer from limited annotation quality, andconsider insufficient dimensions of evaluation. To address these issues, wepresent XLRS-Bench: a comprehensive benchmark for evaluating the perception andreasoning capabilities of MLLMs in ultra-high-resolution RS scenarios.XLRS-Bench boasts the largest average image size (8500$\times$8500) observedthus far, with all evaluation samples meticulously annotated manually, assistedby a novel semi-automatic captioner on ultra-high-resolution RS images. On topof the XLRS-Bench, 16 sub-tasks are defined to evaluate MLLMs' 10 kinds ofperceptual capabilities and 6 kinds of reasoning capabilities, with a primaryemphasis on advanced cognitive processes that facilitate real-worlddecision-making and the capture of spatiotemporal changes. The results of bothgeneral and RS-focused MLLMs on XLRS-Bench indicate that further efforts areneeded for real-world RS applications. We have open-sourced XLRS-Bench tosupport further research in developing more powerful MLLMs for remote sensing.
  </details>

- **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v1)**  `arXiv:2503.23765`  
  _Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, et al._
  <details><summary>Abstract</summary>
  The use of Multimodal Large Language Models (MLLMs) as an end-to-end solutionfor Embodied AI and Autonomous Driving has become a prevailing trend. WhileMLLMs have been extensively studied for visual semantic understanding tasks,their ability to perform precise and quantitative spatial-temporalunderstanding in real-world applications remains largely unexamined, leading touncertain prospects. To evaluate models' Spatial-Temporal Intelligence, weintroduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporalunderstanding through challenging tasks such as estimating and predicting theappearance, pose, displacement, and motion of objects. Our benchmarkencompasses a wide range of robot and vehicle operations across desktop,indoor, and outdoor scenarios. The extensive experiments reveals that thestate-of-the-art MLLMs still struggle in real-world spatial-temporalunderstanding, especially in tasks requiring precise distance estimation andmotion analysis.
  </details>

- **[WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation for Efficient Medical Image Segmentation](http://arxiv.org/abs/2503.23764v1)**  `arXiv:2503.23764`  
  _Md Mahfuz Al Hasan, Mahdi Zaman, Abdul Jawad, Alberto Santamaria-Pang, Ho Hin Lee, Ivan Tarapov, et al._
  <details><summary>Abstract</summary>
  Transformer-based architectures have advanced medical image analysis byeffectively modeling long-range dependencies, yet they often struggle in 3Dsettings due to substantial memory overhead and insufficient capture offine-grained local features. We address these limi- tations with WaveFormer, anovel 3D-transformer that: i) leverages the fundamental frequency-domainproperties of features for contextual rep- resentation, and ii) is inspired bythe top-down mechanism of the human visual recognition system, making it abiologically motivated architec- ture. By employing discrete wavelettransformations (DWT) at multiple scales, WaveFormer preserves both globalcontext and high-frequency de- tails while replacing heavy upsampling layerswith efficient wavelet-based summarization and reconstruction. Thissignificantly reduces the number of parameters, which is critical forreal-world deployment where compu- tational resources and training times areconstrained. Furthermore, the model is generic and easily adaptable to diverseapplications. Evaluations on BraTS2023, FLARE2021, and KiTS2023 demonstrateperformance on par with state-of-the-art methods while offering substantiallylower computational complexity.
  </details>

- **[Decoupled Distillation to Erase: A General Unlearning Method for Any Class-centric Tasks](http://arxiv.org/abs/2503.23751v1)**  `arXiv:2503.23751`  
  _Yu Zhou, Dian Zheng, Qijie Mo, Renjie Lu, Kun-Yu Lin, Wei-Shi Zheng_
  <details><summary>Abstract</summary>
  In this work, we present DEcoupLEd Distillation To Erase (DELETE), a generaland strong unlearning method for any class-centric tasks. To derive this, wefirst propose a theoretical framework to analyze the general form of unlearningloss and decompose it into forgetting and retention terms. Through thetheoretical framework, we point out that a class of previous methods could bemainly formulated as a loss that implicitly optimizes the forgetting term whilelacking supervision for the retention term, disturbing the distribution ofpre-trained model and struggling to adequately preserve knowledge of theremaining classes. To address it, we refine the retention term using "darkknowledge" and propose a mask distillation unlearning method. By applying amask to separate forgetting logits from retention logits, our approachoptimizes both the forgetting and refined retention components simultaneously,retaining knowledge of the remaining classes while ensuring thorough forgettingof the target class. Without access to the remaining data or intervention(i.e., used in some works), we achieve state-of-the-art performance acrossvarious benchmarks. What's more, DELETE is a general solution that can beapplied to various downstream tasks, including face recognition, backdoordefense, and semantic segmentation with great performance.
  </details>

- **[Consistency-aware Self-Training for Iterative-based Stereo Matching](http://arxiv.org/abs/2503.23747v1)**  `arXiv:2503.23747`  
  _Jingyi Zhou, Peng Ye, Haoyu Zhang, Jiakang Yuan, Rao Qiang, Liu YangChenXu, et al._
  <details><summary>Abstract</summary>
  Iterative-based methods have become mainstream in stereo matching due totheir high performance. However, these methods heavily rely on labeled data andface challenges with unlabeled real-world data. To this end, we propose aconsistency-aware self-training framework for iterative-based stereo matchingfor the first time, leveraging real-world unlabeled data in a teacher-studentmanner. We first observe that regions with larger errors tend to exhibit morepronounced oscillation characteristics during model prediction.Based on this,we introduce a novel consistency-aware soft filtering module to evaluate thereliability of teacher-predicted pseudo-labels, which consists of amulti-resolution prediction consistency filter and an iterative predictionconsistency filter to assess the prediction fluctuations of multipleresolutions and iterative optimization respectively. Further, we introduce aconsistency-aware soft-weighted loss to adjust the weight of pseudo-labelsaccordingly, relieving the error accumulation and performance degradationproblem due to incorrect pseudo-labels. Extensive experiments demonstrate thatour method can improve the performance of various iterative-based stereomatching approaches in various scenarios. In particular, our method can achievefurther enhancements over the current SOTA methods on several benchmarkdatasets.
  </details>

- **[Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model](http://arxiv.org/abs/2503.23746v1)**  `arXiv:2503.23746`  
  _Dizhan Xue, Jing Cui, Shengsheng Qian, Chuanrui Hu, Changsheng Xu_
  <details><summary>Abstract</summary>
  Short-video platforms have gained immense popularity, captivating theinterest of millions, if not billions, of users globally. Recently, researchershave highlighted the significance of analyzing the propagation of short-videos,which typically involves discovering commercial values, public opinions, userbehaviors, etc. This paper proposes a new Short-video Propagation InfluenceRating (SPIR) task and aims to promote SPIR from both the dataset and methodperspectives. First, we propose a new Cross-platform Short-Video (XS-Video)dataset, which aims to provide a large-scale and real-world short-videopropagation network across various platforms to facilitate the research onshort-video propagation. Our XS-Video dataset includes 117,720 videos, 381,926samples, and 535 topics across 5 biggest Chinese platforms, annotated with thepropagation influence from level 0 to 9. To the best of our knowledge, this isthe first large-scale short-video dataset that contains cross-platform data orprovides all of the views, likes, shares, collects, fans, comments, and commentcontent. Second, we propose a Large Graph Model (LGM) named NetGPT, based on anovel three-stage training mechanism, to bridge heterogeneous graph-structureddata with the powerful reasoning ability and knowledge of Large Language Models(LLMs). Our NetGPT can comprehend and analyze the short-video propagationgraph, enabling it to predict the long-term propagation influence ofshort-videos. Comprehensive experimental results evaluated by bothclassification and regression metrics on our XS-Video dataset indicate thesuperiority of our method for SPIR.
  </details>

- **[Every Painting Awakened: A Training-free Framework for Painting-to-Animation Generation](http://arxiv.org/abs/2503.23736v1)**  `arXiv:2503.23736`  
  _Lingyu Liu, Yaxiong Wang, Li Zhu, Zhedong Zheng_
  <details><summary>Abstract</summary>
  We introduce a training-free framework specifically designed to bringreal-world static paintings to life through image-to-video (I2V) synthesis,addressing the persistent challenge of aligning these motions with textualguidance while preserving fidelity to the original artworks. Existing I2Vmethods, primarily trained on natural video datasets, often struggle togenerate dynamic outputs from static paintings. It remains challenging togenerate motion while maintaining visual consistency with real-world paintings.This results in two distinct failure modes: either static outputs due tolimited text-based motion interpretation or distorted dynamics caused byinadequate alignment with real-world artistic styles. We leverage the advancedtext-image alignment capabilities of pre-trained image models to guide theanimation process. Our approach introduces synthetic proxy images through twokey innovations: (1) Dual-path score distillation: We employ a dual-patharchitecture to distill motion priors from both real and synthetic data,preserving static details from the original painting while learning dynamiccharacteristics from synthetic frames. (2) Hybrid latent fusion: We integratehybrid features extracted from real paintings and synthetic proxy images viaspherical linear interpolation in the latent space, ensuring smooth transitionsand enhancing temporal consistency. Experimental evaluations confirm that ourapproach significantly improves semantic alignment with text prompts whilefaithfully preserving the unique characteristics and integrity of the originalpaintings. Crucially, by achieving enhanced dynamic effects without requiringany model training or learnable parameters, our framework enables plug-and-playintegration with existing I2V methods, making it an ideal solution foranimating real-world paintings. More animated examples can be found on ourproject website.
  </details>

- **[Investigation of intelligent barbell squat coaching system based on computer vision and machine learning](http://arxiv.org/abs/2503.23731v1)**  `arXiv:2503.23731`  
  _Yinq-Rong Chern, Yuhao Lee, Hsiao-Ching Lin, Guan-Ting Chen, Ying-Hsien Chen, Fu-Sung Lin, et al._
  <details><summary>Abstract</summary>
  Purpose: Research has revealed that strength training can reduce theincidence of chronic diseases and physical deterioration at any age. Therefore,having a movement diagnostic system is crucial for training alone. Hence, thisstudy developed an artificial intelligence and computer vision-based barbellsquat coaching system with a real-time mode that immediately diagnoses theissue and provides feedback after each squat. In addition, a replay mode allowsusers to examine their previous squats and check their comments. Initially,four primary characteristics of the barbell squat were identified: body jointangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.Methods: We collect 8,151 squats from 77 participants, categorizing them asgood squats and six issues. Then, we trained the diagnosis models with threemachine-learning architectures. Furthermore, this research applied the SHapleyAdditive exPlanations (SHAP) method to enhance the accuracy of issue predictionand reduce the computation time by feature selection. Results: The F1 score ofthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Eachsquat diagnosis took less than 0.5 seconds. Finally, this study examined theefficacy of the proposed system with two groups of participants trained withand without the system. Subsequently, participants trained with the systemexhibited substantial improvements in their squat technique, as assessed bothby the system itself and by a professional weightlifting coach. Conclusion:This is a comprehensive study that integrates artificial intelligence, computervision and multivariable processing technologies, aimed at building areal-time, user-friendly barbell squat feedback and training system.
  </details>

- **[KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language](http://arxiv.org/abs/2503.23730v1)**  `arXiv:2503.23730`  
  _Yoonshik Kim, Jaeyoon Jung_
  <details><summary>Abstract</summary>
  The recent emergence of Large Vision-Language Models(VLMs) has resulted in avariety of different benchmarks for evaluating such models. Despite this, weobserve that most existing evaluation methods suffer from the fact that theyeither require the model to choose from pre-determined responses, sacrificingopen-endedness, or evaluate responses using a judge model, resulting insubjective and unreliable evaluation. In addition, we observe a lack ofbenchmarks for VLMs in the Korean language, which are necessary as a separatemetric from more common English language benchmarks, as the performance ofgenerative language models can differ significantly based on the language beingused. Therefore, we present KOFFVQA, a general-purpose free-form visualquestion answering benchmark in the Korean language for the evaluation of VLMs.Our benchmark consists of 275 carefully crafted questions each paired with animage and grading criteria covering 10 different aspects of VLM performance.The grading criteria eliminate the problem of unreliability by allowing thejudge model to grade each response based on a pre-determined set of rules. Bydefining the evaluation criteria in an objective manner, even a smallopen-source model can be used to evaluate models on our benchmark reliably. Inaddition to evaluating a large number of existing VLMs on our benchmark, wealso experimentally verify that our method of using pre-existing gradingcriteria for evaluation is much more reliable than existing methods. Ourevaluation code is available at https://github.com/maum-ai/KOFFVQA
  </details>

- **[Exploring Temporal Dynamics in Event-based Eye Tracker](http://arxiv.org/abs/2503.23725v1)**  `arXiv:2503.23725`  
  _Hongwei Ren, Xiaopeng Lin, Hongxiang Huang, Yue Zhou, Bojun Cheng_
  <details><summary>Abstract</summary>
  Eye-tracking is a vital technology for human-computer interaction, especiallyin wearable devices such as AR, VR, and XR. The realization of high-speed andhigh-precision eye-tracking using frame-based image sensors is constrained bytheir limited temporal resolution, which impairs the accurate capture of rapidocular dynamics, such as saccades and blinks. Event cameras, inspired bybiological vision systems, are capable of perceiving eye movements withextremely low power consumption and ultra-high temporal resolution. This makesthem a promising solution for achieving high-speed, high-precision trackingwith rich temporal dynamics. In this paper, we propose TDTracker, an effectiveeye-tracking framework that captures rapid eye movements by thoroughly modelingtemporal dynamics from both implicit and explicit perspectives. TDTrackerutilizes 3D convolutional neural networks to capture implicit short-termtemporal dynamics and employs a cascaded structure consisting of aFrequency-aware Module, GRU, and Mamba to extract explicit long-term temporaldynamics. Ultimately, a prediction heatmap is used for eye coordinateregression. Experimental results demonstrate that TDTracker achievesstate-of-the-art (SOTA) performance on the synthetic SEET dataset and securedThird place in the CVPR event-based eye-tracking challenge 2025. Our code isavailable at https://github.com/rhwxmx/TDTracker.
  </details>

- **[LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification](http://arxiv.org/abs/2503.23722v1)**  `arXiv:2503.23722`  
  _Xiang Hu, Yuhao Wang, Pingping Zhang, Huchuan Lu_
  <details><summary>Abstract</summary>
  Aerial-Ground person Re-IDentification (AG-ReID) aims to retrieve specificpersons across heterogeneous cameras in different views. Previous methodsusually adopt large-scale models, focusing on view-invariant features. However,they overlook the semantic information in person attributes. Additionally,existing training strategies often rely on full fine-tuning large-scale models,which significantly increases training costs. To address these issues, wepropose a novel framework named LATex for AG-ReID, which adopts prompt-tuningstrategies to leverage attribute-based text knowledge. More specifically, wefirst introduce the Contrastive Language-Image Pre-training (CLIP) model as thebackbone, and propose an Attribute-aware Image Encoder (AIE) to extract globalsemantic features and attribute-aware features. Then, with these features, wepropose a Prompted Attribute Classifier Group (PACG) to generate personattribute predictions and obtain the encoded representations of predictedattributes. Finally, we design a Coupled Prompt Template (CPT) to transformattribute tokens and view information into structured sentences. Thesesentences are processed by the text encoder of CLIP to generate morediscriminative features. As a result, our framework can fully leverageattribute-based text knowledge to improve the AG-ReID. Extensive experiments onthree AG-ReID benchmarks demonstrate the effectiveness of our proposed LATex.The source code will be available.
  </details>

- **[Effective Cloud Removal for Remote Sensing Images by an Improved Mean-Reverting Denoising Model with Elucidated Design Space](http://arxiv.org/abs/2503.23717v1)**  `arXiv:2503.23717`  
  _Yi Liu, Wengen Li, Jihong Guan, Shuigeng Zhou, Yichao Zhang_
  <details><summary>Abstract</summary>
  Cloud removal (CR) remains a challenging task in remote sensing imageprocessing. Although diffusion models (DM) exhibit strong generativecapabilities, their direct applications to CR are suboptimal, as they generatecloudless images from random noise, ignoring inherent information in cloudyinputs. To overcome this drawback, we develop a new CR model EMRDM based onmean-reverting diffusion models (MRDMs) to establish a direct diffusion processbetween cloudy and cloudless images. Compared to current MRDMs, EMRDM offers amodular framework with updatable modules and an elucidated design space, basedon a reformulated forward process and a new ordinary differential equation(ODE)-based backward process. Leveraging our framework, we redesign key MRDMmodules to boost CR performance, including restructuring the denoiser via apreconditioning technique, reorganizing the training process, and improving thesampling process by introducing deterministic and stochastic samplers. Toachieve multi-temporal CR, we further develop a denoising network forsimultaneously denoising sequential images. Experiments on mono-temporal andmulti-temporal datasets demonstrate the superior performance of EMRDM. Our codeis available at https://github.com/Ly403/EMRDM.
  </details>

- **[HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video Generation](http://arxiv.org/abs/2503.23715v1)**  `arXiv:2503.23715`  
  _Kun Liu, Qi Liu, Xinchen Liu, Jie Li, Yongdong Zhang, Jiebo Luo, et al._
  <details><summary>Abstract</summary>
  Text-to-video (T2V) generation has made tremendous progress in generatingcomplicated scenes based on texts. However, human-object interaction (HOI)often cannot be precisely generated by current T2V models due to the lack oflarge-scale videos with accurate captions for HOI. To address this issue, weintroduce HOIGen-1M, the first largescale dataset for HOI Generation,consisting of over one million high-quality videos collected from diversesources. In particular, to guarantee the high quality of videos, we firstdesign an efficient framework to automatically curate HOI videos using thepowerful multimodal large language models (MLLMs), and then the videos arefurther cleaned by human annotators. Moreover, to obtain accurate textualcaptions for HOI videos, we design a novel video description method based on aMixture-of-Multimodal-Experts (MoME) strategy that not only generatesexpressive captions but also eliminates the hallucination by individual MLLM.Furthermore, due to the lack of an evaluation framework for generated HOIvideos, we propose two new metrics to assess the quality of generated videos ina coarse-to-fine manner. Extensive experiments reveal that current T2V modelsstruggle to generate high-quality HOI videos and confirm that our HOIGen-1Mdataset is instrumental for improving HOI video generation. Project webpage isavailable at https://liuqi-creat.github.io/HOIGen.github.io.
  </details>

- **[ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum Labeling for Source-Free Domain Adaptation](http://arxiv.org/abs/2503.23712v1)**  `arXiv:2503.23712`  
  _Jie Cheng, Hao Zheng, Meiguang Zheng, Lei Wang, Hao Wu, Jian Zhang_
  <details><summary>Abstract</summary>
  Source-Free Domain Adaptation (SFDA) aims to train a target model withoutsource data, and the key is to generate pseudo-labels using a pre-trainedsource model. However, we observe that the source model often produces highlyuncertain pseudo-labels for hard samples, particularly those heavily affectedby domain shifts, leading to these noisy pseudo-labels being introduced evenbefore adaptation and further reinforced through parameter updates.Additionally, they continuously influence neighbor samples through propagationin the feature space.To eliminate the issue of noise accumulation, we propose anovel Progressive Curriculum Labeling (ElimPCL) method, which iterativelyfilters trustworthy pseudo-labeled samples based on prototype consistency toexclude high-noise samples from training. Furthermore, a Dual MixUP techniqueis designed in the feature space to enhance the separability of hard samples,thereby mitigating the interference of noisy samples on theirneighbors.Extensive experiments validate the effectiveness of ElimPCL,achieving up to a 3.4% improvement on challenging tasks compared tostate-of-the-art methods.
  </details>

- **[Expanding-and-Shrinking Binary Neural Networks](http://arxiv.org/abs/2503.23709v1)**  `arXiv:2503.23709`  
  _Xulong Shi, Caiyi Sun, Zhi Qi, Liu Hao, Xiaodong Yang_
  <details><summary>Abstract</summary>
  While binary neural networks (BNNs) offer significant benefits in terms ofspeed, memory and energy, they encounter substantial accuracy degradation inchallenging tasks compared to their real-valued counterparts. Due to thebinarization of weights and activations, the possible values of each entry inthe feature maps generated by BNNs are strongly constrained. To tackle thislimitation, we propose the expanding-and-shrinking operation, which enhancesbinary feature maps with negligible increase of computation complexity, therebystrengthening the representation capacity. Extensive experiments conducted onmultiple benchmarks reveal that our approach generalizes well across diverseapplications ranging from image classification, object detection to generativediffusion model, while also achieving remarkable improvement over variousleading binarization algorithms based on different architectures including bothCNNs and Transformers.
  </details>

- **[3D Dental Model Segmentation with Geometrical Boundary Preserving](http://arxiv.org/abs/2503.23702v1)**  `arXiv:2503.23702`  
  _Shufan Xi, Zexian Liu, Junlin Chang, Hongyu Wu, Xiaogang Wang, Aimin Hao_
  <details><summary>Abstract</summary>
  3D intraoral scan mesh is widely used in digital dentistry diagnosis,segmenting 3D intraoral scan mesh is a critical preliminary task. Numerousapproaches have been devised for precise tooth segmentation. Currently, thedeep learning-based methods are capable of the high accuracy segmentation ofcrown. However, the segmentation accuracy at the junction between the crown andthe gum is still below average. Existing down-sampling methods are unable toeffectively preserve the geometric details at the junction. To address theseproblems, we propose CrossTooth, a boundary-preserving segmentation method thatcombines 3D mesh selective downsampling to retain more vertices at thetooth-gingiva area, along with cross-modal discriminative boundary featuresextracted from multi-view rendered images, enhancing the geometricrepresentation of the segmentation network. Using a point network as a backboneand incorporating image complementary features, CrossTooth significantlyimproves segmentation accuracy, as demonstrated by experiments on a publicintraoral scan dataset.
  </details>

- **[Detail-aware multi-view stereo network for depth estimation](http://arxiv.org/abs/2503.23684v1)**  `arXiv:2503.23684`  
  _Haitao Tian, Junyang Li, Chenxing Wang, Helong Jiang_
  <details><summary>Abstract</summary>
  Multi-view stereo methods have achieved great success for depth estimationbased on the coarse-to-fine depth learning frameworks, however, the existingmethods perform poorly in recovering the depth of object boundaries and detailregions. To address these issues, we propose a detail-aware multi-view stereonetwork (DA-MVSNet) with a coarse-to-fine framework. The geometric depth clueshidden in the coarse stage are utilized to maintain the geometric structuralrelationships between object surfaces and enhance the expressive capability ofimage features. In addition, an image synthesis loss is employed to constrainthe gradient flow for detailed regions and further strengthen the supervisionof object boundaries and texture-rich areas. Finally, we propose an adaptivedepth interval adjustment strategy to improve the accuracy of objectreconstruction. Extensive experiments on the DTU and Tanks & Temples datasetsdemonstrate that our method achieves competitive results. The code is availableat https://github.com/wsmtht520-/DAMVSNet.
  </details>

- **[The Devil is in the Distributions: Explicit Modeling of Scene Content is Key in Zero-Shot Video Captioning](http://arxiv.org/abs/2503.23679v1)**  `arXiv:2503.23679`  
  _Mingkai Tian, Guorong Li, Yuankai Qi, Amin Beheshti, Javen Qinfeng Shi, Anton van den Hengel, et al._
  <details><summary>Abstract</summary>
  Zero-shot video captioning requires that a model generate high-qualitycaptions without human-annotated video-text pairs for training.State-of-the-art approaches to the problem leverage CLIP to extractvisual-relevant textual prompts to guide language models in generatingcaptions. These methods tend to focus on one key aspect of the scene and builda caption that ignores the rest of the visual input. To address this issue, andgenerate more accurate and complete captions, we propose a novel progressivemulti-granularity textual prompting strategy for zero-shot video captioning.Our approach constructs three distinct memory banks, encompassing noun phrases,scene graphs of noun phrases, and entire sentences. Moreover, we introduce acategory-aware retrieval mechanism that models the distribution of naturallanguage surrounding the specific topics in question. Extensive experimentsdemonstrate the effectiveness of our method with 5.7%, 16.2%, and 3.4%improvements in terms of the main metric CIDEr on MSR-VTT, MSVD, and VATEXbenchmarks compared to existing state-of-the-art.
  </details>

- **[Learning Bijective Surface Parameterization for Inferring Signed Distance Functions from Sparse Point Clouds with Grid Deformation](http://arxiv.org/abs/2503.23670v1)**  `arXiv:2503.23670`  
  _Takeshi Noda, Chao Chen, Junsheng Zhou, Weiqi Zhang, Yu-Shen Liu, Zhizhong Han_
  <details><summary>Abstract</summary>
  Inferring signed distance functions (SDFs) from sparse point clouds remains achallenge in surface reconstruction. The key lies in the lack of detailedgeometric information in sparse point clouds, which is essential for learning acontinuous field. To resolve this issue, we present a novel approach thatlearns a dynamic deformation network to predict SDFs in an end-to-end manner.To parameterize a continuous surface from sparse points, we propose a bijectivesurface parameterization (BSP) that learns the global shape from local patches.Specifically, we construct a bijective mapping for sparse points from theparametric domain to 3D local patches, integrating patches into the globalsurface. Meanwhile, we introduce grid deformation optimization (GDO) into thesurface approximation to optimize the deformation of grid points and furtherrefine the parametric surfaces. Experimental results on synthetic and realscanned datasets demonstrate that our method significantly outperforms thecurrent state-of-the-art methods. Project page:https://takeshie.github.io/Bijective-SDF
  </details>

- **[Context-Independent OCR with Multimodal LLMs: Effects of Image Resolution and Visual Complexity](http://arxiv.org/abs/2503.23667v1)**  `arXiv:2503.23667`  
  _Kotaro Inoue_
  <details><summary>Abstract</summary>
  Due to their high versatility in tasks such as image captioning, documentanalysis, and automated content generation, multimodal Large Language Models(LLMs) have attracted significant attention across various industrial fields.In particular, they have been shown to surpass specialized models in OpticalCharacter Recognition (OCR). Nevertheless, their performance under differentimage conditions remains insufficiently investigated, and individual characterrecognition is not guaranteed due to their reliance on contextual cues. In thiswork, we examine a context-independent OCR task using single-character imageswith diverse visual complexities to determine the conditions for accuraterecognition. Our findings reveal that multimodal LLMs can match conventionalOCR methods at about 300 ppi, yet their performance deteriorates significantlybelow 150 ppi. Additionally, we observe a very weak correlation between visualcomplexity and misrecognitions, whereas a conventional OCR-specific modelexhibits no correlation. These results suggest that image resolution and visualcomplexity may play an important role in the reliable application of multimodalLLMs to OCR tasks that require precise character-level accuracy.
  </details>

- **[LiM-Loc: Visual Localization with Dense and Accurate 3D Reference Maps Directly Corresponding 2D Keypoints to 3D LiDAR Point Clouds](http://arxiv.org/abs/2503.23664v1)**  `arXiv:2503.23664`  
  _Masahiko Tsuji, Hitoshi Niigaki, Ryuichi Tanida_
  <details><summary>Abstract</summary>
  Visual localization is to estimate the 6-DOF camera pose of a query image ina 3D reference map. We extract keypoints from the reference image and generatea 3D reference map with 3D reconstruction of the keypoints in advance. Weemphasize that the more keypoints in the 3D reference map and the smaller theerror of the 3D positions of the keypoints, the higher the accuracy of thecamera pose estimation. However, previous image-only methods require a hugenumber of images, and it is difficult to 3D-reconstruct keypoints without errordue to inevitable mismatches and failures in feature matching. As a result, the3D reference map is sparse and inaccurate. In contrast, accurate 3D referencemaps can be generated by combining images and 3D sensors. Recently, 3D-LiDARhas been widely used around the world. LiDAR, which measures a large space withhigh density, has become inexpensive. In addition, accurately calibratedcameras are also widely used, so images that record the external parameters ofthe camera without errors can be easily obtained. In this paper, we propose amethod to directly assign 3D LiDAR point clouds to keypoints to generate denseand accurate 3D reference maps. The proposed method avoids feature matching andachieves accurate 3D reconstruction for almost all keypoints. To estimatecamera pose over a wide area, we use the wide-area LiDAR point cloud to removepoints that are not visible to the camera and reduce 2D-3D correspondenceerrors. Using indoor and outdoor datasets, we apply the proposed method toseveral state-of-the-art local features and confirm that it improves theaccuracy of camera pose estimation.
  </details>

- **[DeepDubber-V1: Towards High Quality and Dialogue, Narration, Monologue Adaptive Movie Dubbing Via Multi-Modal Chain-of-Thoughts Reasoning Guidance](http://arxiv.org/abs/2503.23660v1)**  `arXiv:2503.23660`  
  _Junjie Zheng, Zihao Chen, Chaofan Ding, Xinhan Di_
  <details><summary>Abstract</summary>
  Current movie dubbing technology can generate the desired voice from a givenspeech prompt, ensuring good synchronization between speech and visuals whileaccurately conveying the intended emotions. However, in movie dubbing, keyaspects such as adapting to different dubbing styles, handling dialogue,narration, and monologue effectively, and understanding subtle details like theage and gender of speakers, have not been well studied. To address thischallenge, we propose a framework of multi-modal large language model. First,it utilizes multimodal Chain-of-Thought (CoT) reasoning methods on visualinputs to understand dubbing styles and fine-grained attributes. Second, itgenerates high-quality dubbing through large speech generation models, guidedby multimodal conditions. Additionally, we have developed a movie dubbingdataset with CoT annotations. The evaluation results demonstrate a performanceimprovement over state-of-the-art methods across multiple datasets. Inparticular, for the evaluation metrics, the SPK-SIM and EMO-SIM increases from82.48% to 89.74%, 66.24% to 78.88% for dubbing setting 2.0 on V2C Animationdataset, LSE-D and MCD-SL decreases from 14.79 to 14.63, 5.24 to 4.74 fordubbing setting 2.0 on Grid dataset, SPK-SIM increases from 64.03 to 83.42 andWER decreases from 52.69% to 23.20% for initial reasoning setting on proposedCoT-Movie-Dubbing dataset in the comparison with the state-of-the art models.
  </details>

- **[Introducing the Short-Time Fourier Kolmogorov Arnold Network: A Dynamic Graph CNN Approach for Tree Species Classification in 3D Point Clouds](http://arxiv.org/abs/2503.23647v1)**  `arXiv:2503.23647`  
  _Said Ohamouddoua, Mohamed Ohamouddoub, Rafik Lasrib, Hanaa El Afiaa, Raddouane Chiheba, Abdellatif El Afiaa_
  <details><summary>Abstract</summary>
  Accurate classification of tree species based on Terrestrial Laser Scanning(TLS) and Airborne Laser Scanning (ALS) is essential for biodiversityconservation. While advanced deep learning models for 3D point cloudclassification have demonstrated strong performance in this domain, their highcomplexity often hinders the development of efficient, low-computationarchitectures. In this paper, we introduce STFT-KAN, a novel Kolmogorov-Arnoldnetwork that integrates the Short-Time Fourier Transform (STFT), which canreplace the standard linear layer with activation. We implemented STFT-KANwithin a lightweight version of DGCNN, called liteDGCNN, to classify treespecies using the TLS data. Our experiments show that STFT-KAN outperformsexisting KAN variants by effectively balancing model complexity and performancewith parameter count reduction, achieving competitive results compared toMLP-based models. Additionally, we evaluated a hybrid architecture thatcombines MLP in edge convolution with STFT-KAN in other layers, achievingcomparable performance to MLP models while reducing the parameter count by 50%and 75% compared to other KAN-based variants. Furthermore, we compared ourmodel to leading 3D point cloud learning approaches, demonstrating thatSTFT-KAN delivers competitive results compared to the state-of-the-art methodPointMLP lite with an 87% reduction in parameter count.
  </details>

- **[DSU-Net:An Improved U-Net Model Based on DINOv2 and SAM2 with Multi-scale Cross-model Feature Enhancement](http://arxiv.org/abs/2503.21187v2)**  `arXiv:2503.21187`  
  _Yimin Xu, Fan Yang, Bin Xu_
  <details><summary>Abstract</summary>
  Despite the significant advancements in general image segmentation achievedby large-scale pre-trained foundation models (such as Meta's Segment Any-thingModel (SAM) series and DINOv2), their performance in specialized fields remainslimited by two critical issues: the excessive training costs due to large modelparameters, and the insufficient ability to represent specific domaincharacteristics. This paper proposes a multi-scale feature collabora-tionframework guided by DINOv2 for SAM2, with core innovations in three aspects:(1) Establishing a feature collaboration mechanism between DINOv2 and SAM2backbones, where high-dimensional semantic features extracted by theself-supervised model guide multi-scale feature fusion; (2) Designinglightweight adapter modules and cross-modal, cross-layer feature fusion unitsto inject cross-domain knowledge while freezing the base model parameters; (3)Constructing a U-shaped network structure based on U-net, which utilizesattention mechanisms to achieve adaptive aggregation decoding ofmulti-granularity features. This framework surpasses existing state-of-the-artmeth-ods in downstream tasks such as camouflage target detection and salientob-ject detection, without requiring costly training processes. It provides atech-nical pathway for efficient deployment of visual image segmentation,demon-strating significant application value in a wide range of downstreamtasks and specialized fields within image segmentation.Project page:https://github.com/CheneyXuYiMin/SAM2DINO-Seg
  </details>

- **[Context-Aware Weakly Supervised Image Manipulation Localization with SAM Refinement](http://arxiv.org/abs/2503.20294v2)**  `arXiv:2503.20294`  
  _Xinghao Wang, Tao Gong, Qi Chu, Bin Liu, Nenghai Yu_
  <details><summary>Abstract</summary>
  Malicious image manipulation poses societal risks, increasing the importanceof effective image manipulation detection methods. Recent approaches in imagemanipulation detection have largely been driven by fully supervised approaches,which require labor-intensive pixel-level annotations. Thus, it is essential toexplore weakly supervised image manipulation localization methods that onlyrequire image-level binary labels for training. However, existing weaklysupervised image manipulation methods overlook the importance of edgeinformation for accurate localization, leading to suboptimal localizationperformance. To address this, we propose a Context-Aware Boundary Localization(CABL) module to aggregate boundary features and learn context-inconsistencyfor localizing manipulated areas. Furthermore, by leveraging Class ActivationMapping (CAM) and Segment Anything Model (SAM), we introduce the CAM-Guided SAMRefinement (CGSR) module to generate more accurate manipulation localizationmaps. By integrating two modules, we present a novel weakly supervisedframework based on a dual-branch Transformer-CNN architecture. Our methodachieves outstanding localization performance across multiple datasets.
  </details>

- **[Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping](http://arxiv.org/abs/2503.21817v2)**  `arXiv:2503.21817`  
  _Weili Zeng, Ziyuan Huang, Kaixiang Ji, Yichao Yan_
  <details><summary>Abstract</summary>
  Transformer-based models have driven significant advancements in MultimodalLarge Language Models (MLLMs), yet their computational costs surge drasticallywhen scaling resolution, training data, and model parameters. A key bottleneckstems from the proliferation of visual tokens required for fine-grained imageunderstanding. We propose Skip-Vision, a unified framework addressing bothtraining and inference inefficiencies in vision-language models. On top ofconventional token compression approaches, our method introduces twocomplementary acceleration strategies. For training acceleration, we observethat Feed-Forward Network (FFN) computations on visual tokens induce marginalfeature updates. This motivates our Skip-FFN strategy, which bypasses FFNlayers for redundant visual tokens. For inference acceleration, we design aselective KV-cache removal mechanism that prunes the skipped key-value pairsduring decoding while preserving model performance. Experimental resultsdemonstrate that Skip-Vision reduces training time by up to 35\%, inferenceFLOPs by 75\%, and latency by 45\%, while achieving comparable or superiorperformance to existing methods. Our work provides a practical solution forscaling high-performance MLLMs with enhanced efficiency.
  </details>

- **[Resilient Sensor Fusion under Adverse Sensor Failures via Multi-Modal Expert Fusion](http://arxiv.org/abs/2503.19776v2)**  `arXiv:2503.19776`  
  _Konyul Park, Yecheol Kim, Daehun Kim, Jun Won Choi_
  <details><summary>Abstract</summary>
  Modern autonomous driving perception systems utilize complementarymulti-modal sensors, such as LiDAR and cameras. Although sensor fusionarchitectures enhance performance in challenging environments, they stillsuffer significant performance drops under severe sensor failures, such asLiDAR beam reduction, LiDAR drop, limited field of view, camera drop, andocclusion. This limitation stems from inter-modality dependencies in currentsensor fusion frameworks. In this study, we introduce an efficient and robustLiDAR-camera 3D object detector, referred to as MoME, which can achieve robustperformance through a mixture of experts approach. Our MoME fully decouplesmodality dependencies using three parallel expert decoders, which use camerafeatures, LiDAR features, or a combination of both to decode object queries,respectively. We propose Multi-Expert Decoding (MED) framework, where eachquery is decoded selectively using one of three expert decoders. MoME utilizesan Adaptive Query Router (AQR) to select the most appropriate expert decoderfor each query based on the quality of camera and LiDAR features. This ensuresthat each query is processed by the best-suited expert, resulting in robustperformance across diverse sensor failure scenarios. We evaluated theperformance of MoME on the nuScenes-R benchmark. Our MoME achievedstate-of-the-art performance in extreme weather and sensor failure conditions,significantly outperforming the existing models across various sensor failurescenarios.
  </details>

- **[Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations](http://arxiv.org/abs/2503.19706v2)**  `arXiv:2503.19706`  
  _Jungin Park, Jiyoung Lee, Kwanghoon Sohn_
  <details><summary>Abstract</summary>
  View-invariant representation learning from egocentric (first-person, ego)and exocentric (third-person, exo) videos is a promising approach towardgeneralizing video understanding systems across multiple viewpoints. However,this area has been underexplored due to the substantial differences inperspective, motion patterns, and context between ego and exo views. In thispaper, we propose a novel masked ego-exo modeling that promotes both causaltemporal dynamics and cross-view alignment, called Bootstrap Your Own Views(BYOV), for fine-grained view-invariant video representation learning fromunpaired ego-exo videos. We highlight the importance of capturing thecompositional nature of human actions as a basis for robust cross-viewunderstanding. Specifically, self-view masking and cross-view maskingpredictions are designed to learn view-invariant and powerful representationsconcurrently. Experimental results demonstrate that our BYOV significantlysurpasses existing approaches with notable gains across all metrics in fourdownstream ego-exo video tasks. The code is available athttps://github.com/park-jungin/byov.
  </details>

- **[Mitigating Cache Noise in Test-Time Adaptation for Large Vision-Language Models](http://arxiv.org/abs/2503.18334v2)**  `arXiv:2503.18334`  
  _Haotian Zhai, Xinyu Chen, Can Zhang, Tianming Sha, Ruirui Li_
  <details><summary>Abstract</summary>
  Test-time adaptation (TTA) of visual language models has recently attractedsignificant attention as a solution to the performance degradation caused bydistribution shifts in downstream tasks. However, existing cache-based TTAmethods have certain limitations. They mainly rely on the accuracy of cachedfeature labels, and the presence of noisy pseudo-labels can cause thesefeatures to deviate from their true distribution. This makes cache retrievalmethods based on similarity matching highly sensitive to outliers or extremesamples. Moreover, current methods lack effective mechanisms to model classdistributions, which limits their ability to fully exploit the potential ofcached information. To address these challenges, we introduce a comprehensiveand reliable caching mechanism and propose a novel zero-shot TTA method called"Cache, Residual, Gaussian" (CRG). This method not only employs learnableresidual parameters to better align positive and negative visual prototypeswith text prototypes, thereby optimizing the quality of cached features, butalso incorporates Gaussian Discriminant Analysis (GDA) to dynamically modelintra-class feature distributions, further mitigating the impact of noisyfeatures. Experimental results on 13 benchmarks demonstrate that CRGoutperforms state-of-the-art TTA methods, showcasing exceptional robustness andadaptability.
  </details>

- **[Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image](http://arxiv.org/abs/2503.17358v2)**  `arXiv:2503.17358`  
  _Jerred Chen, Ronald Clark_
  <details><summary>Abstract</summary>
  In many robotics and VR/AR applications, fast camera motions cause a highlevel of motion blur, causing existing camera pose estimation methods to fail.In this work, we propose a novel framework that leverages motion blur as a richcue for motion estimation rather than treating it as an unwanted artifact. Ourapproach works by predicting a dense motion flow field and a monocular depthmap directly from a single motion-blurred image. We then recover theinstantaneous camera velocity by solving a linear least squares problem underthe small motion assumption. In essence, our method produces an IMU-likemeasurement that robustly captures fast and aggressive camera movements. Totrain our model, we construct a large-scale dataset with realistic syntheticmotion blur derived from ScanNet++v2 and further refine our model by trainingend-to-end on real data using our fully differentiable pipeline. Extensiveevaluations on real-world benchmarks demonstrate that our method achievesstate-of-the-art angular and translational velocity estimates, outperformingcurrent methods like MASt3R and COLMAP.
  </details>

- **[MagicDistillation: Weak-to-Strong Video Distillation for Large-Scale Few-Step Synthesis](http://arxiv.org/abs/2503.13319v2)**  `arXiv:2503.13319`  
  _Shitong Shao, Hongwei Yi, Hanzhong Guo, Tian Ye, Daquan Zhou, Michael Lingelbach, et al._
  <details><summary>Abstract</summary>
  Recently, open-source video diffusion models (VDMs), such as WanX, Magic141and HunyuanVideo, have been scaled to over 10 billion parameters. Theselarge-scale VDMs have demonstrated significant improvements over smaller-scaleVDMs across multiple dimensions, including enhanced visual quality and morenatural motion dynamics. However, these models face two major limitations: (1)High inference overhead: Large-scale VDMs require approximately 10 minutes tosynthesize a 28-step video on a single H100 GPU. (2) Limited in portrait videosynthesis: Models like WanX-I2V and HunyuanVideo-I2V often produce unnaturalfacial expressions and movements in portrait videos. To address thesechallenges, we propose MagicDistillation, a novel framework designed to reduceinference overhead while ensuring the generalization of VDMs for portrait videosynthesis. Specifically, we primarily use sufficiently high-quality talkingvideo to fine-tune Magic141, which is dedicated to portrait video synthesis. Wethen employ LoRA to effectively and efficiently fine-tune the fake DiT withinthe step distillation framework known as distribution matching distillation(DMD). Following this, we apply weak-to-strong (W2S) distribution matching andminimize the discrepancy between the fake data distribution and the groundtruth distribution, thereby improving the visual fidelity and motion dynamicsof the synthesized videos. Experimental results on portrait video synthesisdemonstrate the effectiveness of MagicDistillation, as our method surpassesEuler, LCM, and DMD baselines in both FID/FVD metrics and VBench. Moreover,MagicDistillation, requiring only 4 steps, also outperforms WanX-I2V (14B) andHunyuanVideo-I2V (13B) on visualization and VBench. Our project page ishttps://magicdistillation.github.io/MagicDistillation/.
  </details>

- **[An interpretable approach to automating the assessment of biofouling in video footage](http://arxiv.org/abs/2503.12875v2)**  `arXiv:2503.12875`  
  _Evelyn J. Mannix, Bartholomew A. Woodham_
  <details><summary>Abstract</summary>
  Biofouling$\unicode{x2013}$communities of organisms that grow on hardsurfaces immersed in water$\unicode{x2013}$provides a pathway for the spread ofinvasive marine species and diseases. To address this risk, internationalvessels are increasingly being obligated to provide evidence of theirbiofouling management practices. Verification that these activities areeffective requires underwater inspections, using divers or underwater remotelyoperated vehicles (ROVs), and the collection and analysis of large amounts ofimagery and footage. Automated assessment using computer vision techniques cansignificantly streamline this process, and this work shows how this challengecan be addressed efficiently and effectively using the interpretable ComponentFeatures (ComFe) approach with a DINOv2 Vision Transformer (ViT) foundationmodel. ComFe is able to obtain improved performance in comparison to previousnon-interpretable Convolutional Neural Network (CNN) methods, withsignificantly fewer weights and greater transparency$\unicode{x2013}$throughidentifying which regions of the image contribute to the classification, andwhich images in the training data lead to that conclusion. All code, data andmodel weights are publicly released.
  </details>

- **[Will Pre-Training Ever End? A First Step Toward Next-Generation Foundation MLLMs via Self-Improving Systematic Cognition](http://arxiv.org/abs/2503.12303v5)**  `arXiv:2503.12303`  
  _Xiaoying Zhang, Da Peng, Yipeng Zhang, Zonghao Guo, Chengyue Wu, Chi Chen, et al._
  <details><summary>Abstract</summary>
  Recent progress in (multimodal) large language models ((M)LLMs) has shiftedfocus from pre-training to inference-time compute scaling and post-trainingoptimization, driven by concerns over limited high-quality real-world data.However, these strategies alone are insufficient for advancing modelcapabilities. We hypothesize that effective model improvement requires a strongsynergy among pre-training, inference-time compute scaling, and post-trainingoptimization. In this paper, we validate this hypothesis in the context ofmultimodal pre-training for foundation MLLM construction. We introduceSelf-Improving cognition (SIcog), a self-learning framework for constructingnext-generation foundation MLLMs by imparting multimodal knowledge andenhancing their systematic cognitive capabilities through multimodalpre-training with self-generated data. Specifically, we introduceChain-of-Description, a step-by-step visual understanding method to improvecomprehensive perception, and integrate structured chain-of-thought (CoT)reasoning to support in-depth multimodal reasoning. SIcog first equips a basemodel with systematic perception and reasoning using minimal externalsupervision. The enhanced model then generates candidate image captions andCoT-style reasoning responses for unlabeled images and image-question pairsacross diverse tasks, which are curated through a self-consistency mechanism.These curated samples are subsequently used for large-scale multimodalpre-training, completing a self-learning cycle that strengthens the model'scognitive foundation. Extensive experiments demonstrate that SIcog producesnext-generation foundation MLLMs with substantially improved multimodalcognition, outperforming prevailing pre-training approaches. These findingsempirically establish SIcog as a promising framework for realizing a completeself-improving paradigm.
  </details>

- **[Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior](http://arxiv.org/abs/2502.21048v2)**  `arXiv:2502.21048`  
  _Chanhui Lee, Yeonghwan Song, Jeany Son_
  <details><summary>Abstract</summary>
  Data-free Universal Adversarial Perturbation (UAP) is an image-agnosticadversarial attack that deceives deep neural networks using a singleperturbation generated solely from random noise without relying on data priors.However, traditional data-free UAP methods often suffer from limitedtransferability due to the absence of semantic content in random noise. Toaddress this issue, we propose a novel data-free universal attack method thatrecursively extracts pseudo-semantic priors directly from the UAPs duringtraining to enrich the semantic content within the data-free UAP framework. Ourapproach effectively leverages latent semantic information within UAPs viaregion sampling, enabling successful input transformations-typicallyineffective in traditional data-free UAP methods due to the lack of semanticcues-and significantly enhancing black-box transferability. Furthermore, weintroduce a sample reweighting technique to mitigate potential imbalances fromrandom sampling and transformations, emphasizing hard examples less affected bythe UAPs. Comprehensive experiments on ImageNet show that our method achievesstate-of-the-art performance in average fooling rate by a substantial margin,notably improves attack transferability across various CNN architecturescompared to existing data-free UAP methods, and even surpasses data-dependentUAP methods. Code is available at: https://github.com/ChnanChan/PSP-UAP.
  </details>

- **[InPK: Infusing Prior Knowledge into Prompt for Vision-Language Models](http://arxiv.org/abs/2502.19777v2)**  `arXiv:2502.19777`  
  _Shuchang Zhou, Jiwei Wei, Shiyuan He, Yuyang Zhou, Chaoning Zhang, Jie Zou, et al._
  <details><summary>Abstract</summary>
  Prompt tuning has become a popular strategy for adapting Vision-LanguageModels (VLMs) to zero/few-shot visual recognition tasks. Some promptingtechniques introduce prior knowledge due to its richness, but when learnabletokens are randomly initialized and disconnected from prior knowledge, theytend to overfit on seen classes and struggle with domain shifts for unseenones. To address this issue, we propose the InPK model, which infusesclass-specific prior knowledge into the learnable tokens during initialization,thus enabling the model to explicitly focus on class-relevant information.Furthermore, to mitigate the weakening of class information by multi-layerencoders, we continuously reinforce the interaction between learnable tokensand prior knowledge across multiple feature levels. This progressiveinteraction allows the learnable tokens to better capture the fine-graineddifferences and universal visual concepts within prior knowledge, enabling themodel to extract more discriminative and generalized text features. Even forunseen classes, the learned interaction allows the model to capture theircommon representations and infer their appropriate positions within theexisting semantic structure. Moreover, we introduce a learnable text-to-visionprojection layer to accommodate the text adjustments, ensuring better alignmentof visual-text semantics. Extensive experiments on 11 recognition datasets showthat InPK significantly outperforms state-of-the-art methods in multiplezero/few-shot image classification tasks.
  </details>

- **[On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video Generation for Mobile Devices](http://arxiv.org/abs/2502.04363v2)**  `arXiv:2502.04363`  
  _Bosung Kim, Kyuhwan Lee, Isu Jeong, Jungmin Cheon, Yeojin Lee, Seulki Lee_
  <details><summary>Abstract</summary>
  We present On-device Sora, the first model training-free solution fordiffusion-based on-device text-to-video generation that operates efficiently onsmartphone-grade devices. To address the challenges of diffusion-basedtext-to-video generation on computation- and memory-limited mobile devices, theproposed On-device Sora applies three novel techniques to pre-trained videogenerative models. First, Linear Proportional Leap (LPL) reduces the excessivedenoising steps required in video diffusion through an efficient leap-basedapproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensivetoken-processing computation in attention layers by merging consecutive tokensalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading(CI-DL) dynamically partitions large models into smaller blocks and loads theminto memory for concurrent model inference, effectively addressing thechallenges of limited device memory. We implement On-device Sora on the iPhone15 Pro, and the experimental evaluations show that it is capable of generatinghigh-quality videos on the device, comparable to those produced by high-endGPUs. These results show that On-device Sora enables efficient and high-qualityvideo generation on resource-constrained mobile devices. We envision theproposed On-device Sora as a significant first step toward democratizingstate-of-the-art generative technologies, enabling video generation oncommodity mobile and embedded devices without resource-intensive re-trainingfor model optimization (compression). The code implementation is available at aGitHub repository(https://github.com/eai-lab/On-device-Sora).
  </details>

- **[Enhancing Intent Understanding for Ambiguous prompt: A Human-Machine Co-Adaption Strategy](http://arxiv.org/abs/2501.15167v4)**  `arXiv:2501.15167`  
  _Yangfan He, Jianhui Wang, Yijin Wang, Kun Li, Yan Zhong, Xinyuan Song, et al._
  <details><summary>Abstract</summary>
  Today's image generation systems are capable of producing realistic andhigh-quality images. However, user prompts often contain ambiguities, making itdifficult for these systems to interpret users' actual intentions.Consequently, many users must modify their prompts several times to ensure thegenerated images meet their expectations. While some methods focus on enhancingprompts to make the generated images fit user needs, the model is still hard tounderstand users' real needs, especially for non-expert users. In thisresearch, we aim to enhance the visual parameter-tuning process, making themodel user-friendly for individuals without specialized knowledge and betterunderstand user needs. We propose a human-machine co-adaption strategy usingmutual information between the user's prompts and the pictures undermodification as the optimizing target to make the system better adapt to userneeds. We find that an improved model can reduce the necessity for multiplerounds of adjustments. We also collect multi-round dialogue datasets withprompts and images pairs and user intent. Various experiments demonstrate theeffectiveness of the proposed method in our proposed dataset. Our annotationtools and several examples of our dataset are available athttps://zenodo.org/records/14876029 for easier review. We will make open sourceour full dataset and code.
  </details>

- **[Finer-CAM: Spotting the Difference Reveals Finer Details for Visual Explanation](http://arxiv.org/abs/2501.11309v2)**  `arXiv:2501.11309`  
  _Ziheng Zhang, Jianyang Gu, Arpita Chowdhury, Zheda Mai, David Carlyn, Tanya Berger-Wolf, et al._
  <details><summary>Abstract</summary>
  Class activation map (CAM) has been widely used to highlight image regionsthat contribute to class predictions. Despite its simplicity and computationalefficiency, CAM often struggles to identify discriminative regions thatdistinguish visually similar fine-grained classes. Prior efforts address thislimitation by introducing more sophisticated explanation processes, but at thecost of extra complexity. In this paper, we propose Finer-CAM, a method thatretains CAM's efficiency while achieving precise localization of discriminativeregions. Our key insight is that the deficiency of CAM lies not in "how" itexplains, but in "what" it explains. Specifically, previous methods attempt toidentify all cues contributing to the target class's logit value, whichinadvertently also activates regions predictive of visually similar classes. Byexplicitly comparing the target class with similar classes and spotting theirdifferences, Finer-CAM suppresses features shared with other classes andemphasizes the unique, discriminative details of the target class. Finer-CAM iseasy to implement, compatible with various CAM methods, and can be extended tomulti-modal models for accurate localization of specific concepts.Additionally, Finer-CAM allows adjustable comparison strength, enabling usersto selectively highlight coarse object contours or fine discriminative details.Quantitatively, we show that masking out the top 5% of activated pixels byFiner-CAM results in a larger relative confidence drop compared to baselines.The source code and demo are available athttps://github.com/Imageomics/Finer-CAM.
  </details>

- **[Know "No'' Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP](http://arxiv.org/abs/2501.10913v2)**  `arXiv:2501.10913`  
  _Junsung Park, Jungbeom Lee, Jongyoon Song, Sangwon Yu, Dahuin Jung, Sungroh Yoon_
  <details><summary>Abstract</summary>
  While CLIP has significantly advanced multimodal understanding by bridgingvision and language, the inability to grasp negation - such as failing todifferentiate concepts like "parking" from "no parking" - poses substantialchallenges. By analyzing the data used in the public CLIP model's pre-training,we posit this limitation stems from a lack of negation-inclusive data. Toaddress this, we introduce data generation pipelines that employ a largelanguage model (LLM) and a multimodal LLM to produce negation-inclusivecaptions. Fine-tuning CLIP with data generated from our pipelines, we developNegationCLIP, which enhances negation awareness while preserving thegenerality. Moreover, to enable a comprehensive evaluation of negationunderstanding, we propose NegRefCOCOg-a benchmark tailored to test VLMs'ability to interpret negation across diverse expressions and positions within asentence. Experiments on various CLIP architectures validate the effectivenessof our data generation pipelines in enhancing CLIP's ability to perceivenegation accurately. Additionally, NegationCLIP's enhanced negation awarenesshas practical applications across various multimodal tasks, demonstrated byperformance gains in text-to-image generation and referring image segmentation.
  </details>

- **[Synthetic Prior for Few-Shot Drivable Head Avatar Inversion](http://arxiv.org/abs/2501.06903v3)**  `arXiv:2501.06903`  
  _Wojciech Zielonka, Stephan J. Garbin, Alexandros Lattas, George Kopanas, Paulo Gotardo, Thabo Beeler, et al._
  <details><summary>Abstract</summary>
  We present SynShot, a novel method for the few-shot inversion of a drivablehead avatar based on a synthetic prior. We tackle three major challenges.First, training a controllable 3D generative network requires a large number ofdiverse sequences, for which pairs of images and high-quality tracked meshesare not always available. Second, the use of real data is strictly regulated(e.g., under the General Data Protection Regulation, which mandates frequentdeletion of models and data to accommodate a situation when a participant'sconsent is withdrawn). Synthetic data, free from these constraints, is anappealing alternative. Third, state-of-the-art monocular avatar models struggleto generalize to new views and expressions, lacking a strong prior and oftenoverfitting to a specific viewpoint distribution. Inspired by machine learningmodels trained solely on synthetic data, we propose a method that learns aprior model from a large dataset of synthetic heads with diverse identities,expressions, and viewpoints. With few input images, SynShot fine-tunes thepretrained synthetic prior to bridge the domain gap, modeling a photorealistichead avatar that generalizes to novel expressions and viewpoints. We model thehead avatar using 3D Gaussian splatting and a convolutional encoder-decoderthat outputs Gaussian parameters in UV texture space. To account for thedifferent modeling complexities over parts of the head (e.g., skin vs hair), weembed the prior with explicit control for upsampling the number of per-partprimitives. Compared to SOTA monocular and GAN-based methods, SynShotsignificantly improves novel view and expression synthesis.
  </details>

- **[Singular Value Scaling: Efficient Generative Model Compression via Pruned Weights Refinement](http://arxiv.org/abs/2412.17387v3)**  `arXiv:2412.17387`  
  _Hyeonjin Kim, Jaejun Yoo_
  <details><summary>Abstract</summary>
  While pruning methods effectively maintain model performance without extratraining costs, they often focus solely on preserving crucial connections,overlooking the impact of pruned weights on subsequent fine-tuning ordistillation, leading to inefficiencies. Moreover, most compression techniquesfor generative models have been developed primarily for GANs, tailored tospecific architectures like StyleGAN, and research into compressing Diffusionmodels has just begun. Even more, these methods are often applicable only toGANs or Diffusion models, highlighting the need for approaches that work acrossboth model types. In this paper, we introduce Singular Value Scaling (SVS), aversatile technique for refining pruned weights, applicable to both modeltypes. Our analysis reveals that pruned weights often exhibit dominant singularvectors, hindering fine-tuning efficiency and leading to suboptimal performancecompared to random initialization. Our method enhances weight initialization byminimizing the disparities between singular values of pruned weights, therebyimproving the fine-tuning process. This approach not only guides the compressedmodel toward superior solutions but also significantly speeds up fine-tuning.Extensive experiments on StyleGAN2, StyleGAN3 and DDPM demonstrate that SVSimproves compression performance across model types without additional trainingcosts. Our code is available at:https://github.com/LAIT-CVLab/Singular-Value-Scaling.
  </details>

- **[HyperGLM: HyperGraph for Video Scene Graph Generation and Anticipation](http://arxiv.org/abs/2411.18042v2)**  `arXiv:2411.18042`  
  _Trong-Thuan Nguyen, Pha Nguyen, Jackson Cothren, Alper Yilmaz, Khoa Luu_
  <details><summary>Abstract</summary>
  Multimodal LLMs have advanced vision-language tasks but still struggle withunderstanding video scenes. To bridge this gap, Video Scene Graph Generation(VidSGG) has emerged to capture multi-object relationships across video frames.However, prior methods rely on pairwise connections, limiting their ability tohandle complex multi-object interactions and reasoning. To this end, we proposeMultimodal LLMs on a Scene HyperGraph (HyperGLM), promoting reasoning aboutmulti-way interactions and higher-order relationships. Our approach uniquelyintegrates entity scene graphs, which capture spatial relationships betweenobjects, with a procedural graph that models their causal transitions, forminga unified HyperGraph. Significantly, HyperGLM enables reasoning by injectingthis unified HyperGraph into LLMs. Additionally, we introduce a new Video SceneGraph Reasoning (VSGR) dataset featuring 1.9M frames from third-person,egocentric, and drone views and supports five tasks: Scene Graph Generation,Scene Graph Anticipation, Video Question Answering, Video Captioning, andRelation Reasoning. Empirically, HyperGLM consistently outperformsstate-of-the-art methods across five tasks, effectively modeling and reasoningcomplex relationships in diverse video scenes.
  </details>

- **[Beyond Walking: A Large-Scale Image-Text Benchmark for Text-based Person Anomaly Search](http://arxiv.org/abs/2411.17776v2)**  `arXiv:2411.17776`  
  _Shuyu Yang, Yaxiong Wang, Li Zhu, Zhedong Zheng_
  <details><summary>Abstract</summary>
  Text-based person search aims to retrieve specific individuals across cameranetworks using natural language descriptions. However, current benchmarks oftenexhibit biases towards common actions like walking or standing, neglecting thecritical need for identifying abnormal behaviors in real-world scenarios. Tomeet such demands, we propose a new task, text-based person anomaly search,locating pedestrians engaged in both routine or anomalous activities via text.To enable the training and evaluation of this new task, we construct alarge-scale image-text Pedestrian Anomaly Behavior (PAB) benchmark, featuring abroad spectrum of actions, e.g., running, performing, playing soccer, and thecorresponding anomalies, e.g., lying, being hit, and falling of the sameidentity. The training set of PAB comprises 1,013,605 synthesized image-textpairs of both normalities and anomalies, while the test set includes 1,978real-world image-text pairs. To validate the potential of PAB, we introduce across-modal pose-aware framework, which integrates human pose patterns withidentity-based hard negative pair sampling. Extensive experiments on theproposed benchmark show that synthetic training data facilitates thefine-grained behavior retrieval, and the proposed pose-aware method arrives at84.93% recall@1 accuracy, surpassing other competitive methods. The dataset,model, and code are available at https://github.com/Shuyu-XJTU/CMP.
  </details>

- **[Controllable Human Image Generation with Personalized Multi-Garments](http://arxiv.org/abs/2411.16801v2)**  `arXiv:2411.16801`  
  _Yisol Choi, Sangkyung Kwak, Sihyun Yu, Hyungwon Choi, Jinwoo Shin_
  <details><summary>Abstract</summary>
  We present BootComp, a novel framework based on text-to-image diffusionmodels for controllable human image generation with multiple referencegarments. Here, the main bottleneck is data acquisition for training:collecting a large-scale dataset of high-quality reference garment images perhuman subject is quite challenging, i.e., ideally, one needs to manually gatherevery single garment photograph worn by each human. To address this, we proposea data generation pipeline to construct a large synthetic dataset, consistingof human and multiple-garment pairs, by introducing a model to extract anyreference garment images from each human image. To ensure data quality, we alsopropose a filtering strategy to remove undesirable generated data based onmeasuring perceptual similarities between the garment presented in human imageand extracted garment. Finally, by utilizing the constructed synthetic dataset,we train a diffusion model having two parallel denoising paths that usemultiple garment images as conditions to generate human images while preservingtheir fine-grained details. We further show the wide-applicability of ourframework by adapting it to different types of reference-based generation inthe fashion domain, including virtual try-on, and controllable human imagegeneration with other conditions, e.g., pose, face, etc.
  </details>

- **[MovieBench: A Hierarchical Movie Level Dataset for Long Video Generation](http://arxiv.org/abs/2411.15262v2)**  `arXiv:2411.15262`  
  _Weijia Wu, Mingyu Liu, Zeyu Zhu, Xi Xia, Haoen Feng, Wen Wang, et al._
  <details><summary>Abstract</summary>
  Recent advancements in video generation models, like Stable Video Diffusion,show promising results, but primarily focus on short, single-scene videos.These models struggle with generating long videos that involve multiple scenes,coherent narratives, and consistent characters. Furthermore, there is nopublicly available dataset tailored for the analysis, evaluation, and trainingof long video generation models. In this paper, we present MovieBench: AHierarchical Movie-Level Dataset for Long Video Generation, which addressesthese challenges by providing unique contributions: (1) movie-length videosfeaturing rich, coherent storylines and multi-scene narratives, (2) consistencyof character appearance and audio across scenes, and (3) hierarchical datastructure contains high-level movie information and detailed shot-leveldescriptions. Experiments demonstrate that MovieBench brings some new insightsand challenges, such as maintaining character ID consistency across multiplescenes for various characters. The dataset will be public and continuouslymaintained, aiming to advance the field of long video generation. Data can befound at: https://weijiawu.github.io/MovieBench/.
  </details>

- **[Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios](http://arxiv.org/abs/2410.17193v2)**  `arXiv:2410.17193`  
  _Kai Wang, Zekai Li, Zhi-Qi Cheng, Samir Khaki, Ahmad Sajedi, Ramakrishna Vedantam, et al._
  <details><summary>Abstract</summary>
  Dataset distillation has demonstrated strong performance on simple datasetslike CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results inmore complex scenarios. In this paper, we propose EDF (emphasizes thediscriminative features), a dataset distillation method that enhances keydiscriminative regions in synthetic images using Grad-CAM activation maps. Ourapproach is inspired by a key observation: in simple datasets, high-activationareas typically occupy most of the image, whereas in complex scenarios, thesize of these areas is much smaller. Unlike previous methods that treat allpixels equally when synthesizing images, EDF uses Grad-CAM activation maps toenhance high-activation areas. From a supervision perspective, we downplaysupervision signals that have lower losses, as they contain common patterns.Additionally, to help the DD community better explore complex scenarios, webuild the Complex Dataset Distillation (Comp-DD) benchmark by meticulouslyselecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. Inparticular, EDF consistently outperforms SOTA results in complex scenarios,such as ImageNet-1K subsets. Hopefully, more researchers will be inspired andencouraged to improve the practicality and efficacy of DD. Our code andbenchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.
  </details>

- **[YOLO11 and Vision Transformers based 3D Pose Estimation of Immature Green Fruits in Commercial Apple Orchards for Robotic Thinning](http://arxiv.org/abs/2410.19846v3)**  `arXiv:2410.19846`  
  _Ranjan Sapkota, Manoj Karkee_
  <details><summary>Abstract</summary>
  In this study, a robust method for 3D pose estimation of immature greenapples (fruitlets) in commercial orchards was developed, utilizing theYOLO11(or YOLOv11) object detection and pose estimation algorithm alongsideVision Transformers (ViT) for depth estimation (Dense Prediction Transformer(DPT) and Depth Anything V2). For object detection and pose estimation,performance comparisons of YOLO11 (YOLO11n, YOLO11s, YOLO11m, YOLO11l andYOLO11x) and YOLOv8 (YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l and YOLOv8x) were madeunder identical hyperparameter settings among the all configurations. It wasobserved that YOLO11n surpassed all configurations of YOLO11 and YOLOv8 interms of box precision and pose precision, achieving scores of 0.91 and 0.915,respectively. Conversely, YOLOv8n exhibited the highest box and pose recallscores of 0.905 and 0.925, respectively. Regarding the mean average precisionat 50\% intersection over union (mAP@50), YOLO11s led all configurations with abox mAP@50 score of 0.94, while YOLOv8n achieved the highest pose mAP@50 scoreof 0.96. In terms of image processing speed, YOLO11n outperformed allconfigurations with an impressive inference speed of 2.7 ms, significantlyfaster than the quickest YOLOv8 configuration, YOLOv8n, which processed imagesin 7.8 ms. Subsequent integration of ViTs for the green fruit's pose depthestimation revealed that Depth Anything V2 outperformed Dense PredictionTransformer in 3D pose length validation, achieving the lowest Root Mean SquareError (RMSE) of 1.52 and Mean Absolute Error (MAE) of 1.28, demonstratingexceptional precision in estimating immature green fruit lengths. Integrationof YOLO11 and Depth Anything Model provides a promising solution to 3D poseestimation of immature green fruits for robotic thinning applications. (YOLOv11pose detection, YOLOv11 Pose, YOLOv11 Keypoints detection, YOLOv11 poseestimation)
  </details>

- **[MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models](http://arxiv.org/abs/2410.10139v2)**  `arXiv:2410.10139`  
  _Peng Xia, Siwei Han, Shi Qiu, Yiyang Zhou, Zhaoyang Wang, Wenhao Zheng, et al._
  <details><summary>Abstract</summary>
  Interleaved multimodal comprehension and generation, enabling models toproduce and interpret both images and text in arbitrary sequences, have becomea pivotal area in multimodal learning. Despite significant advancements, theevaluation of this capability remains insufficient. Existing benchmarks sufferfrom limitations in data scale, scope, and evaluation depth, while currentevaluation metrics are often costly or biased, lacking in reliability forpractical applications. To address these challenges, we introduce MMIE, alarge-scale knowledge-intensive benchmark for evaluating interleaved multimodalcomprehension and generation in Large Vision-Language Models (LVLMs). MMIEcomprises 20K meticulously curated multimodal queries, spanning 3 categories,12 fields, and 102 subfields, including mathematics, coding, physics,literature, health, and arts. It supports both interleaved inputs and outputs,offering a mix of multiple-choice and open-ended question formats to evaluatediverse competencies. Moreover, we propose a reliable automated evaluationmetric, leveraging a scoring model fine-tuned with human-annotated data andsystematic evaluation criteria, aimed at reducing bias and improving evaluationaccuracy. Extensive experiments demonstrate the effectiveness of our benchmarkand metrics in providing a comprehensive evaluation of interleaved LVLMs.Specifically, we evaluate eight LVLMs, revealing that even the best models showsignificant room for improvement, with most achieving only moderate results. Webelieve MMIE will drive further advancements in the development of interleavedLVLMs. We publicly release our benchmark and code inhttps://mmie-bench.github.io/.
  </details>

- **[DICE: Discrete Inversion Enabling Controllable Editing for Multinomial Diffusion and Masked Generative Models](http://arxiv.org/abs/2410.08207v2)**  `arXiv:2410.08207`  
  _Xiaoxiao He, Ligong Han, Quan Dao, Song Wen, Minhao Bai, Di Liu, et al._
  <details><summary>Abstract</summary>
  Discrete diffusion models have achieved success in tasks like imagegeneration and masked language modeling but face limitations in controlledcontent editing. We introduce DICE (Discrete Inversion for ControllableEditing), the first approach to enable precise inversion for discrete diffusionmodels, including multinomial diffusion and masked generative models. Byrecording noise sequences and masking patterns during the reverse diffusionprocess, DICE enables accurate reconstruction and flexible editing of discretedata without the need for predefined masks or attention manipulation. Wedemonstrate the effectiveness of DICE across both image and text domains,evaluating it on models such as VQ-Diffusion, Paella, and RoBERTa. Our resultsshow that DICE preserves high data fidelity while enhancing editingcapabilities, offering new opportunities for fine-grained content manipulationin discrete spaces.
  </details>

- **[Reversible Decoupling Network for Single Image Reflection Removal](http://arxiv.org/abs/2410.08063v2)**  `arXiv:2410.08063`  
  _Hao Zhao, Mingjia Li, Qiming Hu, Xiaojie Guo_
  <details><summary>Abstract</summary>
  Recent deep-learning-based approaches to single-image reflection removal haveshown promising advances, primarily for two reasons: 1) the utilization ofrecognition-pretrained features as inputs, and 2) the design of dual-streaminteraction networks. However, according to the Information Bottleneckprinciple, high-level semantic clues tend to be compressed or discarded duringlayer-by-layer propagation. Additionally, interactions in dual-stream networksfollow a fixed pattern across different layers, limiting overall performance.To address these limitations, we propose a novel architecture called ReversibleDecoupling Network (RDNet), which employs a reversible encoder to securevaluable information while flexibly decoupling transmission- andreflection-relevant features during the forward pass. Furthermore, we customizea transmission-rate-aware prompt generator to dynamically calibrate features,further boosting performance. Extensive experiments demonstrate the superiorityof RDNet over existing SOTA methods on five widely-adopted benchmark datasets.RDNet achieves the best performance in the NTIRE 2025 Single Image ReflectionRemoval in the Wild Challenge in both fidelity and perceptual comparison. Ourcode is available at https://github.com/lime-j/RDNet
  </details>

- **[CASA: Class-Agnostic Shared Attributes in Vision-Language Models for Efficient Incremental Object Detection](http://arxiv.org/abs/2410.05804v3)**  `arXiv:2410.05804`  
  _Mingyi Guo, Yuyang Liu, Zhiyuan Yan, Zongying Lin, Peixi Peng, Yonghong Tian_
  <details><summary>Abstract</summary>
  Incremental object detection is fundamentally challenged by catastrophicforgetting. A major factor contributing to this issue is background shift,where background categories in sequential tasks may overlap with eitherpreviously learned or future unseen classes. To address this, we propose anovel method called Class-Agnostic Shared Attribute Base (CASA) that encouragesthe model to learn category-agnostic attributes shared across incrementalclasses. Our approach leverages an LLM to generate candidate textualattributes, selects the most relevant ones based on the current training data,and records their importance in an assignment matrix. For subsequent tasks, theretained attributes are frozen, and new attributes are selected from theremaining candidates, ensuring both knowledge retention and adaptability.Extensive experiments on the COCO dataset demonstrate the state-of-the-artperformance of our method.
  </details>

- **[RingMo-Aerial: An Aerial Remote Sensing Foundation Model With A Affine Transformation Contrastive Learning](http://arxiv.org/abs/2409.13366v2)**  `arXiv:2409.13366`  
  _Wenhui Diao, Haichen Yu, Kaiyue Kang, Tong Ling, Di Liu, Yingchao Feng, et al._
  <details><summary>Abstract</summary>
  Aerial Remote Sensing (ARS) vision tasks pose significant challenges due tothe unique characteristics of their viewing angles. Existing research hasprimarily focused on algorithms for specific tasks, which have limitedapplicability in a broad range of ARS vision applications. This paper proposesthe RingMo-Aerial model, aiming to fill the gap in foundation model research inthe field of ARS vision. By introducing the Frequency-Enhanced Multi-HeadSelf-Attention (FE-MSA) mechanism and an affine transformation-basedcontrastive learning pre-training method, the model's detection capability forsmall targets is enhanced and optimized for the tilted viewing anglescharacteristic of ARS. Furthermore, the ARS-Adapter, an efficient parameterfine-tuning method, is proposed to improve the model's adaptability andeffectiveness in various ARS vision tasks. Experimental results demonstratethat RingMo-Aerial achieves SOTA performance on multiple downstream tasks. Thisindicates the practicality and efficacy of RingMo-Aerial in enhancing theperformance of ARS vision tasks.
  </details>

- **[3D-GSW: 3D Gaussian Splatting for Robust Watermarking](http://arxiv.org/abs/2409.13222v4)**  `arXiv:2409.13222`  
  _Youngdong Jang, Hyunje Park, Feng Yang, Heeju Ko, Euijin Choo, Sangpil Kim_
  <details><summary>Abstract</summary>
  As 3D Gaussian Splatting (3D-GS) gains significant attention and itscommercial usage increases, the need for watermarking technologies to preventunauthorized use of the 3D-GS models and rendered images has becomeincreasingly important. In this paper, we introduce a robust watermarkingmethod for 3D-GS that secures copyright of both the model and its renderedimages. Our proposed method remains robust against distortions in renderedimages and model attacks while maintaining high rendering quality. To achievethese objectives, we present Frequency-Guided Densification (FGD), whichremoves 3D Gaussians based on their contribution to rendering quality,enhancing real-time rendering and the robustness of the message. FGD utilizesDiscrete Fourier Transform to split 3D Gaussians in high-frequency areas,improving rendering quality. Furthermore, we employ a gradient mask for 3DGaussians and design a wavelet-subband loss to enhance rendering quality. Ourexperiments show that our method embeds the message in the rendered imagesinvisibly and robustly against various attacks, including model distortion. Ourmethod achieves superior performance in both rendering quality and watermarkrobustness while improving real-time rendering efficiency. Project page:https://kuai-lab.github.io/cvpr20253dgsw/
  </details>

- **[Cropper: Vision-Language Model for Image Cropping through In-Context Learning](http://arxiv.org/abs/2408.07790v2)**  `arXiv:2408.07790`  
  _Seung Hyun Lee, Jijun Jiang, Yiran Xu, Zhuofang Li, Junjie Ke, Yinxiao Li, et al._
  <details><summary>Abstract</summary>
  The goal of image cropping is to identify visually appealing crops in animage. Conventional methods are trained on specific datasets and fail to adaptto new requirements. Recent breakthroughs in large vision-language models(VLMs) enable visual in-context learning without explicit training. However,downstream tasks with VLMs remain under explored. In this paper, we propose aneffective approach to leverage VLMs for image cropping. First, we propose anefficient prompt retrieval mechanism for image cropping to automate theselection of in-context examples. Second, we introduce an iterative refinementstrategy to iteratively enhance the predicted crops. The proposed framework, werefer to as Cropper, is applicable to a wide range of cropping tasks, includingfree-form cropping, subject-aware cropping, and aspect ratio-aware cropping.Extensive experiments demonstrate that Cropper significantly outperformsstate-of-the-art methods across several benchmarks.
  </details>

- **[Interpreting Low-level Vision Models with Causal Effect Maps](http://arxiv.org/abs/2407.19789v3)**  `arXiv:2407.19789`  
  _Jinfan Hu, Jinjin Gu, Shiyao Yu, Fanghua Yu, Zheyuan Li, Zhiyuan You, et al._
  <details><summary>Abstract</summary>
  Deep neural networks have significantly improved the performance of low-levelvision tasks but also increased the difficulty of interpretability. A deepunderstanding of deep models is beneficial for both network design andpractical reliability. To take up this challenge, we introduce causality theoryto interpret low-level vision models and propose a model-/task-agnostic methodcalled Causal Effect Map (CEM). With CEM, we can visualize and quantify theinput-output relationships on either positive or negative effects. Afteranalyzing various low-level vision tasks with CEM, we have reached severalinteresting insights, such as: (1) Using more information of input images(e.g., larger receptive field) does NOT always yield positive outcomes. (2)Attempting to incorporate mechanisms with a global receptive field (e.g.,channel attention) into image denoising may prove futile. (3) Integratingmultiple tasks to train a general model could encourage the network toprioritize local information over global context. Based on the causal effecttheory, the proposed diagnostic tool can refresh our common knowledge and bringa deeper understanding of low-level vision models. Codes are available athttps://github.com/J-FHu/CEM.
  </details>

- **[A Double Deep Learning-based Solution for Efficient Event Data Coding and Classification](http://arxiv.org/abs/2407.15531v2)**  `arXiv:2407.15531`  
  _Abdelrahman Seleem, Andr√© F. R. Guarda, Nuno M. M. Rodrigues, Fernando Pereira_
  <details><summary>Abstract</summary>
  Event cameras have the ability to capture asynchronous per-pixel brightnesschanges, called "events", offering advantages over traditional frame-basedcameras for computer vision applications. Efficiently coding event data iscritical for transmission and storage, given the significant volume of events.This paper proposes a novel double deep learning-based architecture for bothevent data coding and classification, using a point cloud-based representationfor events. In this context, the conversions from events to point clouds andback to events are key steps in the proposed solution, and therefore its impactis evaluated in terms of compression and classification performance.Experimental results show that it is possible to achieve a classificationperformance of compressed events which is similar to one of the originalevents, even after applying a lossy point cloud codec, notably the recentlearning-based JPEG Pleno Point Cloud Coding standard, with a clear ratereduction. Experimental results also demonstrate that events coded using JPEGPCC achieve better classification performance than those coded using theconventional lossy MPEG Geometry-based Point Cloud Coding standard.Furthermore, the adoption of learning-based coding offers high potential forperforming computer vision tasks in the compressed domain, which allowsskipping the decoding stage while mitigating the impact of coding artifacts.
  </details>

- **[Gaussian Eigen Models for Human Heads](http://arxiv.org/abs/2407.04545v4)**  `arXiv:2407.04545`  
  _Wojciech Zielonka, Timo Bolkart, Thabo Beeler, Justus Thies_
  <details><summary>Abstract</summary>
  Current personalized neural head avatars face a trade-off: lightweight modelslack detail and realism, while high-quality, animatable avatars requiresignificant computational resources, making them unsuitable for commoditydevices. To address this gap, we introduce Gaussian Eigen Models (GEM), whichprovide high-quality, lightweight, and easily controllable head avatars. GEMutilizes 3D Gaussian primitives for representing the appearance combined withGaussian splatting for rendering. Building on the success of mesh-based 3Dmorphable face models (3DMM), we define GEM as an ensemble of linear eigenbasesfor representing the head appearance of a specific subject. In particular, weconstruct linear bases to represent the position, scale, rotation, and opacityof the 3D Gaussians. This allows us to efficiently generate Gaussian primitivesof a specific head shape by a linear combination of the basis vectors, onlyrequiring a low-dimensional parameter vector that contains the respectivecoefficients. We propose to construct these linear bases (GEM) by distillinghigh-quality compute-intense CNN-based Gaussian avatar models that can generateexpression-dependent appearance changes like wrinkles. These high-qualitymodels are trained on multi-view videos of a subject and are distilled using aseries of principal component analyses. Once we have obtained the bases thatrepresent the animatable appearance space of a specific human, we learn aregressor that takes a single RGB image as input and predicts thelow-dimensional parameter vector that corresponds to the shown facialexpression. In a series of experiments, we compare GEM's self-reenactment andcross-person reenactment results to state-of-the-art 3D avatar methods,demonstrating GEM's higher visual quality and better generalization to newexpressions.
  </details>

- **[Convolutional Kolmogorov-Arnold Networks](http://arxiv.org/abs/2406.13155v3)**  `arXiv:2406.13155`  
  _Alexander Dylan Bodner, Antonio Santiago Tepsich, Jack Natan Spolski, Santiago Pourteau_
  <details><summary>Abstract</summary>
  In this paper, we present Convolutional Kolmogorov-Arnold Networks, a novelarchitecture that integrates the learnable spline-based activation functions ofKolmogorov-Arnold Networks (KANs) into convolutional layers. By replacingtraditional fixed-weight kernels with learnable non-linear functions,Convolutional KANs offer a significant improvement in parameter efficiency andexpressive power over standard Convolutional Neural Networks (CNNs). Weempirically evaluate Convolutional KANs on the Fashion-MNIST dataset,demonstrating competitive accuracy with up to 50% fewer parameters compared tobaseline classic convolutions. This suggests that the KAN Convolution caneffectively capture complex spatial relationships with fewer resources,offering a promising alternative for parameter-efficient deep learning models.
  </details>

- **[Boost Your Human Image Generation Model via Direct Preference Optimization](http://arxiv.org/abs/2405.20216v2)**  `arXiv:2405.20216`  
  _Sanghyeon Na, Yonggyu Kim, Hyunjoon Lee_
  <details><summary>Abstract</summary>
  Human image generation is a key focus in image synthesis due to its broadapplications, but even slight inaccuracies in anatomy, pose, or details cancompromise realism. To address these challenges, we explore Direct PreferenceOptimization (DPO), which trains models to generate preferred (winning) imageswhile diverging from non-preferred (losing) ones. However, conventional DPOmethods use generated images as winning images, limiting realism. To overcomethis limitation, we propose an enhanced DPO approach that incorporateshigh-quality real images as winning images, encouraging outputs to resemblereal images rather than generated ones. However, implementing this concept isnot a trivial task. Therefore, our approach, HG-DPO (Human image Generationthrough DPO), employs a novel curriculum learning framework that graduallyimproves the output of the model toward greater realism, making training morefeasible. Furthermore, HG-DPO effectively adapts to personalized text-to-imagetasks, generating high-quality and identity-specific images, which highlightsthe practical value of our approach.
  </details>

- **[Bayesian Learning-driven Prototypical Contrastive Loss for Class-Incremental Learning](http://arxiv.org/abs/2405.11067v3)**  `arXiv:2405.11067`  
  _Nisha L. Raichur, Lucas Heublein, Tobias Feigl, Alexander R√ºgamer, Christopher Mutschler, Felix Ott_
  <details><summary>Abstract</summary>
  The primary objective of methods in continual learning is to learn tasks in asequential manner over time (sometimes from a stream of data), while mitigatingthe detrimental phenomenon of catastrophic forgetting. This paper proposes amethod to learn an effective representation between previous and newlyencountered class prototypes. We propose a prototypical network with a Bayesianlearning-driven contrastive loss (BLCL), tailored specifically forclass-incremental learning scenarios. We introduce a contrastive loss thatincorporates novel classes into the latent representation by reducingintra-class and increasing inter-class distance. Our approach dynamicallyadapts the balance between the cross-entropy and contrastive loss functionswith a Bayesian learning technique. Experimental results conducted on theCIFAR-10, CIFAR-100, and ImageNet100 datasets for image classification andimages of a GNSS-based dataset for interference classification validate theefficacy of our method, showcasing its superiority over existingstate-of-the-art approaches. Git:https://gitlab.cc-asp.fraunhofer.de/darcy_gnss/gnss_class_incremental_learning
  </details>

- **[MultiBooth: Towards Generating All Your Concepts in an Image from Text](http://arxiv.org/abs/2404.14239v3)**  `arXiv:2404.14239`  
  _Chenyang Zhu, Kai Li, Yue Ma, Chunming He, Xiu Li_
  <details><summary>Abstract</summary>
  This paper introduces MultiBooth, a novel and efficient technique formulti-concept customization in image generation from text. Despite thesignificant advancements in customized generation methods, particularly withthe success of diffusion models, existing methods often struggle withmulti-concept scenarios due to low concept fidelity and high inference cost.MultiBooth addresses these issues by dividing the multi-concept generationprocess into two phases: a single-concept learning phase and a multi-conceptintegration phase. During the single-concept learning phase, we employ amulti-modal image encoder and an efficient concept encoding technique to learna concise and discriminative representation for each concept. In themulti-concept integration phase, we use bounding boxes to define the generationarea for each concept within the cross-attention map. This method enables thecreation of individual concepts within their specified regions, therebyfacilitating the formation of multi-concept images. This strategy not onlyimproves concept fidelity but also reduces additional inference cost.MultiBooth surpasses various baselines in both qualitative and quantitativeevaluations, showcasing its superior performance and computational efficiency.Project Page: https://multibooth.github.io/
  </details>

- **[Gen3DSR: Generalizable 3D Scene Reconstruction via Divide and Conquer from a Single View](http://arxiv.org/abs/2404.03421v2)**  `arXiv:2404.03421`  
  _Andreea Ardelean, Mert √ñzer, Bernhard Egger_
  <details><summary>Abstract</summary>
  Single-view 3D reconstruction is currently approached from two dominantperspectives: reconstruction of scenes with limited diversity using 3D datasupervision or reconstruction of diverse singular objects using large imagepriors. However, real-world scenarios are far more complex and exceed thecapabilities of these methods. We therefore propose a hybrid method following adivide-and-conquer strategy. We first process the scene holistically,extracting depth and semantic information, and then leverage an object-levelmethod for the detailed reconstruction of individual components. By splittingthe problem into simpler tasks, our system is able to generalize to varioustypes of scenes without retraining or fine-tuning. We purposely design ourpipeline to be highly modular with independent, self-contained modules, toavoid the need for end-to-end training of the whole system. This enables thepipeline to naturally improve as future methods can replace the individualmodules. We demonstrate the reconstruction performance of our approach on bothsynthetic and real-world scenes, comparing favorable against prior works.Project page: https://andreeadogaru.github.io/Gen3DSR
  </details>

- **[RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS](http://arxiv.org/abs/2403.13806v2)**  `arXiv:2403.13806`  
  _Michael Niemeyer, Fabian Manhardt, Marie-Julie Rakotosaona, Michael Oechsle, Daniel Duckworth, Rama Gosula, et al._
  <details><summary>Abstract</summary>
  Recent advances in view synthesis and real-time rendering have achievedphotorealistic quality at impressive rendering speeds. While RadianceField-based methods achieve state-of-the-art quality in challenging scenariossuch as in-the-wild captures and large-scale scenes, they often suffer fromexcessively high compute requirements linked to volumetric rendering. GaussianSplatting-based methods, on the other hand, rely on rasterization and naturallyachieve real-time rendering but suffer from brittle optimization heuristicsthat underperform on more challenging scenes. In this work, we presentRadSplat, a lightweight method for robust real-time rendering of complexscenes. Our main contributions are threefold. First, we use radiance fields asa prior and supervision signal for optimizing point-based scenerepresentations, leading to improved quality and more robust optimization.Next, we develop a novel pruning technique reducing the overall point countwhile maintaining high quality, leading to smaller and more compact scenerepresentations with faster inference speeds. Finally, we propose a noveltest-time filtering approach that further accelerates rendering and allows toscale to larger, house-sized scenes. We find that our method enablesstate-of-the-art synthesis of complex captures at 900+ FPS.
  </details>

- **[Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures](http://arxiv.org/abs/2403.02308v3)**  `arXiv:2403.02308`  
  _Yuchen Duan, Weiyun Wang, Zhe Chen, Xizhou Zhu, Lewei Lu, Tong Lu, et al._
  <details><summary>Abstract</summary>
  Transformers have revolutionized computer vision and natural languageprocessing, but their high computational complexity limits their application inhigh-resolution image processing and long-context analysis. This paperintroduces Vision-RWKV (VRWKV), a model adapted from the RWKV model used in theNLP field with necessary modifications for vision tasks. Similar to the VisionTransformer (ViT), our model is designed to efficiently handle sparse inputsand demonstrate robust global processing capabilities, while also scaling upeffectively, accommodating both large-scale parameters and extensive datasets.Its distinctive advantage lies in its reduced spatial aggregation complexity,which renders it exceptionally adept at processing high-resolution imagesseamlessly, eliminating the necessity for windowing operations. Our evaluationsdemonstrate that VRWKV surpasses ViT's performance in image classification andhas significantly faster speeds and lower memory usage processinghigh-resolution inputs. In dense prediction tasks, it outperforms window-basedmodels, maintaining comparable speeds. These results highlight VRWKV'spotential as a more efficient alternative for visual perception tasks. Code isreleased at https://github.com/OpenGVLab/Vision-RWKV.
  </details>

- **[Adaptive Multi-step Refinement Network for Robust Point Cloud Registration](http://arxiv.org/abs/2312.03053v2)**  `arXiv:2312.03053`  
  _Zhi Chen, Yufan Ren, Tong Zhang, Zheng Dang, Wenbing Tao, Sabine S√ºsstrunk, et al._
  <details><summary>Abstract</summary>
  Point Cloud Registration (PCR) estimates the relative rigid transformationbetween two point clouds of the same scene. Despite significant progress withlearning-based approaches, existing methods still face challenges when theoverlapping region between the two point clouds is small. In this paper, wepropose an adaptive multi-step refinement network that refines the registrationquality at each step by leveraging the information from the preceding step. Toachieve this, we introduce a training procedure and a refinement network.Firstly, to adapt the network to the current step, we utilize a generalizedone-way attention mechanism, which prioritizes the last step's estimatedoverlapping region, and we condition the network on step indices. Secondly,instead of training the network to map either random transformations or a fixedpre-trained model's estimations to the ground truth, we train it ontransformations with varying registration qualities, ranging from accurate toinaccurate, thereby enhancing the network's adaptiveness and robustness.Despite its conceptual simplicity, our method achieves state-of-the-artperformance on both the 3DMatch/3DLoMatch and KITTI benchmarks. Notably, on3DLoMatch, our method reaches 80.4% recall rate, with an absolute improvementof 1.2%.
  </details>

- **[Enhancing Object Coherence in Layout-to-Image Synthesis](http://arxiv.org/abs/2311.10522v7)**  `arXiv:2311.10522`  
  _Yibin Wang, Changhai Zhou, Honghui Xu_
  <details><summary>Abstract</summary>
  Layout-to-image synthesis is an emerging technique in conditional imagegeneration. It aims to generate complex scenes, where users require finecontrol over the layout of the objects in a scene. However, it remainschallenging to control the object coherence, including semantic coherence(e.g., the cat looks at the flowers or not) and physical coherence (e.g., thehand and the racket should not be misaligned). In this paper, we propose anovel diffusion model with effective global semantic fusion (GSF) andself-similarity feature enhancement modules to guide the object coherence forthis task. For semantic coherence, we argue that the image caption containsrich information for defining the semantic relationship within the objects inthe images. Instead of simply employing cross-attention between captions andlatent images, which addresses the highly relevant layout restriction andsemantic coherence requirement separately and thus leads to unsatisfyingresults shown in our experiments, we develop GSF to fuse the supervision fromthe layout restriction and semantic coherence requirement and exploit it toguide the image synthesis process. Moreover, to improve the physical coherence,we develop a Self-similarity Coherence Attention (SCA) module to explicitlyintegrate local contextual physical coherence relation into each pixel'sgeneration process. Specifically, we adopt a self-similarity map to encode thephysical coherence restrictions and employ it to extract coherent features fromtext embedding. Through visualization of our self-similarity map, we explorethe essence of SCA, revealing that its effectiveness is not only in capturingreliable physical coherence patterns but also in enhancing complex texturegeneration. Extensive experiments demonstrate the superiority of our proposedmethod.
  </details>

- **[TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic Token Mixer for Visual Recognition](http://arxiv.org/abs/2310.19380v4)**  `arXiv:2310.19380`  
  _Meng Lou, Shu Zhang, Hong-Yu Zhou, Sibei Yang, Chuan Wu, Yizhou Yu_
  <details><summary>Abstract</summary>
  Recent studies have integrated convolutions into transformers to introduceinductive bias and improve generalization performance. However, the staticnature of conventional convolution prevents it from dynamically adapting toinput variations, resulting in a representation discrepancy between convolutionand self-attention as the latter computes attention maps dynamically.Furthermore, when stacking token mixers that consist of convolution andself-attention to form a deep network, the static nature of convolution hindersthe fusion of features previously generated by self-attention into convolutionkernels. These two limitations result in a sub-optimal representation capacityof the entire network. To find a solution, we propose a lightweight DualDynamic Token Mixer (D-Mixer) to simultaneously learn global and local dynamicsvia computing input-dependent global and local aggregation weights. D-Mixerworks by applying an efficient global attention module and an input-dependentdepthwise convolution separately on evenly split feature segments, endowing thenetwork with strong inductive bias and an enlarged receptive field. We useD-Mixer as the basic building block to design TransXNet, a novel hybridCNN-Transformer vision backbone network that delivers compelling performance.In the ImageNet-1K classification, TransXNet-T surpasses Swin-T by 0.3% intop-1 accuracy while requiring less than half of the computational cost.Furthermore, TransXNet-S and TransXNet-B exhibit excellent model scalability,achieving top-1 accuracy of 83.8% and 84.6% respectively, with reasonablecomputational costs. Additionally, our proposed network architecturedemonstrates strong generalization capabilities in various dense predictiontasks, outperforming other state-of-the-art networks while having lowercomputational costs. Code is publicly available athttps://github.com/LMMMEng/TransXNet.
  </details>

[‚Üë Back to Top](#-full-archive)

</details>

### Machine Learning üìä

<details open><summary>Click to Collapse</summary>

- **[Effectively Controlling Reasoning Models through Thinking Intervention](http://arxiv.org/abs/2503.24370v1)**  `arXiv:2503.24370`  
  _Tong Wu, Chong Xiang, Jiachen T. Wang, Prateek Mittal_
  <details><summary>Abstract</summary>
  Reasoning-enhanced large language models (LLMs) explicitly generateintermediate reasoning steps prior to generating final answers, helping themodel excel in complex problem-solving. In this paper, we demonstrate that thisemerging generation framework offers a unique opportunity for more fine-grainedcontrol over model behavior. We propose Thinking Intervention, a novel paradigmdesigned to explicitly guide the internal reasoning processes of LLMs bystrategically inserting or revising specific thinking tokens. We conductcomprehensive evaluations across multiple tasks, including instructionfollowing on IFEval, instruction hierarchy on SEP, and safety alignment onXSTest and SORRY-Bench. Our results demonstrate that Thinking Interventionsignificantly outperforms baseline prompting approaches, achieving up to 6.7%accuracy gains in instruction-following scenarios, 15.4% improvements inreasoning about instruction hierarchies, and a 40.0% increase in refusal ratesfor unsafe prompts using open-source DeepSeek R1 models. Overall, our workopens a promising new research avenue for controlling reasoning LLMs.
  </details>

- **[Which LIME should I trust? Concepts, Challenges, and Solutions](http://arxiv.org/abs/2503.24365v1)**  `arXiv:2503.24365`  
  _Patrick Knab, Sascha Marton, Udo Schlegel, Christian Bartelt_
  <details><summary>Abstract</summary>
  As neural networks become dominant in essential systems, ExplainableArtificial Intelligence (XAI) plays a crucial role in fostering trust anddetecting potential misbehavior of opaque models. LIME (Local InterpretableModel-agnostic Explanations) is among the most prominent model-agnosticapproaches, generating explanations by approximating the behavior of black-boxmodels around specific instances. Despite its popularity, LIME faces challengesrelated to fidelity, stability, and applicability to domain-specific problems.Numerous adaptations and enhancements have been proposed to address theseissues, but the growing number of developments can be overwhelming,complicating efforts to navigate LIME-related research. To the best of ourknowledge, this is the first survey to comprehensively explore and collectLIME's foundational concepts and known limitations. We categorize and compareits various enhancements, offering a structured taxonomy based on intermediatesteps and key issues. Our analysis provides a holistic overview of advancementsin LIME, guiding future research and helping practitioners identify suitableapproaches. Additionally, we provide a continuously updated interactive website(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise andaccessible overview of the survey.
  </details>

- **[SQuat: Subspace-orthogonal KV Cache Quantization](http://arxiv.org/abs/2503.24358v1)**  `arXiv:2503.24358`  
  _Hao Wang, Ligong Han, Kai Xu, Akash Srivastava_
  <details><summary>Abstract</summary>
  The key-value (KV) cache accelerates LLMs decoding by storing KV tensors frompreviously generated tokens. It reduces redundant computation at the cost ofincreased memory usage. To mitigate this overhead, existing approaches compressKV tensors into lower-bit representations; however, quantization errors canaccumulate as more tokens are generated, potentially resulting in undesiredoutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cachequantization). It first constructs a subspace spanned by query tensors tocapture the most critical task-related information. During key tensorquantization, it enforces that the difference between the (de)quantized andoriginal keys remains orthogonal to this subspace, minimizing the impact ofquantization errors on the attention mechanism's outputs. SQuat requires nomodel fine-tuning, no additional calibration dataset for offline learning, andis grounded in a theoretical framework we develop. Through numericalexperiments, we show that our method reduces peak memory by 2.17 to 2.82,improves throughput by 2.45 to 3.60, and achieves more favorable benchmarkscores than existing KV cache quantization algorithms.
  </details>

- **[ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion](http://arxiv.org/abs/2503.24354v1)**  `arXiv:2503.24354`  
  _Rana Muhammad Shahroz Khan, Dongwen Tang, Pingzhi Li, Kai Wang, Tianlong Chen_
  <details><summary>Abstract</summary>
  Parameter generation has emerged as a novel paradigm for neural networkdevelopment, offering an alternative to traditional neural network training bysynthesizing high-quality model weights directly. In the context of Low-RankAdaptation (LoRA) for evolving ($\textit{i.e.}$, constantly updated) largelanguage models (LLMs), this approach promises efficient adaptation withoutcostly retraining. However, existing methods face critical limitations insimultaneously achieving scalability and controllability. In this paper, weintroduce $\texttt{ORAL}$, a novel $\textbf{conditional recurrent diffusion}$framework that addresses these challenges. $\texttt{ORAL}$ incorporates a novelconditioning mechanism that integrates model architecture and textual taskspecifications, enabling the generation of task-specific LoRA parameters thatcan seamlessly transfer across evolving foundation models. Our approachsuccessfully scales to billions-of-parameter LLMs and maintainscontrollability. Through extensive experiments across seven language tasks,four vision tasks, and three multimodal tasks using five pre-trained LLMs, wedemonstrate that $\texttt{ORAL}$ generates high-quality LoRA parameters thatachieve comparable or superior performance to vanilla trained counterparts.
  </details>

- **[NoProp: Training Neural Networks without Back-propagation or Forward-propagation](http://arxiv.org/abs/2503.24322v1)**  `arXiv:2503.24322`  
  _Qinyu Li, Yee Whye Teh, Razvan Pascanu_
  <details><summary>Abstract</summary>
  The canonical deep learning approach for learning requires computing agradient term at each layer by back-propagating the error signal from theoutput towards each learnable parameter. Given the stacked structure of neuralnetworks, where each layer builds on the representation of the layer below,this approach leads to hierarchical representations. More abstract featureslive on the top layers of the model, while features on lower layers areexpected to be less abstract. In contrast to this, we introduce a new learningmethod named NoProp, which does not rely on either forward or backwardspropagation. Instead, NoProp takes inspiration from diffusion and flow matchingmethods, where each layer independently learns to denoise a noisy target. Webelieve this work takes a first step towards introducing a new family ofgradient-free learning methods, that does not learn hierarchicalrepresentations -- at least not in the usual sense. NoProp needs to fix therepresentation at each layer beforehand to a noised version of the target,learning a local denoising process that can then be exploited at inference. Wedemonstrate the effectiveness of our method on MNIST, CIFAR-10, and CIFAR-100image classification benchmarks. Our results show that NoProp is a viablelearning algorithm which achieves superior accuracy, is easier to use andcomputationally more efficient compared to other existing back-propagation-freemethods. By departing from the traditional gradient based learning paradigm,NoProp alters how credit assignment is done within the network, enabling moreefficient distributed learning as well as potentially impacting othercharacteristics of the learning process.
  </details>

- **[Evaluating machine learning models for predicting pesticides toxicity to honey bees](http://arxiv.org/abs/2503.24305v1)**  `arXiv:2503.24305`  
  _Jakub Adamczyk, Jakub Poziemski, Pawel Siedlecki_
  <details><summary>Abstract</summary>
  Small molecules play a critical role in the biomedical, environmental, andagrochemical domains, each with distinct physicochemical requirements andsuccess criteria. Although biomedical research benefits from extensive datasetsand established benchmarks, agrochemical data remain scarce, particularly withrespect to species-specific toxicity. This work focuses on ApisTox, the mostcomprehensive dataset of experimentally validated chemical toxicity to thehoney bee (\textit{Apis mellifera}), an ecologically vital pollinator. Weevaluate ApisTox using a diverse suite of machine learning approaches,including molecular fingerprints, graph kernels, and graph neural networks, aswell as pretrained models. Comparative analysis with medicinal datasets fromthe MoleculeNet benchmark reveals that ApisTox represents a distinct chemicalspace. Performance degradation on non-medicinal datasets, such as ApisTox,demonstrates their limited generalizability of current state-of-the-artalgorithms trained solely on biomedical data. Our study highlights the need formore diverse datasets and for targeted model development geared toward theagrochemical domain.
  </details>

- **[Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model](http://arxiv.org/abs/2503.24290v1)**  `arXiv:2503.24290`  
  _Jingcheng Hu, Yinmin Zhang, Qi Han, Daxin Jiang, Xiangyu Zhang, Heung-Yeung Shum_
  <details><summary>Abstract</summary>
  We introduce Open-Reasoner-Zero, the first open source implementation oflarge-scale reasoning-oriented RL training focusing on scalability, simplicityand accessibility. Through extensive experiments, we demonstrate that aminimalist approach, vanilla PPO with GAE ($\lambda=1$, $\gamma=1$) andstraightforward rule-based rewards, without any KL regularization, issufficient to scale up both response length and benchmark performance, similarto the phenomenon observed in DeepSeek-R1-Zero. Using the same base model asDeepSeek-R1-Zero-Qwen-32B, our implementation achieves superior performance onAIME2024, MATH500, and the GPQA Diamond benchmark while demonstratingremarkable efficiency -- requiring only a tenth of the training steps, comparedto DeepSeek-R1-Zero pipeline. In the spirit of open source, we release oursource code, parameter settings, training data, and model weights acrossvarious sizes.
  </details>

- **[Value of Information-based Deceptive Path Planning Under Adversarial Interventions](http://arxiv.org/abs/2503.24284v1)**  `arXiv:2503.24284`  
  _Wesley A. Suttle, Jesse Milzman, Mustafa O. Karabag, Brian M. Sadler, Ufuk Topcu_
  <details><summary>Abstract</summary>
  Existing methods for deceptive path planning (DPP) address the problem ofdesigning paths that conceal their true goal from a passive, external observer.Such methods do not apply to problems where the observer has the ability toperform adversarial interventions to impede the path planning agent. In thispaper, we propose a novel Markov decision process (MDP)-based model for the DPPproblem under adversarial interventions and develop new value of information(VoI) objectives to guide the design of DPP policies. Using the VoI objectiveswe propose, path planning agents deceive the adversarial observer into choosingsuboptimal interventions by selecting trajectories that are of lowinformational value to the observer. Leveraging connections to the linearprogramming theory for MDPs, we derive computationally efficient solutionmethods for synthesizing policies for performing DPP under adversarialinterventions. In our experiments, we illustrate the effectiveness of theproposed solution method in achieving deceptiveness under adversarialinterventions and demonstrate the superior performance of our approach to bothexisting DPP methods and conservative path planning approaches on illustrativegridworld problems.
  </details>

- **[Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality](http://arxiv.org/abs/2503.24277v1)**  `arXiv:2503.24277`  
  _Sewoong Lee, Adam Davies, Marc E. Canby, Julia Hockenmaier_
  <details><summary>Abstract</summary>
  Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanisticinterpretability, but leading SAE approaches with top-$k$ style activationfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEsare based on the linear representation hypothesis (LRH), which assumes that therepresentations of large language models (LLMs) are linearly encoded, and thesuperposition hypothesis (SH), which states that there can be more features inthe model than its dimensionality. We show that, based on the formaldefinitions of the LRH and SH, the magnitude of sparse feature vectors (thelatent representations learned by SAEs of the dense embeddings of LLMs) can beapproximated using their corresponding dense vector with a closed-form errorbound. To visualize this, we propose the ZF plot, which reveals a previouslyunknown relationship between LLM hidden embeddings and SAE feature vectors,allowing us to make the first empirical measurement of the extent to whichfeature vectors of pre-trained SAEs are over- or under-activated for a giveninput. Correspondingly, we introduce Approximate Feature Activation (AFA),which approximates the magnitude of the ground-truth sparse feature vector, andpropose a new evaluation metric derived from AFA to assess the alignmentbetween inputs and activations. We also leverage AFA to introduce a novel SAEarchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line withtheoretical justifications; and (b) obviate the need to tune SAE sparsityhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achievereconstruction loss comparable to that of state-of-the-art top-k SAEs, withoutrequiring the hyperparameter $k$ to be tuned. Our code is available at:https://github.com/SewoongLee/top-afa-sae.
  </details>

- **[New Statistical Framework for Extreme Error Probability in High-Stakes Domains for Reliable Machine Learning](http://arxiv.org/abs/2503.24262v1)**  `arXiv:2503.24262`  
  _Umberto Michelucci, Francesca Venturini_
  <details><summary>Abstract</summary>
  Machine learning is vital in high-stakes domains, yet conventional validationmethods rely on averaging metrics like mean squared error (MSE) or meanabsolute error (MAE), which fail to quantify extreme errors. Worst-caseprediction failures can have substantial consequences, but current frameworkslack statistical foundations for assessing their probability. In this work anew statistical framework, based on Extreme Value Theory (EVT), is presentedthat provides a rigorous approach to estimating worst-case failures. ApplyingEVT to synthetic and real-world datasets, this method is shown to enable robustestimation of catastrophic failure probabilities, overcoming the fundamentallimitations of standard cross-validation. This work establishes EVT as afundamental tool for assessing model reliability, ensuring safer AI deploymentin new technologies where uncertainty quantification is central todecision-making or scientific analysis.
  </details>

- **[Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review](http://arxiv.org/abs/2503.24259v1)**  `arXiv:2503.24259`  
  _Bruno Deprez, Wei Wei, Wouter Verbeke, Bart Baesens, Kevin Mets, Tim Verdonck_
  <details><summary>Abstract</summary>
  Financial institutions are required by regulation to report suspiciousfinancial transactions related to money laundering. Therefore, they need toconstantly monitor vast amounts of incoming and outgoing transactions. Aparticular challenge in detecting money laundering is that money laundererscontinuously adapt their tactics to evade detection. Hence, detection methodsneed constant fine-tuning. Traditional machine learning models suffer fromcatastrophic forgetting when fine-tuning the model on new data, therebylimiting their effectiveness in dynamic environments. Continual learningmethods may address this issue and enhance current anti-money laundering (AML)practices, by allowing models to incorporate new information while retainingprior knowledge. Research on continual graph learning for AML, however, isstill scarce. In this review, we critically evaluate state-of-the-art continualgraph learning approaches for AML applications. We categorise methods intoreplay-based, regularization-based, and architecture-based strategies withinthe graph neural network (GNN) framework, and we provide in-depth experimentalevaluations on both synthetic and real-world AML data sets that showcase theeffect of the different hyperparameters. Our analysis demonstrates thatcontinual learning improves model adaptability and robustness in the face ofextreme class imbalances and evolving fraud patterns. Finally, we outline keychallenges and propose directions for future research.
  </details>

- **[Spatio-temporal Prediction of Fine-Grained Origin-Destination Matrices with Applications in Ridesharing](http://arxiv.org/abs/2503.24237v1)**  `arXiv:2503.24237`  
  _Run Yang, Runpeng Dai, Siran Gao, Xiaocheng Tang, Fan Zhou, Hongtu Zhu_
  <details><summary>Abstract</summary>
  Accurate spatial-temporal prediction of network-based travelers' requests iscrucial for the effective policy design of ridesharing platforms. Havingknowledge of the total demand between various locations in the upcoming timeslots enables platforms to proactively prepare adequate supplies, therebyincreasing the likelihood of fulfilling travelers' requests and redistributingidle drivers to areas with high potential demand to optimize the globalsupply-demand equilibrium. This paper delves into the prediction ofOrigin-Destination (OD) demands at a fine-grained spatial level, especiallywhen confronted with an expansive set of local regions. While this task holdsimmense practical value, it remains relatively unexplored within the researchcommunity. To fill this gap, we introduce a novel prediction model calledOD-CED, which comprises an unsupervised space coarsening technique to alleviatedata sparsity and an encoder-decoder architecture to capture both semantic andgeographic dependencies. Through practical experimentation, OD-CED hasdemonstrated remarkable results. It achieved an impressive reduction of up to45% reduction in root-mean-square error and 60% in weighted mean absolutepercentage error over traditional statistical methods when dealing with ODmatrices exhibiting a sparsity exceeding 90%.
  </details>

- **[Many-to-Many Matching via Sparsity Controlled Optimal Transport](http://arxiv.org/abs/2503.24204v1)**  `arXiv:2503.24204`  
  _Weijie Liu, Han Bao, Makoto Yamada, Zenan Huang, Nenggan Zheng, Hui Qian_
  <details><summary>Abstract</summary>
  Many-to-many matching seeks to match multiple points in one set and multiplepoints in another set, which is a basis for a wide range of data miningproblems. It can be naturally recast in the framework of Optimal Transport(OT). However, existing OT methods either lack the ability to accomplishmany-to-many matching or necessitate careful tuning of a regularizationparameter to achieve satisfactory results. This paper proposes a novelmany-to-many matching method to explicitly encode many-to-many constraintswhile preventing the degeneration into one-to-one matching. The proposed methodconsists of the following two components. The first component is the matchingbudget constraints on each row and column of a transport plan, which specifyhow many points can be matched to a point at most. The second component is thedeformed $q$-entropy regularization, which encourages a point to meet thematching budget maximally. While the deformed $q$-entropy was initiallyproposed to sparsify a transport plan, we employ it to avoid the degenerationinto one-to-one matching. We optimize the objective via a penalty algorithm,which is efficient and theoretically guaranteed to converge. Experimentalresults on various tasks demonstrate that the proposed method achieves goodperformance by gleaning meaningful many-to-many matchings.
  </details>

- **[NeuRaLaTeX: A machine learning library written in pure LaTeX](http://arxiv.org/abs/2503.24187v1)**  `arXiv:2503.24187`  
  _James A. D. Gardner, Will Rowan, William A. P. Smith_
  <details><summary>Abstract</summary>
  In this paper, we introduce NeuRaLaTeX, which we believe to be the first deeplearning library written entirely in LaTeX. As part of your LaTeX document youcan specify the architecture of a neural network and its loss functions, definehow to generate or load training data, and specify training hyperparameters andexperiments. When the document is compiled, the LaTeX compiler will generate orload training data, train the network, run experiments, and generate figures.This paper generates a random 100 point spiral dataset, trains a two layer MLPon it, evaluates on a different random spiral dataset, produces plots andtables of results. The paper took 48 hours to compile and the entire sourcecode for NeuRaLaTeX is contained within the source code of the paper. Wepropose two new metrics: the Written In Latex (WIL) metric measures theproportion of a machine learning library that is written in pure LaTeX, whilethe Source Code Of Method in Source Code of Paper (SCOMISCOP) metric measuresthe proportion of a paper's implementation that is contained within the papersource. We are state-of-the-art for both metrics, outperforming the ResNet andTransformer papers, as well as the PyTorch and Tensorflow libraries. Sourcecode, documentation, videos, crypto scams and an invitation to invest in thecommercialisation of NeuRaLaTeX are available at https://www.neuralatex.com
  </details>

- **[Ride-Sourcing Vehicle Rebalancing with Service Accessibility Guarantees via Constrained Mean-Field Reinforcement Learning](http://arxiv.org/abs/2503.24183v1)**  `arXiv:2503.24183`  
  _Matej Jusup, Kenan Zhang, Zhiyuan Hu, Barna P√°sztor, Andreas Krause, Francesco Corman_
  <details><summary>Abstract</summary>
  The rapid expansion of ride-sourcing services such as Uber, Lyft, and DidiChuxing has fundamentally reshaped urban transportation by offering flexible,on-demand mobility via mobile applications. Despite their convenience, theseplatforms confront significant operational challenges, particularly vehiclerebalancing - the strategic repositioning of thousands of vehicles to addressspatiotemporal mismatches in supply and demand. Inadequate rebalancing resultsin prolonged rider waiting times, inefficient vehicle utilization, andinequitable distribution of services, leading to disparities in driveravailability and income.  To tackle these complexities, we introduce scalable continuous-statemean-field control (MFC) and reinforcement learning (MFRL) models thatexplicitly represent each vehicle's precise location and employ continuousrepositioning actions guided by the distribution of other vehicles. To ensureequitable service distribution, an accessibility constraint is integratedwithin our optimal control formulation, balancing operational efficiency withequitable access to the service across geographic regions. Our approachacknowledges realistic conditions, including inherent stochasticity intransitions, the simultaneous occurrence of vehicle-rider matching, vehicles'rebalancing and cruising, and variability in rider behaviors. Crucially, werelax the traditional mean-field assumption of equal supply-demand volume,better reflecting practical scenarios. Extensive empirical evaluation usingreal-world data-driven simulation of Shenzhen demonstrates the real-timeefficiency and robustness of our approach at the scale of tens of thousands ofvehicles.  The code is available athttps://github.com/mjusup1501/mf-vehicle-rebalancing.
  </details>

- **[Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer Using Multimodal Machine Learning](http://arxiv.org/abs/2503.24165v1)**  `arXiv:2503.24165`  
  _Peiying Hua, Andrea Olofson, Faraz Farhadi, Liesbeth Hondelink, Gregory Tsongalis, Konstantin Dragnev, et al._
  <details><summary>Abstract</summary>
  Lung cancer is the primary cause of cancer death globally, with non-smallcell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLCpatients, approximately 32.3% have mutations in the epidermal growth factorreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinaseinhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLCpatients with activating and T790M resistance EGFR mutations. Despite itsestablished efficacy, drug resistance poses a significant challenge forpatients to fully benefit from osimertinib. The absence of a standard tool toaccurately predict TKI resistance, including that of osimertinib, remains acritical obstacle. To bridge this gap, in this study, we developed aninterpretable multimodal machine learning model designed to predict patientresistance to osimertinib among late-stage NSCLC patients with activating EGFRmutations, achieving a c-index of 0.82 on a multi-institutional dataset. Thismachine learning model harnesses readily available data routinely collectedduring patient visits and medical assessments to facilitate precision lungcancer management and informed treatment decisions. By integrating various datatypes such as histology images, next generation sequencing (NGS) data,demographics data, and clinical records, our multimodal model can generatewell-informed recommendations. Our experiment results also demonstrated thesuperior performance of the multimodal model over single modality models(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit ofcombining multiple modalities in patient outcome prediction.
  </details>

- **[LLM4FS: Leveraging Large Language Models for Feature Selection and How to Improve It](http://arxiv.org/abs/2503.24157v1)**  `arXiv:2503.24157`  
  _Jianhao Li, Xianchao Xiu_
  <details><summary>Abstract</summary>
  Recent advances in large language models (LLMs) have provided newopportunities for decision-making, particularly in the task of automatedfeature selection. In this paper, we first comprehensively evaluate LLM-basedfeature selection methods, covering the state-of-the-art DeepSeek-R1,GPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy calledLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,input data samples into LLMs, and directly call traditional data-driventechniques such as random forest and forward sequential selection. Notably, ouranalysis reveals that the hybrid strategy leverages the contextualunderstanding of LLMs and the high statistical reliability of traditionaldata-driven methods to achieve excellent feature selection performance, evensurpassing LLMs and traditional data-driven methods. Finally, we point out thelimitations of its application in decision-making.
  </details>

- **[Learning a Canonical Basis of Human Preferences from Binary Ratings](http://arxiv.org/abs/2503.24150v1)**  `arXiv:2503.24150`  
  _Kailas Vodrahalli, Wei Wei, James Zou_
  <details><summary>Abstract</summary>
  Recent advances in generative AI have been driven by alignment techniquessuch as reinforcement learning from human feedback (RLHF). RLHF and relatedtechniques typically involve constructing a dataset of binary or ranked choicehuman preferences and subsequently fine-tuning models to align with thesepreferences. This paper shifts the focus to understanding the preferencesencoded in such datasets and identifying common human preferences. We find thata small subset of 21 preference categories (selected from a set of nearly 5,000distinct preferences) captures >89% of preference variation across individuals.This small set of preferences is analogous to a canonical basis of humanpreferences, similar to established findings that characterize human variationin psychology or facial recognition studies. Through both synthetic andempirical evaluations, we confirm that our low-rank, canonical set of humanpreferences generalizes across the entire dataset and within specific topics.We further demonstrate our preference basis' utility in model evaluation, whereour preference categories offer deeper insights into model alignment, and inmodel training, where we show that fine-tuning on preference-defined subsetssuccessfully aligns the model accordingly.
  </details>

- **[Reinforcement Learning for Safe Autonomous Two Device Navigation of Cerebral Vessels in Mechanical Thrombectomy](http://arxiv.org/abs/2503.24140v1)**  `arXiv:2503.24140`  
  _Harry Robertshaw, Benjamin Jackson, Jiaheng Wang, Hadi Sadati, Lennart Karstensen, Alejandro Granados, et al._
  <details><summary>Abstract</summary>
  Purpose: Autonomous systems in mechanical thrombectomy (MT) hold promise forreducing procedure times, minimizing radiation exposure, and enhancing patientsafety. However, current reinforcement learning (RL) methods only reach thecarotid arteries, are not generalizable to other patient vasculatures, and donot consider safety. We propose a safe dual-device RL algorithm that cannavigate beyond the carotid arteries to cerebral vessels.  Methods: We used the Simulation Open Framework Architecture to represent theintricacies of cerebral vessels, and a modified Soft Actor-Critic RL algorithmto learn, for the first time, the navigation of micro-catheters andmicro-guidewires. We incorporate patient safety metrics into our rewardfunction by integrating guidewire tip forces. Inverse RL is used withdemonstrator data on 12 patient-specific vascular cases.  Results: Our simulation demonstrates successful autonomous navigation withinunseen cerebral vessels, achieving a 96% success rate, 7.0s procedure time, and0.24 N mean forces, well below the proposed 1.5 N vessel rupture threshold.  Conclusion: To the best of our knowledge, our proposed autonomous system forMT two-device navigation reaches cerebral vessels, considers safety, and isgeneralizable to unseen patient-specific cases for the first time. We envisagefuture work will extend the validation to vasculatures of different complexityand on in vitro models. While our contributions pave the way towards deployingagents in clinical settings, safety and trustworthiness will be crucialelements to consider when proposing new methodology.
  </details>

- **[CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning](http://arxiv.org/abs/2503.24123v1)**  `arXiv:2503.24123`  
  _Seewon Choi, Alaia Solko-Breslin, Rajeev Alur, Eric Wong_
  <details><summary>Abstract</summary>
  Many computational tasks benefit from being formulated as the composition ofneural networks followed by a discrete symbolic program. The goal ofneurosymbolic learning is to train the neural networks using only end-to-endinput-output labels of the composite. We introduce CTSketch, a novel, scalableneurosymbolic learning algorithm. CTSketch uses two techniques to improve thescalability of neurosymbolic inference: decompose the symbolic program intosub-programs and summarize each sub-program with a sketched tensor. Thisstrategy allows us to approximate the output distribution of the program withsimple tensor operations over the input distributions and summaries. We providetheoretical insight into the maximum error of the approximation. Furthermore,we evaluate CTSketch on many benchmarks from the neurosymbolic literature,including some designed for evaluating scalability. Our results show thatCTSketch pushes neurosymbolic learning to new scales that have previously beenunattainable by obtaining high accuracy on tasks involving over one thousandinputs.
  </details>

- **[Level the Level: Balancing Game Levels for Asymmetric Player Archetypes With Reinforcement Learning](http://arxiv.org/abs/2503.24099v1)**  `arXiv:2503.24099`  
  _Florian Rupp, Kai Eckert_
  <details><summary>Abstract</summary>
  Balancing games, especially those with asymmetric multiplayer content,requires significant manual effort and extensive human playtesting duringdevelopment. For this reason, this work focuses on generating balanced levelstailored to asymmetric player archetypes, where the disparity in abilities isbalanced entirely through the level design. For instance, while one archetypemay have an advantage over another, both should have an equal chance ofwinning. We therefore conceptualize game balancing as a procedural contentgeneration problem and build on and extend a recently introduced method thatuses reinforcement learning to balance tile-based game levels. We evaluate themethod on four different player archetypes and demonstrate its ability tobalance a larger proportion of levels compared to two baseline approaches.Furthermore, our results indicate that as the disparity between playerarchetypes increases, the required number of training steps grows, while themodel's accuracy in achieving balance decreases.
  </details>

- **[TransMamba: Flexibly Switching between Transformer and Mamba](http://arxiv.org/abs/2503.24067v1)**  `arXiv:2503.24067`  
  _Yixing Li, Ruobing Xie, Zhen Yang, Xingwu Sun, Shuaipeng Li, Weidong Han, et al._
  <details><summary>Abstract</summary>
  Transformers are the cornerstone of modern large language models, but theirquadratic computational complexity limits efficiency in long-sequenceprocessing. Recent advancements in Mamba, a state space model (SSM) with linearcomplexity, offer promising efficiency gains but suffer from unstablecontextual learning and multitask generalization. This paper proposesTransMamba, a novel framework that unifies Transformer and Mamba through sharedparameter matrices (e.g., QKV and CBx), and thus could dynamically switchbetween attention and SSM mechanisms at different token lengths and layers. Wedesign the Memory converter to bridge Transformer and Mamba by convertingattention outputs into SSM-compatible states, ensuring seamless informationflow at TransPoints where the transformation happens. The TransPoint schedulingis also thoroughly explored for further improvements. We conducted extensiveexperiments demonstrating that TransMamba achieves superior training efficiencyand performance compared to baselines, and validated the deeper consistencybetween Transformer and Mamba paradigms, offering a scalable solution fornext-generation sequence modeling.
  </details>

- **[Accelerated Airfoil Design Using Neural Network Approaches](http://arxiv.org/abs/2503.24052v1)**  `arXiv:2503.24052`  
  _Anantram Patel, Nikhil Mogre, Mandar Mane, Jayavardhan Reddy Enumula, Vijay Kumar Sutrakar_
  <details><summary>Abstract</summary>
  In this paper, prediction of airfoil shape from targeted pressuredistribution (suction and pressure sides) and vice versa is demonstrated usingboth Convolutional Neural Networks (CNNs) and Deep Neural Networks (DNNs)techniques. The dataset is generated for 1600 airfoil shapes, with simulationscarried out at Reynolds numbers (Re) ranging from 10,000 and 90,00,000 andangles of attack (AoA) ranging from 0 to 15 degrees, ensuring the datasetcaptured diverse aerodynamic conditions. Five different CNN and DNN models aredeveloped depending on the input/output parameters. Results demonstrate thatthe refined models exhibit improved efficiency, with the DNN model achieving amulti-fold reduction in training time compared to the CNN model for complexdatasets consisting of varying airfoil, Re, and AoA. The predicted airfoilshapes/pressure distribution closely match the targeted values, validating theeffectiveness of deep learning frameworks. However, the performance of CNNmodels is found to be better compared to DNN models. Lastly, a flying wingaircraft model of wingspan >10 m is considered for the prediction of pressuredistribution along the chordwise. The proposed CNN and DNN models showpromising results. This research underscores the potential of deep learningmodels accelerating aerodynamic optimization and advancing the design ofhigh-performance airfoils.
  </details>

- **[Frequency-Aware Attention-LSTM for PM$_{2.5}$ Time Series Forecasting](http://arxiv.org/abs/2503.24043v1)**  `arXiv:2503.24043`  
  _Jiahui LU, Shuang Wu, Zhenkai Qin, Dongze Wu, Guifang Yang_
  <details><summary>Abstract</summary>
  To enhance the accuracy and robustness of PM$_{2.5}$ concentrationforecasting, this paper introduces FALNet, a Frequency-Aware LSTM Network thatintegrates frequency-domain decomposition, temporal modeling, andattention-based refinement. The model first applies STL and FFT to extracttrend, seasonal, and denoised residual components, effectively filtering outhigh-frequency noise. The filtered residuals are then fed into a stacked LSTMto capture long-term dependencies, followed by a multi-head attention mechanismthat dynamically focuses on key time steps. Experiments conducted on real-worldurban air quality datasets demonstrate that FALNet consistently outperformsconventional models across standard metrics such as MAE, RMSE, and $R^2$. Themodel shows strong adaptability in capturing sharp fluctuations duringpollution peaks and non-stationary conditions. These results validate theeffectiveness and generalizability of FALNet for real-time air pollutionprediction, environmental risk assessment, and decision-making support.
  </details>

- **[Bayesian Predictive Coding](http://arxiv.org/abs/2503.24016v1)**  `arXiv:2503.24016`  
  _Alexander Tschantz, Magnus Koudahl, Hampus Linander, Lancelot Da Costa, Conor Heins, Jeff Beck, et al._
  <details><summary>Abstract</summary>
  Predictive coding (PC) is an influential theory of information processing inthe brain, providing a biologically plausible alternative to backpropagation.It is motivated in terms of Bayesian inference, as hidden states and parametersare optimised via gradient descent on variational free energy. However,implementations of PC rely on maximum \textit{a posteriori} (MAP) estimates ofhidden states and maximum likelihood (ML) estimates of parameters, limitingtheir ability to quantify epistemic uncertainty. In this work, we investigate aBayesian extension to PC that estimates a posterior distribution over networkparameters. This approach, termed Bayesian Predictive coding (BPC), preservesthe locality of PC and results in closed-form Hebbian weight updates. Comparedto PC, our BPC algorithm converges in fewer epochs in the full-batch settingand remains competitive in the mini-batch setting. Additionally, we demonstratethat BPC offers uncertainty quantification comparable to existing methods inBayesian deep learning, while also improving convergence properties. Together,these results suggest that BPC provides a biologically plausible method forBayesian learning in the brain, as well as an attractive approach touncertainty quantification in deep learning.
  </details>

- **[Tree-Guided $L_1$-Convex Clustering](http://arxiv.org/abs/2503.24012v1)**  `arXiv:2503.24012`  
  _Bingyuan Zhang, Yoshikazu Terada_
  <details><summary>Abstract</summary>
  Convex clustering is a modern clustering framework that guarantees globallyoptimal solutions and performs comparably to other advanced clustering methods.However, obtaining a complete dendrogram (clusterpath) for large-scale datasetsremains computationally challenging due to the extensive costs associated withiterative optimization approaches. To address this limitation, we develop anovel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering(TGCC). We first focus on the fact that the loss function of $L_1$-convexclustering with tree-structured weights can be efficiently optimized using adynamic programming approach. We then develop an efficient cluster fusionalgorithm that utilizes the tree structure of the weights to accelerate theoptimization process and eliminate the issue of cluster splits commonlyobserved in convex clustering. By combining the dynamic programming approachwith the cluster fusion algorithm, the TGCC algorithm achieves superiorcomputational efficiency without sacrificing clustering performance.Remarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$points in $\mathbb{R}^2$ within 15 seconds on a standard laptop without theneed for parallel or distributed computing frameworks. Moreover, we extend theTGCC algorithm to develop biclustering and sparse convex clustering algorithms.
  </details>

- **[CITRAS: Covariate-Informed Transformer for Time Series Forecasting](http://arxiv.org/abs/2503.24007v1)**  `arXiv:2503.24007`  
  _Yosuke Yamaguchi, Issei Suemitsu, Wenpeng Wei_
  <details><summary>Abstract</summary>
  Covariates play an indispensable role in practical time series forecasting,offering rich context from the past and sometimes extending into the future.However, their availability varies depending on the scenario, and situationsoften involve multiple target variables simultaneously. Moreover, thecross-variate dependencies between them are multi-granular, with somecovariates having a short-term impact on target variables and others showinglong-term correlations. This heterogeneity and the intricate dependenciesarising in covariate-informed forecasting present significant challenges toexisting deep models. To address these issues, we propose CITRAS, a patch-basedTransformer that flexibly leverages multiple targets and covariates coveringboth the past and the future forecasting horizon. While preserving the strongautoregressive capabilities of the canonical Transformer, CITRAS introduces twonovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shiftand Attention Score Smoothing. KV Shift seamlessly incorporates future knowncovariates into the forecasting of target variables based on their concurrentdependencies. Additionally, Attention Score Smoothing transforms locallyaccurate patch-wise cross-variate dependencies into global variate-leveldependencies by smoothing the past series of attention scores. Experimentally,CITRAS achieves state-of-the-art performance in both covariate-informed andmultivariate forecasting, demonstrating its versatile ability to leveragecross-variate dependency for improved forecasting accuracy.
  </details>

- **[Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving](http://arxiv.org/abs/2503.24000v1)**  `arXiv:2503.24000`  
  _Wei Gao, Xinyu Zhou, Peng Sun, Tianwei Zhang, Yonggang Wen_
  <details><summary>Abstract</summary>
  Key-Value cache (\texttt{KV} \texttt{cache}) compression has emerged as apromising technique to optimize Large Language Model (LLM) serving. Itprimarily decreases the memory consumption of \texttt{KV} \texttt{cache} toreduce the computation cost. Despite the development of many compressionalgorithms, their applications in production environments are still notprevalent. In this paper, we revisit mainstream \texttt{KV} \texttt{cache}compression solutions from a practical perspective. Our contributions arethree-fold. First, we comprehensively review existing algorithmic designs andbenchmark studies for \texttt{KV} \texttt{cache} compression and identifymissing pieces in their performance measurement, which could hinder theiradoption in practice. Second, we empirically evaluate representative\texttt{KV} \texttt{cache} compression methods to uncover two key issues thataffect the computational efficiency: (1) while compressing \texttt{KV}\texttt{cache} can reduce memory consumption, current implementations (e.g.,FlashAttention, PagedAttention) do not optimize for production-level LLMserving, resulting in suboptimal throughput performance; (2) compressing\texttt{KV} \texttt{cache} may lead to longer outputs, resulting in increasedend-to-end latency. We further investigate the accuracy performance ofindividual samples rather than the overall performance, revealing the intrinsiclimitations in \texttt{KV} \texttt{cache} compression when handling specificLLM tasks. Third, we provide tools to shed light on future \texttt{KV}\texttt{cache} compression studies and facilitate their practical deployment inproduction. They are open-sourced in\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.
  </details>

- **[Federated Structured Sparse PCA for Anomaly Detection in IoT Networks](http://arxiv.org/abs/2503.23981v1)**  `arXiv:2503.23981`  
  _Chenyi Huang, Xinrong Li, Xianchao Xiu_
  <details><summary>Abstract</summary>
  Although federated learning has gained prominence as a privacy-preservingframework tailored for distributed Internet of Things (IoT) environments,current federated principal component analysis (PCA) methods lack integrationof sparsity, a critical feature for robust anomaly detection. To address thislimitation, we propose a novel federated structured sparse PCA (FedSSP)approach for anomaly detection in IoT networks. The proposed model uniquelyintegrates double sparsity regularization: (1) row-wise sparsity governed by$\ell_{2,p}$-norm with $p\in[0,1)$ to eliminate redundant feature dimensions,and (2) element-wise sparsity via $\ell_{q}$-norm with $q\in[0,1)$ to suppressnoise-sensitive components. To efficiently solve this non-convex optimizationproblem in a distributed setting, we devise a proximal alternating minimization(PAM) algorithm with rigorous theoretical proofs establishing its convergenceguarantees. Experiments on real datasets validate that incorporating structuredsparsity enhances both model interpretability and detection accuracy.
  </details>

- **[Noise-based reward-modulated learning](http://arxiv.org/abs/2503.23972v1)**  `arXiv:2503.23972`  
  _Jes√∫s Garc√≠a Fern√°ndez, Nasir Ahmad, Marcel van Gerven_
  <details><summary>Abstract</summary>
  Recent advances in reinforcement learning (RL) have led to significantimprovements in task performance. However, training neural networks in an RLregime is typically achieved in combination with backpropagation, limitingtheir applicability in resource-constrained environments or when usingnon-differentiable neural networks. While noise-based alternatives likereward-modulated Hebbian learning (RMHL) have been proposed, their performancehas remained limited, especially in scenarios with delayed rewards, whichrequire retrospective credit assignment over time. Here, we derive a novelnoise-based learning rule that addresses these challenges. Our approachcombines directional derivative theory with Hebbian-like updates to enableefficient, gradient-free learning in RL. It features stochastic noisy neuronswhich can approximate gradients, and produces local synaptic updates modulatedby a global reward signal. Drawing on concepts from neuroscience, our methoduses reward prediction error as its optimization target to generateincreasingly advantageous behavior, and incorporates an eligibility trace tofacilitate temporal credit assignment in environments with delayed rewards. Itsformulation relies on local information alone, making it compatible withimplementations in neuromorphic hardware. Experimental validation shows thatour approach significantly outperforms RMHL and is competitive with BP-basedbaselines, highlighting the promise of noise-based, biologically inspiredlearning for low-power and real-time applications.
  </details>

- **[Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in Discriminative and Generative AI Operations](http://arxiv.org/abs/2503.23934v1)**  `arXiv:2503.23934`  
  _Adri√°n S√°nchez-Momp√≥, Ioannis Mavromatis, Peizheng Li, Konstantinos Katsaros, Aftab Khan_
  <details><summary>Abstract</summary>
  This study presents an empirical investigation into the energy consumption ofDiscriminative and Generative AI models within real-world MLOps pipelines. ForDiscriminative models, we examine various architectures and hyperparametersduring training and inference and identify energy-efficient practices. ForGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily onenergy consumption across different model sizes and varying service requests.Our study employs software-based power measurements, ensuring ease ofreplication across diverse configurations, models, and datasets. We analysemultiple models and hardware setups to uncover correlations among variousmetrics, identifying key contributors to energy consumption. The resultsindicate that for Discriminative models, optimising architectures,hyperparameters, and hardware can significantly reduce energy consumptionwithout sacrificing performance. For LLMs, energy efficiency depends onbalancing model size, reasoning complexity, and request-handling capacity, aslarger models do not necessarily consume more energy when utilisation remainslow. This analysis provides practical guidelines for designing green andsustainable ML operations, emphasising energy consumption and carbon footprintreductions while maintaining performance. This paper can serve as a benchmarkfor accurately estimating total energy use across different types of AI models.
  </details>

- **[DiffScale: Continuous Downscaling and Bias Correction of Subseasonal Wind Speed Forecasts using Diffusion Models](http://arxiv.org/abs/2503.23893v1)**  `arXiv:2503.23893`  
  _Maximilian Springenberg, Noelia Otero, Yuxin Xue, Jackie Ma_
  <details><summary>Abstract</summary>
  Renewable resources are strongly dependent on local and large-scale weathersituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond twoweeks and up to two months -- can offer significant socioeconomic advantages tothe energy sector. This study aims to enhance wind speed predictions using adiffusion model with classifier-free guidance to downscale S2S forecasts ofsurface wind speed. We propose DiffScale, a diffusion model that super-resolvesspatial information for continuous downscaling factors and lead times.Leveraging weather priors as guidance for the generative process of diffusionmodels, we adopt the perspective of conditional probabilities on samplingsuper-resolved S2S forecasts. We aim to directly estimate the densityassociated with the target S2S forecasts at different spatial resolutions andlead times without auto-regression or sequence prediction, resulting in anefficient and flexible model. Synthetic experiments were designed tosuper-resolve wind speed S2S forecasts from the European Center forMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finerresolution of ERA5 reanalysis data, which serves as a high-resolution target.The innovative aspect of DiffScale lies in its flexibility to downscalearbitrary scaling factors, enabling it to generalize across various gridresolutions and lead times -without retraining the model- while correctingmodel errors, making it a versatile tool for improving S2S wind speedforecasts. We achieve a significant improvement in prediction quality,outperforming baselines up to week 3.
  </details>

- **[An End-to-End Comprehensive Gear Fault Diagnosis Method Based on Multi-Scale Feature-Level Fusion Strategy](http://arxiv.org/abs/2503.23887v1)**  `arXiv:2503.23887`  
  _Bowei Qiao, Hongwei Wang_
  <details><summary>Abstract</summary>
  To satisfy the requirements of the end-to-end fault diagnosis of gears, anintegrated intelligent method of fault diagnosis for gears using accelerationsignals was proposed, which was based on Gabor-based Adaptive Short-TimeFourier Transform (Gabor-ASTFT) and Dual-Tree Complex Wavelet Transform(DTCWT)algorithms, Dilated Residual structure and feature fusion layer, is proposed inthis paper. Initially, the raw one-dimensional acceleration signals collectedfrom the gearbox base using vibration sensors undergo pre-segmentationprocessing. The Gabor-ASTFT and DTCWT are then applied to convert the originalone-dimensional time-domain signals into two-dimensional time-frequencyrepresentations, facilitating the preliminary extraction of fault features andobtaining weak feature maps.Subsequently, a dual-channel structure isestablished using deconvolution and dilated convolution to perform upsamplingand downsampling on the feature maps, adjusting their sizes accordingly. Afeature fusion layer is then constructed to integrate the dual-channelfeatures, enabling multi-scale analysis of the extracted faultfeatures.Finally, a convolutional neural network (CNN) model incorporating aresidual structure is developed to conduct deep feature extraction from thefused feature maps. The extracted features are subsequently fed into a GlobalAverage Pooling(GAP) and a classification function for fault classification.Conducting comparative experiments on different datasets, the proposed methodis demonstrated to effectively meet the requirements of end-to-end faultdiagnosis for gears.
  </details>

- **[Communication-Efficient and Personalized Federated Foundation Model Fine-Tuning via Tri-Matrix Adaptation](http://arxiv.org/abs/2503.23869v1)**  `arXiv:2503.23869`  
  _Yongle Li, Bo Liu, Sheng Huang, ZHeng ZHang, Xiaotong Yuan, Richang Hong_
  <details><summary>Abstract</summary>
  In federated learning, fine-tuning pre-trained foundation models posessignificant challenges, particularly regarding high communication cost andsuboptimal model performance due to data heterogeneity between the clients. Toaddress these issues, this paper introduces communication-efficient federatedLoRA adaption (CE-LoRA), a method that employs a tri-factorization low-rankadaptation approach with personalized model parameter aggregation. We firstpresents a novel LoRA parameter factorization by introducing a small-size densematrix, which can significantly reduce the communication cost and achievecomparable empirical performance than transferring the low-rank parametermatrix used by existing methods. Without violating data privacy, the serverconsiders the client similarity in both training dataset and model parameterspace, and learns personalized weights for model aggregation. Our experimentson various LLM and VLM fine-tuning tasks demonstrate that CE-LoRA not onlysignificantly reduces communication overhead but also improves performanceunder not independently and identically distributed data conditions. Inaddition, CE-LoRA improves data privacy protection, effectively mitigatinggradient-based data reconstruction attacks.
  </details>

- **[An extrapolated and provably convergent algorithm for nonlinear matrix decomposition with the ReLU function](http://arxiv.org/abs/2503.23832v1)**  `arXiv:2503.23832`  
  _Nicolas Gillis, Margherita Porcelli, Giovanni Seraghiti_
  <details><summary>Abstract</summary>
  Nonlinear matrix decomposition (NMD) with the ReLU function, denotedReLU-NMD, is the following problem: given a sparse, nonnegative matrix $X$ anda factorization rank $r$, identify a rank-$r$ matrix $\Theta$ such that$X\approx \max(0,\Theta)$. This decomposition finds application in datacompression, matrix completion with entries missing not at random, and manifoldlearning. The standard ReLU-NMD model minimizes the least squares error, thatis, $\|X - \max(0,\Theta)\|_F^2$. The corresponding optimization problem isnondifferentiable and highly nonconvex. This motivated Saul to propose analternative model, Latent-ReLU-NMD, where a latent variable $Z$ is introducedand satisfies $\max(0,Z)=X$ while minimizing $\|Z - \Theta\|_F^2$ (``Anonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.Math. Data Sci., 2022). Our first contribution is to show that the twoformulations may yield different low-rank solutions $\Theta$; in particular, weshow that Latent-ReLU-NMD can be ill-posed when ReLU-NMD is not, meaning thatthere are instances in which the infimum of Latent-ReLU-NMD is not attainedwhile that of ReLU-NMD is. We also consider another alternative model, called3B-ReLU-NMD, which parameterizes $\Theta=WH$, where $W$ has $r$ columns and $H$has $r$ rows, allowing one to get rid of the rank constraint inLatent-ReLU-NMD. Our second contribution is to prove the convergence of a blockcoordinate descent (BCD) applied to 3B-ReLU-NMD and referred to as BCD-NMD. Ourthird contribution is a novel extrapolated variant of BCD-NMD, dubbed eBCD-NMD,which we prove is also convergent under mild assumptions. We illustrate thesignificant acceleration effect of eBCD-NMD compared to BCD-NMD, and also showthat eBCD-NMD performs well against the state of the art on synthetic andreal-world data sets.
  </details>

- **[Node Embeddings via Neighbor Embeddings](http://arxiv.org/abs/2503.23822v1)**  `arXiv:2503.23822`  
  _Jan Niklas B√∂hm, Marius Keute, Alica Guzm√°n, Sebastian Damrich, Andrew Draganov, Dmitry Kobak_
  <details><summary>Abstract</summary>
  Graph layouts and node embeddings are two distinct paradigms fornon-parametric graph representation learning. In the former, nodes are embeddedinto 2D space for visualization purposes. In the latter, nodes are embeddedinto a high-dimensional vector space for downstream processing.State-of-the-art algorithms for these two paradigms, force-directed layouts andrandom-walk-based contrastive learning (such as DeepWalk and node2vec), havelittle in common. In this work, we show that both paradigms can be approachedwith a single coherent framework based on established neighbor embeddingmethods. Specifically, we introduce graph t-SNE, a neighbor embedding methodfor two-dimensional graph layouts, and graph CNE, a contrastive neighborembedding method that produces high-dimensional node representations byoptimizing the InfoNCE objective. We show that both graph t-SNE and graph CNEstrongly outperform state-of-the-art algorithms in terms of local structurepreservation, while being conceptually simpler.
  </details>

- **[When Counterfactual Reasoning Fails: Chaos and Real-World Complexity](http://arxiv.org/abs/2503.23820v1)**  `arXiv:2503.23820`  
  _Yahya Aalaila, Gerrit Gro√ümann, Sumantrak Mukherjee, Jonas Wahl, Sebastian Vollmer_
  <details><summary>Abstract</summary>
  Counterfactual reasoning, a cornerstone of human cognition anddecision-making, is often seen as the 'holy grail' of causal learning, withapplications ranging from interpreting machine learning models to promotingalgorithmic fairness. While counterfactual reasoning has been extensivelystudied in contexts where the underlying causal model is well-defined,real-world causal modeling is often hindered by model and parameteruncertainty, observational noise, and chaotic behavior. The reliability ofcounterfactual analysis in such settings remains largely unexplored. In thiswork, we investigate the limitations of counterfactual reasoning within theframework of Structural Causal Models. Specifically, we empirically investigate\emph{counterfactual sequence estimation} and highlight cases where it becomesincreasingly unreliable. We find that realistic assumptions, such as lowdegrees of model uncertainty or chaotic dynamics, can result incounterintuitive outcomes, including dramatic deviations between predicted andtrue counterfactual trajectories. This work urges caution when applyingcounterfactual reasoning in settings characterized by chaos and uncertainty.Furthermore, it raises the question of whether certain systems may posefundamental limitations on the ability to answer counterfactual questions abouttheir behavior.
  </details>

- **[Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics](http://arxiv.org/abs/2503.23819v1)**  `arXiv:2503.23819`  
  _Swarnava Bhattacharyya, Umapada Pal, Tapabrata Chakraborti_
  <details><summary>Abstract</summary>
  Deep learning based diagnostic AI systems based on medical images arestarting to provide similar performance as human experts. However these datahungry complex systems are inherently black boxes and therefore slow to beadopted for high risk applications like healthcare. This problem of lack oftransparency is exacerbated in the case of recent large foundation models,which are trained in a self supervised manner on millions of data points toprovide robust generalisation across a range of downstream tasks, but theembeddings generated from them happen through a process that is notinterpretable, and hence not easily trustable for clinical applications. Toaddress this timely issue, we deploy conformal analysis to quantify thepredictive uncertainty of a vision transformer (ViT) based foundation modelacross patient demographics with respect to sex, age and ethnicity for thetasks of skin lesion classification using several public benchmark datasets.The significant advantage of this method is that conformal analysis is methodindependent and it not only provides a coverage guarantee at population levelbut also provides an uncertainty score for each individual. We used amodel-agnostic dynamic F1-score-based sampling during model training, whichhelped to stabilize the class imbalance and we investigate the effects onuncertainty quantification (UQ) with or without this bias mitigation step. Thuswe show how this can be used as a fairness metric to evaluate the robustness ofthe feature embeddings of the foundation model (Google DermFoundation) and thusadvance the trustworthiness and fairness of clinical AI.
  </details>

- **[An extension of linear self-attention for in-context learning](http://arxiv.org/abs/2503.23814v1)**  `arXiv:2503.23814`  
  _Katsuyuki Hagiwara_
  <details><summary>Abstract</summary>
  In-context learning is a remarkable property of transformers and has been thefocus of recent research. An attention mechanism is a key component intransformers, in which an attention matrix encodes relationships between wordsin a sentence and is used as weights for words in a sentence. This mechanism iseffective for capturing language representations. However, it is questionablewhether naive self-attention is suitable for in-context learning in generaltasks, since the computation implemented by self-attention is somewhatrestrictive in terms of matrix multiplication. In fact, we may need appropriateinput form designs when considering heuristic implementations of computationalalgorithms. In this paper, in case of linear self-attention, we extend it byintroducing a bias matrix in addition to a weight matrix for an input. Despitethe simple extension, the extended linear self-attention can output anyconstant matrix, input matrix and multiplications of two or three matrices inthe input. Note that the second property implies that it can be a skipconnection. Therefore, flexible matrix manipulations can be implemented byconnecting the extended linear self-attention components. As an example ofimplementation using the extended linear self-attention, we show a heuristicconstruction of a batch-type gradient descent of ridge regression under areasonable input form.
  </details>

- **[Accelerating High-Efficiency Organic Photovoltaic Discovery via Pretrained Graph Neural Networks and Generative Reinforcement Learning](http://arxiv.org/abs/2503.23766v1)**  `arXiv:2503.23766`  
  _Jiangjie Qiu, Hou Hei Lam, Xiuyuan Hu, Wentao Li, Siwei Fu, Fankun Zeng, et al._
  <details><summary>Abstract</summary>
  Organic photovoltaic (OPV) materials offer a promising avenue towardcost-effective solar energy utilization. However, optimizing donor-acceptor(D-A) combinations to achieve high power conversion efficiency (PCE) remains asignificant challenge. In this work, we propose a framework that integrateslarge-scale pretraining of graph neural networks (GNNs) with a GPT-2(Generative Pretrained Transformer 2)-based reinforcement learning (RL)strategy to design OPV molecules with potentially high PCE. This approachproduces candidate molecules with predicted efficiencies approaching 21\%,although further experimental validation is required. Moreover, we conducted apreliminary fragment-level analysis to identify structural motifs recognized bythe RL model that may contribute to enhanced PCE, thus providing designguidelines for the broader research community. To facilitate continueddiscovery, we are building the largest open-source OPV dataset to date,expected to include nearly 3,000 donor-acceptor pairs. Finally, we discussplans to collaborate with experimental teams on synthesizing and characterizingAI-designed molecules, which will provide new data to refine and improve ourpredictive and generative models.
  </details>

- **[Time-Series Forecasting via Topological Information Supervised Framework with Efficient Topological Feature Learning](http://arxiv.org/abs/2503.23757v1)**  `arXiv:2503.23757`  
  _ZiXin Lin, Nur Fariha Syaqina Zulkepli_
  <details><summary>Abstract</summary>
  Topological Data Analysis (TDA) has emerged as a powerful tool for extractingmeaningful features from complex data structures, driving significantadvancements in fields such as neuroscience, biology, machine learning, andfinancial modeling. Despite its success, the integration of TDA withtime-series prediction remains underexplored due to three primary challenges:the limited utilization of temporal dependencies within topological features,computational bottlenecks associated with persistent homology, and thedeterministic nature of TDA pipelines restricting generalized feature learning.This study addresses these challenges by proposing the Topological InformationSupervised (TIS) Prediction framework, which leverages neural networks andConditional Generative Adversarial Networks (CGANs) to generate synthetictopological features, preserving their distribution while significantlyreducing computational time. We propose a novel training strategy thatintegrates topological consistency loss to improve the predictive accuracy ofdeep learning models. Specifically, we introduce two state-of-the-art models,TIS-BiGRU and TIS-Informer, designed to capture short-term and long-termtemporal dependencies, respectively. Comparative experimental resultsdemonstrate the superior performance of TIS models over conventionalpredictors, validating the effectiveness of integrating topologicalinformation. This work not only advances TDA-based time-series prediction butalso opens new avenues for utilizing topological features in deep learningarchitectures.
  </details>

- **[PDSL: Privacy-Preserved Decentralized Stochastic Learning with Heterogeneous Data Distribution](http://arxiv.org/abs/2503.23726v1)**  `arXiv:2503.23726`  
  _Lina Wang, Yunsheng Yuan, Chunxiao Wang, Feng Li_
  <details><summary>Abstract</summary>
  In the paradigm of decentralized learning, a group of agents collaborates tolearn a global model using distributed datasets without a central server.However, due to the heterogeneity of the local data across the differentagents, learning a robust global model is rather challenging. Moreover, thecollaboration of the agents relies on their gradient information exchange,which poses a risk of privacy leakage. In this paper, to address these issues,we propose PDSL, a novel privacy-preserved decentralized stochastic learningalgorithm with heterogeneous data distribution. On one hand, we innovate inutilizing the notion of Shapley values such that each agent can preciselymeasure the contributions of its heterogeneous neighbors to the global learninggoal; on the other hand, we leverage the notion of differential privacy toprevent each agent from suffering privacy leakage when it contributes gradientinformation to its neighbors. We conduct both solid theoretical analysis andextensive experiments to demonstrate the efficacy of our PDSL algorithm interms of privacy preservation and convergence.
  </details>

- **[Unimodal-driven Distillation in Multimodal Emotion Recognition with Dynamic Fusion](http://arxiv.org/abs/2503.23721v1)**  `arXiv:2503.23721`  
  _Jiagen Li, Rui Yu, Huihao Huang, Huaicheng Yan_
  <details><summary>Abstract</summary>
  Multimodal Emotion Recognition in Conversations (MERC) identifies emotionalstates across text, audio and video, which is essential for intelligentdialogue systems and opinion analysis. Existing methods emphasize heterogeneousmodal fusion directly for cross-modal integration, but often suffer fromdisorientation in multimodal learning due to modal heterogeneity and lack ofinstructive guidance. In this work, we propose SUMMER, a novel heterogeneousmultimodal integration framework leveraging Mixture of Experts withHierarchical Cross-modal Fusion and Interactive Knowledge Distillation. Keycomponents include a Sparse Dynamic Mixture of Experts (SDMoE) for capturingdynamic token-wise interactions, a Hierarchical Cross-Modal Fusion (HCMF) foreffective fusion of heterogeneous modalities, and Interactive KnowledgeDistillation (IKD), which uses a pre-trained unimodal teacher to guidemultimodal fusion in latent and logit spaces. Experiments on IEMOCAP and MELDshow SUMMER outperforms state-of-the-art methods, particularly in recognizingminority and semantically similar emotions.
  </details>

- **[Steering Large Agent Populations using Mean-Field Schrodinger Bridges with Gaussian Mixture Models](http://arxiv.org/abs/2503.23705v1)**  `arXiv:2503.23705`  
  _George Rapakoulias, Ali Reza Pedram, Panagiotis Tsiotras_
  <details><summary>Abstract</summary>
  The Mean-Field Schrodinger Bridge (MFSB) problem is an optimization problemaiming to find the minimum effort control policy to drive a McKean-Vlassovstochastic differential equation from one probability measure to another. Inthe context of multiagent control, the objective is to control theconfiguration of a swarm of identical, interacting cooperative agents, ascaptured by the time-varying probability measure of their state. Availablemethods for solving this problem for distributions with continuous support relyeither on spatial discretizations of the problem's domain or on approximatingoptimal solutions using neural networks trained through stochastic optimizationschemes. For agents following Linear Time-Varying dynamics, and for GaussianMixture Model boundary distributions, we propose a highly efficientparameterization to approximate the solutions of the corresponding MFSB inclosed form, without any learning steps. Our proposed approach consists of amixture of elementary policies, each solving a Gaussian-to-Gaussian CovarianceSteering problem from the components of the initial to the components of theterminal mixture. Leveraging the semidefinite formulation of the CovarianceSteering problem, our proposed solver can handle probabilistic hard constraintson the system's state, while maintaining numerical tractability. We illustrateour approach on a variety of numerical examples.
  </details>

- **[A Low-complexity Structured Neural Network to Realize States of Dynamical Systems](http://arxiv.org/abs/2503.23697v1)**  `arXiv:2503.23697`  
  _Hansaka Aluvihare, Levi Lingsch, Xianqi Li, Sirani M. Perera_
  <details><summary>Abstract</summary>
  Data-driven learning is rapidly evolving and places a new perspective onrealizing state-space dynamical systems. However, dynamical systems derivedfrom nonlinear ordinary differential equations (ODEs) suffer from limitationsin computational efficiency. Thus, this paper stems from data-driven learningto advance states of dynamical systems utilizing a structured neural network(StNN). The proposed learning technique also seeks to identify an optimal,low-complexity operator to solve dynamical systems, the so-called Hankeloperator, derived from time-delay measurements. Thus, we utilize the StNN basedon the Hankel operator to solve dynamical systems as an alternative to existingdata-driven techniques. We show that the proposed StNN reduces the number ofparameters and computational complexity compared with the conventional neuralnetworks and also with the classical data-driven techniques, such as SparseIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view ofKoopman (HAVOK), which is commonly known as delay-Dynamic ModeDecomposition(DMD) or Hankel-DMD. More specifically, we present numericalsimulations to solve dynamical systems utilizing the StNN based on the Hankeloperator beginning from the fundamental Lotka-Volterra model, where we comparethe StNN with the LEarning Across Dynamical Systems (LEADS), and extend ouranalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNNwith conventional neural networks, SINDy, and HAVOK. Hence, we show that theproposed StNN paves the way for realizing state-space dynamical systems with alow-complexity learning algorithm, enabling prediction and understanding offuture states.
  </details>

- **[Data-Driven Forecasting of High-Dimensional Transient and Stationary Processes via Space-Time Projection](http://arxiv.org/abs/2503.23686v1)**  `arXiv:2503.23686`  
  _Oliver T. Schmidt_
  <details><summary>Abstract</summary>
  Space-Time Projection (STP) is introduced as a data-driven forecastingapproach for high-dimensional and time-resolved data. The method computesextended space-time proper orthogonal modes from training data spanning aprediction horizon comprising both hindcast and forecast intervals. Forecastsare then generated by projecting the hindcast portion of these modes onto newdata, simultaneously leveraging their orthogonality and optimal correlationwith the forecast extension. Rooted in Proper Orthogonal Decomposition (POD)theory, dimensionality reduction and time-delay embedding are intrinsic to theapproach. For a given ensemble and fixed prediction horizon, the only tunableparameter is the truncation rank--no additional hyperparameters are required.The hindcast accuracy serves as a reliable indicator for short-term forecastaccuracy and establishes a lower bound on forecast errors. The efficacy of themethod is demonstrated using two datasets: transient, highly anisotropicsimulations of supernova explosions in a turbulent interstellar medium, andexperimental velocity fields of a turbulent high-subsonic engineering flow. Ina comparative study with standard Long Short-Term Memory (LSTM) neuralnetworks--acknowledging that alternative architectures or training strategiesmay yield different outcomes--the method consistently provided more accurateforecasts. Considering its simplicity and robust performance, STP offers aninterpretable and competitive benchmark for forecasting high-dimensionaltransient and chaotic processes, relying purely on spatiotemporal correlationinformation.
  </details>

- **[Dynamic Operating System Scheduling Using Double DQN: A Reinforcement Learning Approach to Task Optimization](http://arxiv.org/abs/2503.23659v1)**  `arXiv:2503.23659`  
  _Xiaoxuan Sun, Yifei Duan, Yingnan Deng, Fan Guo, Guohui Cai, Yuting Peng_
  <details><summary>Abstract</summary>
  In this paper, an operating system scheduling algorithm based on Double DQN(Double Deep Q network) is proposed, and its performance under different tasktypes and system loads is verified by experiments. Compared with thetraditional scheduling algorithm, the algorithm based on Double DQN candynamically adjust the task priority and resource allocation strategy, thusimproving the task completion efficiency, system throughput, and responsespeed. The experimental results show that the Double DQN algorithm has highscheduling performance under light load, medium load and heavy load scenarios,especially when dealing with I/O intensive tasks, and can effectively reducetask completion time and system response time. In addition, the algorithm alsoshows high optimization ability in resource utilization and can intelligentlyadjust resource allocation according to the system state, avoiding resourcewaste and excessive load. Future studies will further explore the applicationof the algorithm in more complex systems, especially scheduling optimization incloud computing and large-scale distributed environments, combining factorssuch as network latency and energy efficiency to improve the overallperformance and adaptability of the algorithm.
  </details>

- **[A Survey of Reinforcement Learning-Based Motion Planning for Autonomous Driving: Lessons Learned from a Driving Task Perspective](http://arxiv.org/abs/2503.23650v1)**  `arXiv:2503.23650`  
  _Zhuoren Li, Guizhe Jin, Ran Yu, Zhiwen Chen, Nan Li, Wei Han, et al._
  <details><summary>Abstract</summary>
  Reinforcement learning (RL), with its ability to explore and optimizepolicies in complex, dynamic decision-making tasks, has emerged as a promisingapproach to addressing motion planning (MoP) challenges in autonomous driving(AD). Despite rapid advancements in RL and AD, a systematic description andinterpretation of the RL design process tailored to diverse driving tasksremains underdeveloped. This survey provides a comprehensive review of RL-basedMoP for AD, focusing on lessons from task-specific perspectives. We firstoutline the fundamentals of RL methodologies, and then survey theirapplications in MoP, analyzing scenario-specific features and task requirementsto shed light on their influence on RL design choices. Building on thisanalysis, we summarize key design experiences, extract insights from variousdriving task applications, and provide guidance for future implementations.Additionally, we examine the frontier challenges in RL-based MoP, review recentefforts to addresse these challenges, and propose strategies for overcomingunresolved issues.
  </details>

- **[Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning](http://arxiv.org/abs/2503.22456v2)**  `arXiv:2503.22456`  
  _Abdullah Vanlioglu_
  <details><summary>Abstract</summary>
  We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach thatenhances the exploration-exploitation tradeoff by dynamically assigning weightsto generated outputs based on their advantage and entropy for ReinforcementLearning-based Large Language Model fine-tuning. EGSW integrates entropyregularization with advantage-based weighting to balance policy updates,enabling efficient exploration in high-dimensional state spaces. By employingtemperature-scaled softmax weighting over sequences, EGSW prioritizinghigh-reward, high-uncertainty steps while maintaining training stability.Although originally developed to improve Group Relative Policy Optimization(GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable toother reinforcement learning (RL) algorithms and can be implemented in bothstep-wise and trajectory-wise settings. Empirical evaluations demonstrate thatEGSW enhances GRPO reasoning ability, yielding improvements in sampleefficiency. Future work will explore the application of EGSW to advanced RLmethodologies.
  </details>

- **[Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback](http://arxiv.org/abs/2503.22230v2)**  `arXiv:2503.22230`  
  _Wei Shen, Guanlin Liu, Zheng Wu, Ruofei Zhu, Qingping Yang, Chao Xin, et al._
  <details><summary>Abstract</summary>
  Reinforcement Learning from Human Feedback (RLHF) is crucial for aligninglarge language models with human preferences. While recent research has focusedon algorithmic improvements, the importance of prompt-data construction hasbeen overlooked. This paper addresses this gap by exploring data-drivenbottlenecks in RLHF performance scaling, particularly reward hacking anddecreasing response diversity. We introduce a hybrid reward system combiningreasoning task verifiers (RTV) and a generative reward model (GenRM) tomitigate reward hacking. We also propose a novel prompt-selection method,Pre-PPO, to maintain response diversity and enhance learning effectiveness.Additionally, we find that prioritizing mathematical and coding tasks early inRLHF training significantly improves performance. Experiments across two modelsizes validate our methods' effectiveness and scalability. Results show thatRTV is most resistant to reward hacking, followed by GenRM with ground truth,and then GenRM with SFT Best-of-N responses. Our strategies enable rapidcapture of subtle task-specific distinctions, leading to substantialimprovements in overall RLHF performance. This work highlights the importanceof careful data construction and provides practical methods to overcomeperformance barriers in RLHF.
  </details>

- **[The Mathematical Relationship Between Layer Normalization and Dynamic Activation Functions](http://arxiv.org/abs/2503.21708v2)**  `arXiv:2503.21708`  
  _Felix Stollenwerk_
  <details><summary>Abstract</summary>
  A recent paper proposes Dynamic Tanh (DyT) as a drop-in replacement for layernormalization (LN). Although the method is empirically well-motivated andappealing from a practical point of view, it lacks a theoretical foundation. Inthis work, we shed light on the mathematical relationship between layernormalization and dynamic activation functions. In particular, we derive DyTfrom LN and show that a well-defined approximation is needed to do so. Bydropping said approximation, an alternative activation function is obtained,which we call Dynamic Inverse Square Root Unit (DyISRU). DyISRU is the exactcounterpart of layer normalization, and we demonstrate numerically that itindeed resembles LN more accurately than DyT does.
  </details>

- **[Efficient Learning for Entropy-Regularized Markov Decision Processes via Multilevel Monte Carlo](http://arxiv.org/abs/2503.21224v2)**  `arXiv:2503.21224`  
  _Matthieu Meunier, Christoph Reisinger, Yufei Zhang_
  <details><summary>Abstract</summary>
  Designing efficient learning algorithms with complexity guarantees for Markovdecision processes (MDPs) with large or continuous state and action spacesremains a fundamental challenge. We address this challenge forentropy-regularized MDPs with Polish state and action spaces, assuming accessto a generative model of the environment. We propose a novel family ofmultilevel Monte Carlo (MLMC) algorithms that integrate fixed-point iterationwith MLMC techniques and a generic stochastic approximation of the Bellmanoperator. We quantify the precise impact of the chosen approximate Bellmanoperator on the accuracy of the resulting MLMC estimator. Leveraging this erroranalysis, we show that using a biased plain MC estimate for the Bellmanoperator results in quasi-polynomial sample complexity, whereas an unbiasedrandomized multilevel approximation of the Bellman operator achieves polynomialsample complexity in expectation. Notably, these complexity bounds areindependent of the dimensions or cardinalities of the state and action spaces,distinguishing our approach from existing algorithms whose complexities scalewith the sizes of these spaces. We validate these theoretical performanceguarantees through numerical experiments.
  </details>

- **[Innovative LSGTime Model for Crime Spatiotemporal Prediction Based on MindSpore Framework](http://arxiv.org/abs/2503.20136v2)**  `arXiv:2503.20136`  
  _Zhenkai Qin, BaoZhong Wei, Caifeng Gao_
  <details><summary>Abstract</summary>
  With the acceleration of urbanization, the spatiotemporal characteristics ofcriminal activities have become increasingly complex. Accurate prediction ofcrime distribution is crucial for optimizing the allocation of police resourcesand preventing crime. This paper proposes LGSTime, a crime spatiotemporalprediction model that integrates Long Short-Term Memory (LSTM), Gated RecurrentUnit (GRU), and the Multi-head Sparse Self-attention mechanism. LSTM and GRUcapture long-term dependencies in crime time series, such as seasonality andperiodicity, through their unique gating mechanisms. The Multi-head SparseSelf-attention mechanism, on the other hand, focuses on both temporal andspatial features of criminal events simultaneously through parallel processingand sparsification techniques, significantly improving computational efficiencyand prediction accuracy. The integrated model leverages the strengths of eachtechnique to better handle complex spatiotemporal data. Experimental findingsdemonstrate that the model attains optimal performance across four real - worldcrime datasets. In comparison to the CNN model, it exhibits performanceenhancements of 2.8\%, 1.9\%, and 1.4\% in the Mean Squared Error (MSE), MeanAbsolute Error (MAE), and Root Mean Squared Error (RMSE) metrics respectively.These results offer a valuable reference for tackling the challenges in crimeprediction.
  </details>

- **[Comparison of Metadata Representation Models for Knowledge Graph Embeddings](http://arxiv.org/abs/2503.21804v2)**  `arXiv:2503.21804`  
  _Shusaku Egami, Kyoumoto Matsushita, Takanori Ugai, Ken Fukuda_
  <details><summary>Abstract</summary>
  Hyper-relational Knowledge Graphs (HRKGs) extend traditional KGs beyondbinary relations, enabling the representation of contextual, provenance, andtemporal information in domains, such as historical events, sensor data, videocontent, and narratives. HRKGs can be structured using several MetadataRepresentation Models (MRMs), including Reification (REF), Singleton Property(SGP), and RDF-star (RDR). However, the effects of different MRMs on KGEmbedding (KGE) and Link Prediction (LP) models remain unclear. This studyevaluates MRMs in the context of LP tasks, identifies the limitations ofexisting evaluation frameworks, and introduces a new task that ensures faircomparisons across MRMs. Furthermore, we propose a framework that effectivelyreflects the knowledge representations of the three MRMs in latent space.Experiments on two types of datasets reveal that REF performs well in simpleHRKGs, whereas SGP is less effective. However, in complex HRKGs, thedifferences among MRMs in the LP tasks are minimal. Our findings contribute toan optimal knowledge representation strategy for HRKGs in LP tasks.
  </details>

- **[Graph neural networks extrapolate out-of-distribution for shortest paths](http://arxiv.org/abs/2503.19173v2)**  `arXiv:2503.19173`  
  _Robert R. Nerem, Samantha Chen, Sanjoy Dasgupta, Yusu Wang_
  <details><summary>Abstract</summary>
  Neural networks (NNs), despite their success and wide adoption, stillstruggle to extrapolate out-of-distribution (OOD), i.e., to inputs that are notwell-represented by their training dataset. Addressing the OOD generalizationgap is crucial when models are deployed in environments significantly differentfrom the training set, such as applying Graph Neural Networks (GNNs) trained onsmall graphs to large, real-world graphs. One promising approach for achievingrobust OOD generalization is the framework of neural algorithmic alignment,which incorporates ideas from classical algorithms by designing neuralarchitectures that resemble specific algorithmic paradigms (e.g. dynamicprogramming). The hope is that trained models of this form would have superiorOOD capabilities, in much the same way that classical algorithms work for allinstances. We rigorously analyze the role of algorithmic alignment in achievingOOD generalization, focusing on graph neural networks (GNNs) applied to thecanonical shortest path problem. We prove that GNNs, trained to minimize asparsity-regularized loss over a small set of shortest path instances, exactlyimplement the Bellman-Ford (BF) algorithm for shortest paths. In fact, if a GNNminimizes this loss within an error of $\epsilon$, it implements the BFalgorithm with an error of $O(\epsilon)$. Consequently, despite limitedtraining data, these GNNs are guaranteed to extrapolate to arbitraryshortest-path problems, including instances of any size. Our empirical resultssupport our theory by showing that NNs trained by gradient descent are able tominimize this loss and extrapolate in practice.
  </details>

- **[LoRA Subtraction for Drift-Resistant Space in Exemplar-Free Continual Learning](http://arxiv.org/abs/2503.18985v2)**  `arXiv:2503.18985`  
  _Xuan Liu, Xiaobin Chang_
  <details><summary>Abstract</summary>
  In continual learning (CL), catastrophic forgetting often arises due tofeature drift. This challenge is particularly prominent in the exemplar-freecontinual learning (EFCL) setting, where samples from previous tasks cannot beretained, making it difficult to preserve prior knowledge. To address thisissue, some EFCL methods aim to identify feature spaces that minimize theimpact on previous tasks while accommodating new ones. However, they rely onstatic features or outdated statistics stored from old tasks, which preventsthem from capturing the dynamic evolution of the feature space in CL, leadingto performance degradation over time. In this paper, we introduce theDrift-Resistant Space (DRS), which effectively handles feature drifts withoutrequiring explicit feature modeling or the storage of previous tasks. A novelparameter-efficient fine-tuning approach called Low-Rank Adaptation Subtraction(LoRA-) is proposed to develop the DRS. This method subtracts the LoRA weightsof old tasks from the initial pre-trained weight before processing new taskdata to establish the DRS for model training. Therefore, LoRA- enhancesstability, improves efficiency, and simplifies implementation. Furthermore,stabilizing feature drifts allows for better plasticity by learning with atriplet loss. Our method consistently achieves state-of-the-art results,especially for long task sequences, across multiple datasets.
  </details>

- **[Inductive Moment Matching](http://arxiv.org/abs/2503.07565v6)**  `arXiv:2503.07565`  
  _Linqi Zhou, Stefano Ermon, Jiaming Song_
  <details><summary>Abstract</summary>
  Diffusion models and Flow Matching generate high-quality samples but are slowat inference, and distilling them into few-step models often leads toinstability and extensive tuning. To resolve these trade-offs, we proposeInductive Moment Matching (IMM), a new class of generative models for one- orfew-step sampling with a single-stage training procedure. Unlike distillation,IMM does not require pre-training initialization and optimization of twonetworks; and unlike Consistency Models, IMM guarantees distribution-levelconvergence and remains stable under various hyperparameters and standard modelarchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FIDusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98on CIFAR-10 for a model trained from scratch.
  </details>

- **[Studying the Interplay Between the Actor and Critic Representations in Reinforcement Learning](http://arxiv.org/abs/2503.06343v2)**  `arXiv:2503.06343`  
  _Samuel Garcin, Trevor McInroe, Pablo Samuel Castro, Prakash Panangaden, Christopher G. Lucas, David Abel, et al._
  <details><summary>Abstract</summary>
  Extracting relevant information from a stream of high-dimensionalobservations is a central challenge for deep reinforcement learning agents.Actor-critic algorithms add further complexity to this challenge, as it isoften unclear whether the same information will be relevant to both the actorand the critic. To this end, we here explore the principles that underlieeffective representations for the actor and for the critic in on-policyalgorithms. We focus our study on understanding whether the actor and criticwill benefit from separate, rather than shared, representations. Our primaryfinding is that when separated, the representations for the actor and criticsystematically specialise in extracting different types of information from theenvironment -- the actor's representation tends to focus on action-relevantinformation, while the critic's representation specialises in encoding valueand dynamics information. We conduct a rigourous empirical study to understandhow different representation learning approaches affect the actor and critic'sspecialisations and their downstream performance, in terms of sample efficiencyand generation capabilities. Finally, we discover that a separated critic playsan important role in exploration and data collection during training. Our code,trained models and data are accessible athttps://github.com/francelico/deac-rep.
  </details>

- **[CryptoPulse: Short-Term Cryptocurrency Forecasting with Dual-Prediction and Cross-Correlated Market Indicators](http://arxiv.org/abs/2502.19349v3)**  `arXiv:2502.19349`  
  _Amit Kumar, Taoran Ji_
  <details><summary>Abstract</summary>
  Cryptocurrencies fluctuate in markets with high price volatility, posingsignificant challenges for investors. To aid in informed decision-making,systems predicting cryptocurrency market movements have been developed,typically focusing on historical patterns. However, these methods oftenoverlook three critical factors influencing market dynamics: 1) the macroinvesting environment, reflected in major cryptocurrency fluctuations affectingcollaborative investor behaviors; 2) overall market sentiment, heavilyinfluenced by news impacting investor strategies; and 3) technical indicators,offering insights into overbought or oversold conditions, momentum, and markettrends, which are crucial for short-term price movements. This paper proposes adual prediction mechanism that forecasts the next day's closing price byincorporating macroeconomic fluctuations, technical indicators, and individualcryptocurrency price changes. Additionally, a novel refinement mechanismenhances predictions through market sentiment-based rescaling and fusion.Experiments demonstrate that the proposed model achieves state-of-the-artperformance, consistently outperforming ten comparison methods.
  </details>

- **[XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units](http://arxiv.org/abs/2502.06924v4)**  `arXiv:2502.06924`  
  _Arghadip Das, Arnab Raha, Shamik Kundu, Soumendu Kumar Ghosh, Deepak Mathaikutty, Vijay Raghunathan_
  <details><summary>Abstract</summary>
  State-Space Models (SSMs) have emerged as efficient alternatives totransformers for sequential data tasks, offering linear or near-linearscalability with sequence length, making them ideal for long-sequenceapplications in NLP, vision, and edge AI, including real-time transcription,translation, and contextual search. These applications require lightweight,high-performance models for deployment on resource-constrained devices likelaptops and PCs. Designing specialized accelerators for every emerging neuralnetwork is costly and impractical; instead, optimizing models for existing NPUsin AI PCs provides a scalable solution. To this end, we propose XAMBA, thefirst framework to enable and optimize SSMs on commercial off-the-shelf (COTS)state-of-the-art (SOTA) NPUs. XAMBA follows a three-step methodology: (1)enabling SSMs on NPUs, (2) optimizing performance to meet KPI requirements, and(3) trading accuracy for additional performance gains. After enabling SSMs onNPUs, XAMBA mitigates key bottlenecks using CumBA and ReduBA, replacingsequential CumSum and ReduceSum operations with matrix-based computations,significantly improving execution speed and memory efficiency. Additionally,ActiBA enhances performance by approximating expensive activation functions(e.g., Swish, Softplus) using piecewise linear mappings, reducing latency withminimal accuracy loss. Evaluations on an Intel Core Ultra Series 2 AI PC showthat XAMBA achieves up to 4.8X speed-up over the baseline. Our implementationis available at https://github.com/arghadippurdue/XAMBA.
  </details>

- **[The AI off-switch problem as a signalling game: bounded rationality and incomparability](http://arxiv.org/abs/2502.06403v3)**  `arXiv:2502.06403`  
  _Alessio Benavoli, Alessandro Facchini, Marco Zaffalon_
  <details><summary>Abstract</summary>
  The off-switch problem is a critical challenge in AI control: if an AI systemresists being switched off, it poses a significant risk. In this paper, wemodel the off-switch problem as a signalling game, where a human decision-makercommunicates its preferences about some underlying decision problem to an AIagent, which then selects actions to maximise the human's utility. We assumethat the human is a bounded rational agent and explore various boundedrationality mechanisms. Using real machine learning models, we reprove priorresults and demonstrate that a necessary condition for an AI system to refrainfrom disabling its off-switch is its uncertainty about the human's utility. Wealso analyse how message costs influence optimal strategies and extend theanalysis to scenarios involving incomparability.
  </details>

- **[Learning dynamical systems with hit-and-run random feature maps](http://arxiv.org/abs/2501.06661v2)**  `arXiv:2501.06661`  
  _Pinak Mandal, Georg A. Gottwald_
  <details><summary>Abstract</summary>
  We show how random feature maps can be used to forecast dynamical systemswith excellent forecasting skill. We consider the tanh activation function andjudiciously choose the internal weights in a data-driven manner such that theresulting features explore the nonlinear, non-saturated regions of theactivation function. We introduce skip connections and construct a deep variantof random feature maps by combining several units. To mitigate the curse ofdimensionality, we introduce localization where we learn local maps, employingconditional independence. Our modified random feature maps provide excellentforecasting skill for both single trajectory forecasts as well as long-timeestimates of statistical properties, for a range of chaotic dynamical systemswith dimensions up to 512. In contrast to other methods such as reservoircomputers which require extensive hyperparameter tuning, we effectively need totune only a single hyperparameter, and are able to achieve state-of-the-artforecast skill with much smaller networks.
  </details>

- **[Score-Based Metropolis-Hastings Algorithms](http://arxiv.org/abs/2501.00467v2)**  `arXiv:2501.00467`  
  _Ahmed Aloui, Ali Hasan, Juncheng Dong, Zihao Wu, Vahid Tarokh_
  <details><summary>Abstract</summary>
  In this paper, we introduce a new approach for integrating score-based modelswith the Metropolis-Hastings algorithm. While traditional score-based diffusionmodels excel in accurately learning the score function from data points, theylack an energy function, making the Metropolis-Hastings adjustment stepinaccessible. Consequently, the unadjusted Langevin algorithm is often used forsampling using estimated score functions. The lack of an energy function thenprevents the application of the Metropolis-adjusted Langevin algorithm andother Metropolis-Hastings methods, limiting the wealth of other algorithmsdeveloped that use acceptance functions. We address this limitation byintroducing a new loss function based on the \emph{detailed balance condition},allowing the estimation of the Metropolis-Hastings acceptance probabilitiesgiven a learned score function. We demonstrate the effectiveness of theproposed method for various scenarios, including sampling from heavy-taildistributions.
  </details>

- **[FreqX: Analyze the Attribution Methods in Another Domain](http://arxiv.org/abs/2411.18343v2)**  `arXiv:2411.18343`  
  _Zechen Liu, Feiyang Zhang, Wei Song, Xiang Li, Wei Wei_
  <details><summary>Abstract</summary>
  Personalized Federal learning(PFL) allows clients to cooperatively train apersonalized model without disclosing their private dataset. However, PFLsuffers from Non-IID, heterogeneous devices, lack of fairness, and unclearcontribution which urgently need the interpretability of deep learning model toovercome these challenges. These challenges proposed new demands forinterpretability. Low cost, privacy, and detailed information. There is nocurrent interpretability method satisfying them. In this paper, we propose anovel interpretability method \emph{FreqX} by introducing Signal Processing andInformation Theory. Our experiments show that the explanation results of FreqXcontain both attribution information and concept information. FreqX runs atleast 10 times faster than the baselines which contain concept information.
  </details>

- **[LSEAttention is All You Need for Time Series Forecasting](http://arxiv.org/abs/2410.23749v5)**  `arXiv:2410.23749`  
  _Dizhen Liang_
  <details><summary>Abstract</summary>
  Transformer-based architectures have achieved remarkable success in naturallanguage processing and computer vision. However, their performance inmultivariate long-term forecasting often falls short compared to simpler linearbaselines. Previous research has identified the traditional attention mechanismas a key factor limiting their effectiveness in this domain. To bridge thisgap, we introduce LATST, a novel approach designed to mitigate entropy collapseand training instability common challenges in Transformer-based time seriesforecasting. We rigorously evaluate LATST across multiple real-worldmultivariate time series datasets, demonstrating its ability to outperformexisting state-of-the-art Transformer models. Notably, LATST manages to achievecompetitive performance with fewer parameters than some linear models oncertain datasets, highlighting its efficiency and effectiveness.
  </details>

- **[RelChaNet: Neural Network Feature Selection using Relative Change Scores](http://arxiv.org/abs/2410.02344v2)**  `arXiv:2410.02344`  
  _Felix Zimmer_
  <details><summary>Abstract</summary>
  There is an ongoing effort to develop feature selection algorithms to improveinterpretability, reduce computational resources, and minimize overfitting inpredictive models. Neural networks stand out as architectures on which to buildfeature selection methods, and recently, neuron pruning and regrowth haveemerged from the sparse neural network literature as promising new tools. Weintroduce RelChaNet, a novel and lightweight supervised feature selectionalgorithm that uses neuron pruning and regrowth in the input layer of a denseneural network. For neuron pruning, a gradient sum metric measures the relativechange induced in a network after a feature enters, while neurons are randomlyregrown. We also propose an extension that adapts the size of the input layerat runtime. Extensive experiments on 13 different datasets show that ourapproach generally outperforms the current state-of-the-art methods, and inparticular improves the average accuracy by 2% on the MNIST dataset. Our codeis available at https://github.com/flxzimmer/relchanet.
  </details>

- **[The impact of internal variability on benchmarking deep learning climate emulators](http://arxiv.org/abs/2408.05288v2)**  `arXiv:2408.05288`  
  _Bj√∂rn L√ºtjens, Raffaele Ferrari, Duncan Watson-Parris, Noelle Selin_
  <details><summary>Abstract</summary>
  Full-complexity Earth system models (ESMs) are computationally veryexpensive, limiting their use in exploring the climate outcomes of multipleemission pathways. More efficient emulators that approximate ESMs can directlymap emissions onto climate outcomes, and benchmarks are being used to evaluatetheir accuracy on standardized tasks and datasets. We investigate a popularbenchmark in data-driven climate emulation, ClimateBench, on which deeplearning-based emulators are currently achieving the best performance. Wecompare these deep learning emulators with a linear regression-based emulator,akin to pattern scaling, and show that it outperforms the incumbent100M-parameter deep learning foundation model, ClimaX, on 3 out of 4regionally-resolved climate variables, notably surface temperature andprecipitation. While emulating surface temperature is expected to bepredominantly linear, this result is surprising for emulating precipitation.Precipitation is a much more noisy variable, and we show that deep learningemulators can overfit to internal variability noise at low frequencies,degrading their performance in comparison to a linear emulator. We address theissue of overfitting by increasing the number of climate simulations peremission pathway (from 3 to 50) and updating the benchmark targets with therespective ensemble averages from the MPI-ESM1.2-LR model. Using the newtargets, we show that linear pattern scaling continues to be more accurate ontemperature, but can be outperformed by a deep learning-based technique foremulating precipitation. We publish our code and data atgithub.com/blutjens/climate-emulator.
  </details>

- **[Backdoor Graph Condensation](http://arxiv.org/abs/2407.11025v4)**  `arXiv:2407.11025`  
  _Jiahao Wu, Ning Lu, Zeiyu Dai, Kun Wang, Wenqi Fan, Shengcai Liu, et al._
  <details><summary>Abstract</summary>
  Graph condensation has recently emerged as a prevalent technique to improvethe training efficiency for graph neural networks (GNNs). It condenses a largegraph into a small one such that a GNN trained on this small synthetic graphcan achieve comparable performance to a GNN trained on the large graph.However, while existing graph condensation studies mainly focus on the besttrade-off between graph size and the GNNs' performance (model utility), theyoverlook the security issues of graph condensation. To bridge this gap, wefirst explore backdoor attack against the GNNs trained on the condensed graphs.  We introduce an effective backdoor attack against graph condensation, termedBGC. This attack aims to (1) preserve the condensed graph quality despitetrigger injection, and (2) ensure trigger efficacy through the condensationprocess, achieving a high attack success rate. Specifically, BGC consistentlyupdates triggers during condensation and targets representative nodes forpoisoning. Extensive experiments demonstrate the effectiveness of our attack.BGC achieves a high attack success rate (close to 1.0) and good model utilityin all cases. Furthermore, the results against multiple defense methodsdemonstrate BGC's resilience under their defenses. Finally, we analyze the keyhyperparameters that influence the attack performance. Our code is availableat: https://github.com/JiahaoWuGit/BGC.
  </details>

- **[Tackling Copyright Issues in AI Image Generation Through Originality Estimation and Genericization](http://arxiv.org/abs/2406.03341v7)**  `arXiv:2406.03341`  
  _Hiroaki Chiba-Okabe, Weijie J. Su_
  <details><summary>Abstract</summary>
  The rapid progress of generative AI technology has sparked significantcopyright concerns, leading to numerous lawsuits filed against AI developers.Notably, generative AI's capacity for generating images of copyrightedcharacters has been well documented in the literature, and while varioustechniques for mitigating copyright issues have been studied, significant risksremain. Here, we propose a genericization method that modifies the outputs of agenerative model to make them more generic and less likely to imitatedistinctive features of copyrighted materials. To achieve this, we introduce ametric for quantifying the level of originality of data, estimated by drawingsamples from a generative model, and applied in the genericization process. Asa practical implementation, we introduce PREGen (Prompt Rewriting-EnhancedGenericization), which combines our genericization method with an existingmitigation technique. Compared to the existing method, PREGen reduces thelikelihood of generating copyrighted characters by more than half when thenames of copyrighted characters are used as the prompt. Additionally, whilegenerative models can produce copyrighted characters even when their names arenot directly mentioned in the prompt, PREGen almost entirely prevents thegeneration of such characters in these cases. Ultimately, this study advancescomputational approaches for quantifying and strengthening copyrightprotection, thereby providing practical methodologies to promote responsiblegenerative AI development.
  </details>

- **[Accelerated Smoothing: A Scalable Approach to Randomized Smoothing](http://arxiv.org/abs/2402.07498v2)**  `arXiv:2402.07498`  
  _Devansh Bhardwaj, Kshitiz Kaushik, Sarthak Gupta_
  <details><summary>Abstract</summary>
  Randomized smoothing has emerged as a potent certifiable defense againstadversarial attacks by employing smoothing noises from specific distributionsto ensure the robustness of a smoothed classifier. However, the utilization ofMonte Carlo sampling in this process introduces a compute-intensive element,which constrains the practicality of randomized smoothing on a larger scale. Toaddress this limitation, we propose a novel approach that replaces Monte Carlosampling with the training of a surrogate neural network. Through extensiveexperimentation in various settings, we demonstrate the efficacy of ourapproach in approximating the smoothed classifier with remarkable precision.Furthermore, we demonstrate that our approach significantly accelerates therobust radius certification process, providing nearly $600$X improvement incomputation time, overcoming the computational bottlenecks associated withtraditional randomized smoothing.
  </details>

- **[Implicit Bias and Fast Convergence Rates for Self-attention](http://arxiv.org/abs/2402.05738v2)**  `arXiv:2402.05738`  
  _Bhavya Vasudeva, Puneesh Deora, Christos Thrampoulidis_
  <details><summary>Abstract</summary>
  We study the fundamental optimization principles of self-attention, thedefining mechanism of transformers, by analyzing the implicit bias ofgradient-based optimizers in training a self-attention layer with a lineardecoder in binary classification. Building on prior studies in linear logisticregression, recent findings demonstrate that the key-query matrix $W_t$ fromgradient-descent (GD) converges in direction towards $W_{mm}$, which maximizesthe margin between optimal and non-optimal tokens across sequences. However,this convergence is local, dependent on initial conditions, only holdsasymptotically as the number of iterations increases, and leaves questionsabout the potential benefits of adaptive step-size rules unaddressed. To bridgethis gap, we first establish scenarios for which convergence is provably\emph{global}. We then analyze two adaptive step-size strategies: normalized GDand Polyak step-size, demonstrating \emph{finite-time} convergence rates for$W_t$ to $W_{mm}$, and quantifying the sparsification rate of the attentionmap. These findings not only show that these strategies can accelerateparameter convergence over standard GD in a non-convex setting but also deepenthe understanding of the implicit bias in self-attention, linking it moreclosely to the phenomena observed in linear logistic regression despite itsintricate non-convex nature.
  </details>

- **[Model Selection for Inverse Reinforcement Learning via Structural Risk Minimization](http://arxiv.org/abs/2312.16566v2)**  `arXiv:2312.16566`  
  _Chendi Qu, Jianping He, Xiaoming Duan, Jiming Chen_
  <details><summary>Abstract</summary>
  Inverse reinforcement learning (IRL) usually assumes the reward functionmodel is pre-specified as a weighted sum of features and estimates theweighting parameters only. However, how to select features and determine aproper reward model is nontrivial and experience-dependent. A simplistic modelis less likely to contain the ideal reward function, while a model with highcomplexity leads to substantial computation cost and potential overfitting.This paper addresses this trade-off in the model selection for IRL problems byintroducing the structural risk minimization (SRM) framework from statisticallearning. SRM selects an optimal reward function class from a hypothesis setminimizing both estimation error and model complexity. To formulate an SRMscheme for IRL, we estimate the policy gradient from given demonstration as theempirical risk, and establish the upper bound of Rademacher complexity as themodel penalty of hypothesis function classes. The SRM learning guarantee isfurther presented. In particular, we provide the explicit form for the linearweighted sum setting. Simulations demonstrate the performance and efficiency ofour algorithm.
  </details>

- **[ADMM Algorithms for Residual Network Training: Convergence Analysis and Parallel Implementation](http://arxiv.org/abs/2310.15334v2)**  `arXiv:2310.15334`  
  _Jintao Xu, Yifei Li, Wenxun Xing_
  <details><summary>Abstract</summary>
  We propose both serial and parallel proximal (linearized) alternatingdirection method of multipliers (ADMM) algorithms for training residual neuralnetworks. In contrast to backpropagation-based approaches, our methodsinherently mitigate the exploding gradient issue and are well-suited forparallel and distributed training through regional updates. Theoretically, weprove that the proposed algorithms converge at an R-linear (sublinear) rate forboth the iteration points and the objective function values. These results holdwithout imposing stringent constraints on network width, depth, or trainingdata size. Furthermore, we theoretically analyze our parallel/distributed ADMMalgorithms, highlighting their reduced time complexity and lower per-nodememory consumption. To facilitate practical deployment, we develop a controlprotocol for parallel ADMM implementation using Python's multiprocessing andinterprocess communication. Experimental results validate the proposed ADMMalgorithms, demonstrating rapid and stable convergence, improved performance,and high computational efficiency. Finally, we highlight the improvedscalability and efficiency achieved by our parallel ADMM training strategy.
  </details>

- **[Interpretable Few-shot Learning with Online Attribute Selection](http://arxiv.org/abs/2211.09107v3)**  `arXiv:2211.09107`  
  _Mohammad Reza Zarei, Majid Komeili_
  <details><summary>Abstract</summary>
  Few-shot learning (FSL) presents a challenging learning problem in which onlya few samples are available for each class. Decision interpretation is moreimportant in few-shot classification due to a greater chance of error comparedto traditional classification. However, the majority of the previous FSLmethods are black-box models. In this paper, we propose an inherentlyinterpretable model for FSL based on human-friendly attributes. Previously,human-friendly attributes have been utilized to train models with the potentialfor human interaction and interpretability. However, such approaches are notdirectly extendible to the few-shot classification scenario. Moreover, wepropose an online attribute selection mechanism to effectively filter outirrelevant attributes in each episode. The attribute selection mechanismimproves accuracy and helps with interpretability by reducing the number ofattributes that participate in each episode. We further propose a mechanismthat automatically detects the episodes where the pool of availablehuman-friendly attributes is insufficient, and subsequently augments it byengaging some learned unknown attributes. We demonstrate that the proposedmethod achieves results on par with black-box few-shot learning models on fourwidely used datasets. We also empirically evaluate the level of decisionalignment between different models and human understanding and show that ourmodel outperforms the comparison methods based on this criterion.
  </details>

[‚Üë Back to Top](#-full-archive)

</details>

### Multiagent Systems üåê

<details open><summary>Click to Collapse</summary>

- **[A Constrained Multi-Agent Reinforcement Learning Approach to Autonomous Traffic Signal Control](http://arxiv.org/abs/2503.23626v1)**  `arXiv:2503.23626`  
  _Anirudh Satheesh, Keenan Powell_
  <details><summary>Abstract</summary>
  Traffic congestion in modern cities is exacerbated by the limitations oftraditional fixed-time traffic signal systems, which fail to adapt to dynamictraffic patterns. Adaptive Traffic Signal Control (ATSC) algorithms haveemerged as a solution by dynamically adjusting signal timing based on real-timetraffic conditions. However, the main limitation of such methods is that theyare not transferable to environments under real-world constraints, such asbalancing efficiency, minimizing collisions, and ensuring fairness acrossintersections. In this paper, we view the ATSC problem as a constrainedmulti-agent reinforcement learning (MARL) problem and propose a novel algorithmnamed Multi-Agent Proximal Policy Optimization with Lagrange Cost Estimator(MAPPO-LCE) to produce effective traffic signal control policies. Our approachintegrates the Lagrange multipliers method to balance rewards and constraints,with a cost estimator for stable adjustment. We also introduce threeconstraints on the traffic network: GreenTime, GreenSkip, and PhaseSkip, whichpenalize traffic policies that do not conform to real-world scenarios. Ourexperimental results on three real-world datasets demonstrate that MAPPO-LCEoutperforms three baseline MARL algorithms by across all environments andtraffic constraints (improving on MAPPO by 12.60%, IPPO by 10.29%, and QTRAN by13.10%). Our results show that constrained MARL is a valuable tool for trafficplanners to deploy scalable and efficient ATSC methods in real-world trafficnetworks. We provide code at https://github.com/Asatheesh6561/MAPPO-LCE.
  </details>

- **[Teams of LLM Agents can Exploit Zero-Day Vulnerabilities](http://arxiv.org/abs/2406.01637v2)**  `arXiv:2406.01637`  
  _Yuxuan Zhu, Antony Kellermann, Akul Gupta, Philip Li, Richard Fang, Rohan Bindu, et al._
  <details><summary>Abstract</summary>
  LLM agents have become increasingly sophisticated, especially in the realm ofcybersecurity. Researchers have shown that LLM agents can exploit real-worldvulnerabilities when given a description of the vulnerability and toycapture-the-flag problems. However, these agents still perform poorly onreal-world vulnerabilities that are unknown to the agent ahead of time(zero-day vulnerabilities).  In this work, we show that teams of LLM agents can exploit real-world,zero-day vulnerabilities. Prior agents struggle with exploring many differentvulnerabilities and long-range planning when used alone. To resolve this, weintroduce HPTSA, a system of agents with a planning agent that can launchsubagents. The planning agent explores the system and determines whichsubagents to call, resolving long-term planning issues when trying differentvulnerabilities. We construct a benchmark of 14 real-world vulnerabilities andshow that our team of agents improve over prior agent frameworks by up to 4.3X.
  </details>

[‚Üë Back to Top](#-full-archive)

</details>

### Robotics ü§ñ

<details open><summary>Click to Collapse</summary>

- **[Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation](http://arxiv.org/abs/2503.24361v1)**  `arXiv:2503.24361`  
  _Abhiram Maddukuri, Zhenyu Jiang, Lawrence Yunliang Chen, Soroush Nasiriany, Yuqi Xie, Yu Fang, et al._
  <details><summary>Abstract</summary>
  Large real-world robot datasets hold great potential to train generalistrobot models, but scaling real-world human data collection is time-consumingand resource-intensive. Simulation has great potential in supplementinglarge-scale data, especially with recent advances in generative AI andautomated data generation tools that enable scalable creation of robot behaviordatasets. However, training a policy solely in simulation and transferring itto the real world often demands substantial human effort to bridge the realitygap. A compelling alternative is to co-train the policy on a mixture ofsimulation and real-world datasets. Preliminary studies have recently shownthis strategy to substantially improve the performance of a policy over onetrained on a limited amount of real-world data. Nonetheless, the communitylacks a systematic understanding of sim-and-real co-training and what it takesto reap the benefits of simulation data for real-robot learning. This workpresents a simple yet effective recipe for utilizing simulation data to solvevision-based robotic manipulation tasks. We derive this recipe fromcomprehensive experiments that validate the co-training strategy on varioussimulation and real-world datasets. Using two domains--a robot arm and ahumanoid--across diverse tasks, we demonstrate that simulation data can enhancereal-world task performance by an average of 38%, even with notable differencesbetween the simulation and real-world data. Videos and additional results canbe found at https://co-training.github.io/
  </details>

- **[Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for Pickup-and-Delivery Tasks](http://arxiv.org/abs/2503.24325v1)**  `arXiv:2503.24325`  
  _Daniel Garces, Stephanie Gil_
  <details><summary>Abstract</summary>
  We consider a multi-robot setting, where we have a fleet of multi-capacityautonomous robots that must service spatially distributed pickup-and-deliveryrequests with fixed maximum wait times. Requests can be either scheduled aheadof time or they can enter the system in real-time. In this setting, stabilityfor a routing policy is defined as the cost of the policy being uniformlybounded over time. Most previous work either solve the problem offline totheoretically maintain stability or they consider dynamically arriving requestsat the expense of the theoretical guarantees on stability. In this paper, weaim to bridge this gap by proposing a novel proactive rollout-based routingframework that adapts to real-time demand while still provably maintaining thestability of the learned routing policy. We derive provable stabilityguarantees for our method by proposing a fleet sizing algorithm that obtains asufficiently large fleet that ensures stability by construction. To validateour theoretical results, we consider a case study on real ride requests forHarvard's evening Van System. We also evaluate the performance of our frameworkusing the currently deployed smaller fleet size. In this smaller setup, wecompare against the currently deployed routing algorithm, greedy heuristics,and Monte-Carlo-Tree-Search-based algorithms. Our empirical results show thatour framework maintains stability when we use the sufficiently large fleet sizefound in our theoretical results. For the smaller currently deployed fleetsize, our method services 6% more requests than the closest baseline whilereducing median passenger wait times by 33%.
  </details>

- **[AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World](http://arxiv.org/abs/2503.24278v1)**  `arXiv:2503.24278`  
  _Zhiyuan Zhou, Pranav Atreya, You Liang Tan, Karl Pertsch, Sergey Levine_
  <details><summary>Abstract</summary>
  Scalable and reproducible policy evaluation has been a long-standingchallenge in robot learning. Evaluations are critical to assess progress andbuild better policies, but evaluation in the real world, especially at a scalethat would provide statistically reliable results, is costly in terms of humantime and hard to obtain. Evaluation of increasingly generalist robot policiesrequires an increasingly diverse repertoire of evaluation environments, makingthe evaluation bottleneck even more pronounced. To make real-world evaluationof robotic policies more practical, we propose AutoEval, a system toautonomously evaluate generalist robot policies around the clock with minimalhuman intervention. Users interact with AutoEval by submitting evaluation jobsto the AutoEval queue, much like how software jobs are submitted with a clusterscheduling system, and AutoEval will schedule the policies for evaluationwithin a framework supplying automatic success detection and automatic sceneresets. We show that AutoEval can nearly fully eliminate human involvement inthe evaluation process, permitting around the clock evaluations, and theevaluation results correspond closely to ground truth evaluations conducted byhand. To facilitate the evaluation of generalist policies in the roboticscommunity, we provide public access to multiple AutoEval scenes in the popularBridgeData robot setup with WidowX robot arms. In the future, we hope thatAutoEval scenes can be set up across institutions to form a diverse anddistributed evaluation network.
  </details>

- **[Pseudo-Random UAV Test Generation Using Low-Fidelity Path Simulator](http://arxiv.org/abs/2503.24172v1)**  `arXiv:2503.24172`  
  _Anas Shrinah, Kerstin Eder_
  <details><summary>Abstract</summary>
  Simulation-based testing provides a safe and cost-effective environment forverifying the safety of Uncrewed Aerial Vehicles (UAVs). However, simulationcan be resource-consuming, especially when High-Fidelity Simulators (HFS) areused. To optimise simulation resources, we propose a pseudo-random testgenerator that uses a Low-Fidelity Simulator (LFS) to estimate UAV flightpaths. This work simplifies the PX4 autopilot HFS to develop a LFS, whichoperates one order of magnitude faster than the HFS.Test cases predicted tocause safety violations in the LFS are subsequently validated using the HFS.
  </details>

- **[HACTS: a Human-As-Copilot Teleoperation System for Robot Learning](http://arxiv.org/abs/2503.24070v1)**  `arXiv:2503.24070`  
  _Zhiyuan Xu, Yinuo Zhao, Kun Wu, Ning Liu, Junjie Ji, Zhengping Che, et al._
  <details><summary>Abstract</summary>
  Teleoperation is essential for autonomous robot learning, especially inmanipulation tasks that require human demonstrations or corrections. However,most existing systems only offer unilateral robot control and lack the abilityto synchronize the robot's status with the teleoperation hardware, preventingreal-time, flexible intervention. In this work, we introduce HACTS(Human-As-Copilot Teleoperation System), a novel system that establishesbilateral, real-time joint synchronization between a robot arm andteleoperation hardware. This simple yet effective feedback mechanism, akin to asteering wheel in autonomous vehicles, enables the human copilot to interveneseamlessly while collecting action-correction data for future learning.Implemented using 3D-printed components and low-cost, off-the-shelf motors,HACTS is both accessible and scalable. Our experiments show that HACTSsignificantly enhances performance in imitation learning (IL) and reinforcementlearning (RL) tasks, boosting IL recovery capabilities and data efficiency, andfacilitating human-in-the-loop RL. HACTS paves the way for more effective andinteractive human-robot collaboration and data-collection, advancing thecapabilities of robot manipulation.
  </details>

- **[Toward Anxiety-Reducing Pocket Robots for Children](http://arxiv.org/abs/2503.24041v1)**  `arXiv:2503.24041`  
  _Morten Roed Frederiksen, Kasper St√∏y, Maja Matariƒá_
  <details><summary>Abstract</summary>
  A common denominator for most therapy treatments for children who suffer froman anxiety disorder is daily practice routines to learn techniques needed toovercome anxiety. However, applying those techniques while experiencing anxietycan be highly challenging. This paper presents the design, implementation, andpilot study of a tactile hand-held pocket robot AffectaPocket, designed to workalongside therapy as a focus object to facilitate coping during an anxietyattack. The robot does not require daily practice to be used, has a small formfactor, and has been designed for children 7 to 12 years old. The pocket robotworks by sensing when it is being held and attempts to shift the child's focusby presenting them with a simple three-note rhythm-matching game. We conducteda pilot study of the pocket robot involving four children aged 7 to 10 years,and then a main study with 18 children aged 6 to 8 years; neither studyinvolved children with anxiety. Both studies aimed to assess the reliability ofthe robot's sensor configuration, its design, and the effectiveness of the usertutorial. The results indicate that the morphology and sensor setup performedadequately and the tutorial process enabled the children to use the robot withlittle practice. This work demonstrates that the presented pocket robot couldrepresent a step toward developing low-cost accessible technologies to helpchildren suffering from anxiety disorders.
  </details>

- **[A Reactive Framework for Whole-Body Motion Planning of Mobile Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic Programmi](http://arxiv.org/abs/2503.23975v1)**  `arXiv:2503.23975`  
  _Chenyu Zhang, Shiying Sun, Kuan Liu, Chuanbao Zhou, Xiaoguang Zhao, Min Tan, et al._
  <details><summary>Abstract</summary>
  As an important branch of embodied artificial intelligence, mobilemanipulators are increasingly applied in intelligent services, but theirredundant degrees of freedom also limit efficient motion planning in clutteredenvironments. To address this issue, this paper proposes a hybrid learning andoptimization framework for reactive whole-body motion planning of mobilemanipulators. We develop the Bayesian distributional soft actor-critic(Bayes-DSAC) algorithm to improve the quality of value estimation and theconvergence performance of the learning. Additionally, we introduce a quadraticprogramming method constrained by the signed distance field to enhance thesafety of the obstacle avoidance motion. We conduct experiments and makecomparison with standard benchmark. The experimental results verify that ourproposed framework significantly improves the efficiency of reactive whole-bodymotion planning, reduces the planning time, and improves the success rate ofmotion planning. Additionally, the proposed reinforcement learning methodensures a rapid learning process in the whole-body planning task. The novelframework allows mobile manipulators to adapt to complex environments moresafely and efficiently.
  </details>

- **[MAER-Nav: Bidirectional Motion Learning Through Mirror-Augmented Experience Replay for Robot Navigation](http://arxiv.org/abs/2503.23908v1)**  `arXiv:2503.23908`  
  _Shanze Wang, Mingao Tan, Zhibo Yang, Biao Huang, Xiaoyu Shen, Hailong Huang, et al._
  <details><summary>Abstract</summary>
  Deep Reinforcement Learning (DRL) based navigation methods have demonstratedpromising results for mobile robots, but suffer from limited action flexibilityin confined spaces. Conventional DRL approaches predominantly learnforward-motion policies, causing robots to become trapped in complexenvironments where backward maneuvers are necessary for recovery. This paperpresents MAER-Nav (Mirror-Augmented Experience Replay for Robot Navigation), anovel framework that enables bidirectional motion learning without requiringexplicit failure-driven hindsight experience replay or reward functionmodifications. Our approach integrates a mirror-augmented experience replaymechanism with curriculum learning to generate synthetic backward navigationexperiences from successful trajectories. Experimental results in bothsimulation and real-world environments demonstrate that MAER-Nav significantlyoutperforms state-of-the-art methods while maintaining strong forwardnavigation capabilities. The framework effectively bridges the gap between thecomprehensive action space utilization of traditional planning methods and theenvironmental adaptability of learning-based approaches, enabling robustnavigation in scenarios where conventional DRL methods consistently fail.
  </details>

- **[Less is More: Contextual Sampling for Nonlinear Data-Enabled Predictive Control](http://arxiv.org/abs/2503.23890v1)**  `arXiv:2503.23890`  
  _Julius Beerwerth, Bassam Alrifaee_
  <details><summary>Abstract</summary>
  Data-enabled Predictive Control (DeePC) is a powerful data-driven approachfor predictive control without requiring an explicit system model. However, itshigh computational cost limits its applicability to real-time robotic systems.For robotic applications such as motion planning and trajectory tracking,real-time control is crucial. Nonlinear DeePC either relies on large datasetsor learning the nonlinearities to ensure predictive accuracy, leading to highcomputational complexity. This work introduces contextual sampling, a noveldata selection strategy to handle nonlinearities for DeePC by dynamicallyselecting the most relevant data at each time step. By reducing the datasetsize while preserving prediction accuracy, our method improves computationalefficiency, of DeePC for real-time robotic applications. We validate ourapproach for autonomous vehicle motion planning. For a dataset size of 100sub-trajectories, Contextual sampling DeePC reduces tracking error by 53.2 %compared to Leverage Score sampling. Additionally, Contextual sampling reducesmax computation time by 87.2 % compared to using the full dataset of 491sub-trajectories while achieving comparable tracking performance. These resultshighlight the potential of Contextual sampling to enable real-time, data-drivencontrol for robotic systems.
  </details>

- **[ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos](http://arxiv.org/abs/2503.23877v1)**  `arXiv:2503.23877`  
  _Junyao Shi, Zhuolun Zhao, Tianyou Wang, Ian Pedroza, Amy Luo, Jie Wang, et al._
  <details><summary>Abstract</summary>
  Many recent advances in robotic manipulation have come through imitationlearning, yet these rely largely on mimicking a particularly hard-to-acquireform of demonstrations: those collected on the same robot in the same room withthe same objects as the trained policy must handle at test time. In contrast,large pre-recorded human video datasets demonstrating manipulation skillsin-the-wild already exist, which contain valuable information for robots. Is itpossible to distill a repository of useful robotic skill policies out of suchdata without any additional requirements on robot-specific demonstrations orexploration? We present the first such system ZeroMimic, that generatesimmediately deployable image goal-conditioned skill policies for several commoncategories of manipulation tasks (opening, closing, pouring, pick&place,cutting, and stirring) each capable of acting upon diverse objects and acrossdiverse unseen task setups. ZeroMimic is carefully designed to exploit recentadvances in semantic and geometric visual understanding of human videos,together with modern grasp affordance detectors and imitation policy classes.After training ZeroMimic on the popular EpicKitchens dataset of ego-centrichuman videos, we evaluate its out-of-the-box performance in varied real-worldand simulated kitchen settings with two different robot embodiments,demonstrating its impressive abilities to handle these varied tasks. To enableplug-and-play reuse of ZeroMimic policies on other task setups and robots, werelease software and policy checkpoints of our skill policies.
  </details>

- **[GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via Language Models](http://arxiv.org/abs/2503.23875v1)**  `arXiv:2503.23875`  
  _Wenkang Ji, Huaben Chen, Mingyang Chen, Guobin Zhu, Lufeng Xu, Roderich Gro√ü, et al._
  <details><summary>Abstract</summary>
  The development of control policies for multi-robot systems traditionallyfollows a complex and labor-intensive process, often lacking the flexibility toadapt to dynamic tasks. This has motivated research on methods to automaticallycreate control policies. However, these methods require iterative processes ofmanually crafting and refining objective functions, thereby prolonging thedevelopment cycle. This work introduces \textit{GenSwarm}, an end-to-end systemthat leverages large language models to automatically generate and deploycontrol policies for multi-robot tasks based on simple user instructions innatural language. As a multi-language-agent system, GenSwarm achieves zero-shotlearning, enabling rapid adaptation to altered or unseen tasks. The white-boxnature of the code policies ensures strong reproducibility andinterpretability. With its scalable software and hardware architectures,GenSwarm supports efficient policy deployment on both simulated and real-worldmulti-robot systems, realizing an instruction-to-execution end-to-endfunctionality that could prove valuable for robotics specialists andnon-specialists alike.The code of the proposed GenSwarm system is availableonline: https://github.com/WindyLab/GenSwarm.
  </details>

- **[Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as Feedback Enables Pure Simulation Learning](http://arxiv.org/abs/2503.23835v1)**  `arXiv:2503.23835`  
  _Yifei Yang, Lu Chen, Zherui Song, Yenan Chen, Wentao Sun, Zhongxiang Zhou, et al._
  <details><summary>Abstract</summary>
  Grasp-based manipulation tasks are fundamental to robots interacting withtheir environments, yet gripper state ambiguity significantly reduces therobustness of imitation learning policies for these tasks. Data-drivensolutions face the challenge of high real-world data costs, while simulationdata, despite its low costs, is limited by the sim-to-real gap. We identify theroot cause of gripper state ambiguity as the lack of tactile feedback. Toaddress this, we propose a novel approach employing pseudo-tactile as feedback,inspired by the idea of using a force-controlled gripper as a tactile sensor.This method enhances policy robustness without additional data collection andhardware involvement, while providing a noise-free binary gripper stateobservation for the policy and thus facilitating pure simulation learning tounleash the power of simulation. Experimental results across three real-worldgrasp-based tasks demonstrate the necessity, effectiveness, and efficiency ofour approach.
  </details>

- **[Trajectory Planning for Automated Driving using Target Funnels](http://arxiv.org/abs/2503.23795v1)**  `arXiv:2503.23795`  
  _Benjamin Bogenberger, Johannes B√ºrger, Vladislav Nenchev_
  <details><summary>Abstract</summary>
  Self-driving vehicles rely on sensory input to monitor their surroundings andcontinuously adapt to the most likely future road course. Predictive trajectoryplanning is based on snapshots of the (uncertain) road course as a key input.Under noisy perception data, estimates of the road course can varysignificantly, leading to indecisive and erratic steering behavior. To overcomethis issue, this paper introduces a predictive trajectory planning algorithmwith a novel objective function: instead of targeting a single referencetrajectory based on the most likely road course, tracking a series of targetreference sets, called a target funnel, is considered. The proposed planningalgorithm integrates probabilistic information about the road course, and thusimplicitly considers regular updates to road perception. Our solution isassessed in a case study using real driving data collected from a prototypevehicle. The results demonstrate that the algorithm maintains tracking accuracyand substantially reduces undesirable steering commands in the presence ofnoisy road perception, achieving a 56% reduction in input costs compared to acertainty equivalent formulation.
  </details>

- **[Towards a cognitive architecture to enable natural language interaction in co-constructive task learning](http://arxiv.org/abs/2503.23760v1)**  `arXiv:2503.23760`  
  _Manuel Scheibl, Birte Richter, Alissa M√ºller, Michael Beetz, Britta Wrede_
  <details><summary>Abstract</summary>
  This research addresses the question, which characteristics a cognitivearchitecture must have to leverage the benefits of natural language inCo-Constructive Task Learning (CCTL). To provide context, we first discussInteractive Task Learning (ITL), the mechanisms of the human memory system, andthe significance of natural language and multi-modality. Next, we examine thecurrent state of cognitive architectures, analyzing their capabilities toinform a concept of CCTL grounded in multiple sources. We then integrateinsights from various research domains to develop a unified framework. Finally,we conclude by identifying the remaining challenges and requirements necessaryto achieve CCTL in Human-Robot Interaction (HRI).
  </details>

- **[Towards Benchmarking and Assessing the Safety and Robustness of Autonomous Driving on Safety-critical Scenarios](http://arxiv.org/abs/2503.23708v1)**  `arXiv:2503.23708`  
  _Jingzheng Li, Xianglong Liu, Shikui Wei, Zhijun Chen, Bing Li, Qing Guo, et al._
  <details><summary>Abstract</summary>
  Autonomous driving has made significant progress in both academia andindustry, including performance improvements in perception task and thedevelopment of end-to-end autonomous driving systems. However, the safety androbustness assessment of autonomous driving has not received sufficientattention. Current evaluations of autonomous driving are typically conducted innatural driving scenarios. However, many accidents often occur in edge cases,also known as safety-critical scenarios. These safety-critical scenarios aredifficult to collect, and there is currently no clear definition of whatconstitutes a safety-critical scenario. In this work, we explore the safety androbustness of autonomous driving in safety-critical scenarios. First, weprovide a definition of safety-critical scenarios, including static trafficscenarios such as adversarial attack scenarios and natural distribution shifts,as well as dynamic traffic scenarios such as accident scenarios. Then, wedevelop an autonomous driving safety testing platform to comprehensivelyevaluate autonomous driving systems, encompassing not only the assessment ofperception modules but also system-level evaluations. Our work systematicallyconstructs a safety verification process for autonomous driving, providingtechnical support for the industry to establish standardized test framework andreduce risks in real-world road deployment.
  </details>

- **[Grasping a Handful: Sequential Multi-Object Dexterous Grasp Generation](http://arxiv.org/abs/2503.22370v2)**  `arXiv:2503.22370`  
  _Haofei Lu, Yifei Dong, Zehang Weng, Jens Lundell, Danica Kragic_
  <details><summary>Abstract</summary>
  We introduce the sequential multi-object robotic grasp sampling algorithmSeqGrasp that can robustly synthesize stable grasps on diverse objects usingthe robotic hand's partial Degrees of Freedom (DoF). We use SeqGrasp toconstruct the large-scale Allegro Hand sequential grasping dataset SeqDatasetand use it for training the diffusion-based sequential grasp generatorSeqDiffuser. We experimentally evaluate SeqGrasp and SeqDiffuser against thestate-of-the-art non-sequential multi-object grasp generation method MultiGraspin simulation and on a real robot. The experimental results demonstrate thatSeqGrasp and SeqDiffuser reach an 8.71%-43.33% higher grasp success rate thanMultiGrasp. Furthermore, SeqDiffuser is approximately 1000 times faster atgenerating grasps than SeqGrasp and MultiGrasp.
  </details>

- **[CALMM-Drive: Confidence-Aware Autonomous Driving with Large Multimodal Model](http://arxiv.org/abs/2412.04209v2)**  `arXiv:2412.04209`  
  _Ruoyu Yao, Yubin Wang, Haichao Liu, Rui Yang, Zengqi Peng, Lei Zhu, et al._
  <details><summary>Abstract</summary>
  Decision-making and motion planning constitute critical components forensuring the safety and efficiency of autonomous vehicles (AVs). Existingmethodologies typically adopt two paradigms: decision then planning orgeneration then scoring. However, the former architecture often suffers fromdecision-planning misalignment that incurs risky situations. Meanwhile, thelatter struggles to balance short-term operational metrics (e.g., immediatemotion smoothness) with long-term tactical goals (e.g., route efficiency),resulting in myopic or overly conservative behaviors. To address these issues,we introduce CALMM-Drive, a novel Confidence-Aware Large Multimodal Model (LMM)empowered Autonomous Driving framework. Our approach integrates drivingtask-oriented Chain-of-Thought (CoT) reasoning coupled with Top-K confidenceelicitation, which facilitates high-level reasoning to generate multiplecandidate decisions with their confidence levels. Furthermore, we propose anovel planning module that integrates a diffusion model for trajectorygeneration and a hierarchical refinement process to find the optimaltrajectory. This framework enables the selection over trajectory candidatesaccounting for both low-level solution quality and high-level tacticalconfidence, which avoids the risks within one-shot decisions and overcomes thelimitations in short-sighted scoring mechanisms. Comprehensive evaluations innuPlan closed-loop simulation environments demonstrate the competitiveperformance of CALMM-Drive across both common and long-tail benchmarks,showcasing a significant advancement in the integration of uncertainty inLMM-empowered AVs. The code will be released upon acceptance.
  </details>

- **[Dynamic High-Order Control Barrier Functions with Diffuser for Safety-Critical Trajectory Planning at Signal-Free Intersections](http://arxiv.org/abs/2412.00162v2)**  `arXiv:2412.00162`  
  _Di Chen, Ruiguo Zhong, Kehua Chen, Zhiwei Shang, Meixin Zhu, Edward Chung_
  <details><summary>Abstract</summary>
  Planning safe and efficient trajectories through signal-free intersectionspresents significant challenges for autonomous vehicles (AVs), particularly indynamic, multi-task environments with unpredictable interactions and anincreased possibility of conflicts. This study aims to address these challengesby developing a unified, robust, adaptive framework to ensure safety andefficiency across three distinct intersection movements: left-turn, right-turn,and straight-ahead. Existing methods often struggle to reliably ensure safetyand effectively learn multi-task behaviors from demonstrations in suchenvironments. This study proposes a safety-critical planning method thatintegrates Dynamic High-Order Control Barrier Functions (DHOCBF) with adiffusion-based model, called Dynamic Safety-Critical Diffuser (DSC-Diffuser).The DSC-Diffuser leverages task-guided planning to enhance efficiency, allowingthe simultaneous learning of multiple driving tasks from real-world expertdemonstrations. Moreover, the incorporation of goal-oriented constraintssignificantly reduces displacement errors, ensuring precise trajectoryexecution. To further ensure driving safety in dynamic environments, theproposed DHOCBF framework dynamically adjusts to account for the movements ofsurrounding vehicles, offering enhanced adaptability and reduce theconservatism compared to traditional control barrier functions. Validityevaluations of DHOCBF, conducted through numerical simulations, demonstrate itsrobustness in adapting to variations in obstacle velocities, sizes,uncertainties, and locations, effectively maintaining driving safety across awide range of complex and uncertain scenarios. Comprehensive performanceevaluations demonstrate that DSC-Diffuser generates realistic, stable, andgeneralizable policies, providing flexibility and reliable safety assurance incomplex multi-task driving scenarios.
  </details>

- **[Robust Nonprehensile Object Transportation with Uncertain Inertial Parameters](http://arxiv.org/abs/2411.07079v3)**  `arXiv:2411.07079`  
  _Adam Heins, Angela P. Schoellig_
  <details><summary>Abstract</summary>
  We consider the nonprehensile object transportation task known as thewaiter's problem - in which a robot must move an object on a tray from onelocation to another - when the transported object has uncertain inertialparameters. In contrast to existing approaches that completely ignoreuncertainty in the inertia matrix or which only consider small parametererrors, we are interested in pushing the limits of the amount of inertialparameter uncertainty that can be handled. We first show how constraints thatare robust to inertial parameter uncertainty can be incorporated into anoptimization-based motion planning framework to transport objects while movingquickly. Next, we develop necessary conditions for the inertial parameters tobe realizable on a bounding shape based on moment relaxations, allowing us toverify whether a trajectory will violate the constraints for any realizableinertial parameters. Finally, we demonstrate our approach on a mobilemanipulator in simulations and real hardware experiments: our proposed robustconstraints consistently successfully transport a 56 cm tall object withsubstantial inertial parameter uncertainty in the real world, while thebaseline approaches drop the object while transporting it.
  </details>

- **[Fast Online Learning of CLiFF-maps in Changing Environments](http://arxiv.org/abs/2410.12237v2)**  `arXiv:2410.12237`  
  _Yufei Zhu, Andrey Rudenko, Luigi Palmieri, Lukas Heuer, Achim J. Lilienthal, Martin Magnusson_
  <details><summary>Abstract</summary>
  Maps of dynamics are effective representations of motion patterns learnedfrom prior observations, with recent research demonstrating their ability toenhance various downstream tasks such as human-aware robot navigation,long-term human motion prediction, and robot localization. Current advancementshave primarily concentrated on methods for learning maps of human flow inenvironments where the flow is static, i.e., not assumed to change over time.In this paper we propose an online update method of the CLiFF-map (an advancedmap of dynamics type that models motion patterns as velocity and orientationmixtures) to actively detect and adapt to human flow changes. As newobservations are collected, our goal is to update a CLiFF-map to effectivelyand accurately integrate them, while retaining relevant historic motionpatterns. The proposed online update method maintains a probabilisticrepresentation in each observed location, updating parameters by continuouslytracking sufficient statistics. In experiments using both synthetic andreal-world datasets, we show that our method is able to maintain accuraterepresentations of human motion dynamics, contributing to high performanceflow-compliant planning downstream tasks, while being orders of magnitudefaster than the comparable baselines.
  </details>

- **[Joint Moment Estimation for Hip Exoskeleton Control: A Generalized Moment Feature Generation Method](http://arxiv.org/abs/2410.00462v2)**  `arXiv:2410.00462`  
  _Yuanwen Zhang, Jingfeng Xiong, Haolan Xian, Chuheng Chen, Xinxing Chen, Chenglong Fu, et al._
  <details><summary>Abstract</summary>
  Hip joint moments during walking are the key foundation for hip exoskeletonassistance control. Most recent studies have shown estimating hip joint momentsinstantaneously offers a lot of advantages compared to generating assistivetorque profiles based on gait estimation, such as simple sensor requirementsand adaptability to variable walking speeds. However, existing joint momentestimation methods still suffer from a lack of personalization, leading toestimation accuracy degradation for new users. To address the challenges, thispaper proposes a hip joint moment estimation method based on generalized momentfeatures (GMF). A GMF generator is constructed to learn GMF of the joint momentwhich is invariant to individual variations while remaining decodable intojoint moments through a dedicated decoder. Utilizing this well-featuredrepresentation, a GRU-based neural network is used to predict GMF with jointkinematics data, which can easily be acquired by hip exoskeleton encoders. Theproposed estimation method achieves a root mean square error of 0.1180 Nm/kgunder 28 walking speed conditions on a treadmill dataset, improved by 6.5%compared to the model without body parameter fusion, and by 8.3% for theconventional fusion model with body parameter. Furthermore, the proposed methodwas employed on a hip exoskeleton with only encoder sensors and achieved anaverage 20.5% metabolic reduction (p<0.01) for users compared to assist-offcondition in level-ground walking.
  </details>

- **[Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-level Goal Decomposition](http://arxiv.org/abs/2409.19250v2)**  `arXiv:2409.19250`  
  _Minseo Kwon, Yaesol Kim, Young J. Kim_
  <details><summary>Abstract</summary>
  In robotic task planning, symbolic planners using rule-based representationslike PDDL are effective but struggle with long-sequential tasks in complicatedenvironments due to exponentially increasing search space. Meanwhile, LLM-basedapproaches, which are grounded in artificial neural networks, offer fasterinference and commonsense reasoning but suffer from lower success rates. Toaddress the limitations of the current symbolic (slow speed) or LLM-basedapproaches (low accuracy), we propose a novel neuro-symbolic task planner thatdecomposes complex tasks into subgoals using LLM and carries out task planningfor each subgoal using either symbolic or MCTS-based LLM planners, depending onthe subgoal complexity. This decomposition reduces planning time and improvessuccess rates by narrowing the search space and enabling LLMs to focus on moremanageable tasks. Our method significantly reduces planning time whilemaintaining high success rates across task planning domains, as well asreal-world and simulated robotics environments. More details are available athttp://graphics.ewha.ac.kr/LLMTAMP/.
  </details>

- **[Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models](http://arxiv.org/abs/2409.16663v3)**  `arXiv:2409.16663`  
  _Alexander Popov, Alperen Degirmenci, David Wehr, Shashank Hegde, Ryan Oldja, Alexey Kamenev, et al._
  <details><summary>Abstract</summary>
  We propose the use of latent space generative world models to address thecovariate shift problem in autonomous driving. A world model is a neuralnetwork capable of predicting an agent's next state given past states andactions. By leveraging a world model during training, the driving policyeffectively mitigates covariate shift without requiring an excessive amount oftraining data. During end-to-end training, our policy learns how to recoverfrom errors by aligning with states observed in human demonstrations, so thatat runtime it can recover from perturbations outside the training distribution.Additionally, we introduce a novel transformer-based perception encoder thatemploys multi-view cross-attention and a learned scene query. We presentqualitative and quantitative results, demonstrating significant improvementsupon prior state of the art in closed-loop testing in the CARLA simulator, aswell as showing the ability to handle perturbations in both CARLA and NVIDIA'sDRIVE Sim.
  </details>

- **[Tactile Ergodic Coverage on Curved Surfaces](http://arxiv.org/abs/2402.04862v3)**  `arXiv:2402.04862`  
  _Cem Bilaloglu, Tobias L√∂w, Sylvain Calinon_
  <details><summary>Abstract</summary>
  In this article, we present a feedback control method for tactile coveragetasks, such as cleaning or surface inspection. These tasks are challenging toplan due to complex continuous physical interactions. In these tasks, thecoverage target and progress can be easily measured using a camera and encodedin a point cloud. We propose an ergodic coverage method that operates directlyon point clouds, guiding the robot to spend more time on regions requiring morecoverage. For robot control and contact behavior, we use geometric algebra toformulate a task-space impedance controller that tracks a line whilesimultaneously exerting a desired force along that line. We evaluate theperformance of our method in kinematic simulations and demonstrate itsapplicability in real-world experiments on kitchenware. Our source codes,experimental data, and videos are available as open access athttps://sites.google.com/view/tactile-ergodic-control/
  </details>

- **[Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions](http://arxiv.org/abs/2402.01116v5)**  `arXiv:2402.01116`  
  _Hansung Kim, Siddharth H. Nair, Francesco Borrelli_
  <details><summary>Abstract</summary>
  We propose a hierarchical architecture designed for scalable real-time ModelPredictive Control (MPC) in complex, multi-modal traffic scenarios. Thisarchitecture comprises two key components: 1) RAID-Net, a novel attention-basedRecurrent Neural Network that predicts relevant interactions along the MPCprediction horizon between the autonomous vehicle and the surrounding vehiclesusing Lagrangian duality, and 2) a reduced Stochastic MPC problem thateliminates irrelevant collision avoidance constraints, enhancing computationalefficiency. Our approach is demonstrated in a simulated traffic intersectionwith interactive surrounding vehicles, showcasing a 12x speed-up in solving themotion planning problem. A video demonstrating the proposed architecture inmultiple complex traffic scenarios can be found here:https://youtu.be/-pRiOnPb9_c. GitHub:https://github.com/MPC-Berkeley/hmpc_raidnet
  </details>

[‚Üë Back to Top](#-full-archive)

</details>

